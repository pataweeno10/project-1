{"cells":[{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":"<h1> Code for Lychee Yield Prediction </h1>"},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":"Using TensorFlow backend.\n"}],"source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.cm as cm\n# multivariate linear regression with regularization\nfrom sklearn.linear_model import LinearRegression, Ridge, Lasso\n# support vector machine regression\nfrom sklearn.svm import SVR\n# neural network\nfrom keras.models import Sequential\nfrom keras.layers import LSTM, Dense, Dropout, Masking, Embedding\n# normalization\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler\n# score\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n\nimport pickle\nfrom calendar import monthrange"},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":"def clean_text_to_number(df):\n    '''\n    convert all text to 0\n    '''\n    cols = df.columns\n    type_list = []\n    for col in cols:\n        print(col)\n        try:\n            df[col].astype(float)\n        except:\n            for i in range(df[col].shape[0]):\n                if isinstance(df[col].iloc[i], str):\n                    df[col].iloc[i] = 0\n    return df"},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"rain amount dataframe\n(6083, 9)\nhumid dataframe\n(6083, 9)\ntemperature dataframe\n(6083, 9)\nrain dataframe sample\n     1    4    7   10 13    16    19   22 total\n0    0    0    0    0  0     0     0  1.2   1.2\n1  4.4  0.2    5  2.6  0  17.4     0    0  29.6\n2    0    0    0    0  0     0     0    0     -\n3    0    0    0    0  0     0     0    0     -\n4    0  0.6  0.7  2.5  2   7.3  15.1  1.4  29.6\narea dataframe sample\n   year  district  code  allarea  yieldarea      yield  yieldperarea\n0  1994         1    10    24562      16404   8366.040           510\n1  1995         1    10    22053      15021   5798.106           386\n2  1996         1    10    27955      18807   8068.203           429\n3  1997         1    10    31203      23278  11429.498           491\n4  1998         1    10    34200      23519   1481.697            63\n"}],"source":"# import data frame\nrain_df     = pd.read_excel('rain_amount_2003-2019.xlsx')\nhumid_df    = pd.read_excel('relative_humid_2003-2019.xlsx')\ntemp_df     = pd.read_excel('temp_2003-2019.xlsx')\narea_df     = pd.read_excel('area_2003-2019.xls', sheet_name = 'Sheet1')\nlychee_yield_df = pd.read_excel('lycheeproduct.xlsx')\n\n# extract data\nrain_df     = rain_df.iloc[5:-5, :]\nhumid_df    = humid_df.iloc[5:-5, :]\ntemp_df     = temp_df.iloc[5:-5, :]\n\n# reset index\nrain_df     = rain_df.reset_index().drop(columns=['index'])\nhumid_df    = humid_df.reset_index().drop(columns=['index'])\ntemp_df     = temp_df.reset_index().drop(columns=['index'])\n\n# set column name\nrain_df.columns     = ['days', 'location', 'date', '1', '4', '7', '10', '13', '16', '19', '22', 'total']\nhumid_df.columns    = ['days', 'location', 'date', '1', '4', '7', '10', '13', '16', '19', '22', 'mean']\ntemp_df.columns     = ['days', 'location', 'date', '1', '4', '7', '10', '13', '16', '19', '22', 'mean']\nlychee_yield_df.columns = ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', 'total', 'year']\narea_df.columns     = ['year', 'district', 'code', 'province', 'allarea', 'yieldarea', 'yield', 'yieldperarea']\narea_df['year']     = area_df['year'] - 543\n\n# ดึงค่า date เก็บไว้ก่อน\nall_datetime    = pd.to_datetime(rain_df['date'])\n\nrain_df     = rain_df.drop(columns = ['location', 'days', 'date'])\nhumid_df    = humid_df.drop(columns =['location', 'days', 'date'])\ntemp_df     = temp_df.drop(columns =['location', 'days', 'date'])\narea_df     = area_df.drop(columns = ['province'])\n\nprint('rain amount dataframe')\nprint(rain_df.shape)\nprint('humid dataframe')\nprint(humid_df.shape)\nprint('temperature dataframe')\nprint(temp_df.shape)\nprint('rain dataframe sample')\nprint(rain_df.head(5))\nprint('area dataframe sample')\nprint(area_df.head(5))"},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":"# # get datetime from 3 hour data set\n# all_year        = pd.DataFrame(all_datetime.dt.year)\n# all_month       = pd.DataFrame(all_datetime.dt.month)\n# all_day         = pd.DataFrame(all_datetime.dt.day)\n\n# all_year.columns    = ['year']\n# all_month.columns   = ['month']\n# all_day.columns     = ['day']\n# # concat to existing dataframe\n# rain_df = pd.concat([all_year, all_month, all_day, rain_df], axis = 1)\n# humid_df = pd.concat([all_year, all_month, all_day, humid_df], axis = 1)\n# temp_df = pd.concat([all_year, all_month, all_day, temp_df], axis = 1)\n\n# # clean text element and save in pickle form\n\n# rain_df_clean = clean_text_to_number(rain_df)\n# with open('rain_df_clean.pickle', 'wb') as f:\n#     pickle.dump(rain_df_clean, f)\n# humid_df_clean = clean_text_to_number(humid_df)\n# with open('humid_df_clean.pickle', 'wb') as f:\n#     pickle.dump(humid_df_clean, f)\n# temp_df_clean = clean_text_to_number(temp_df)\n# with open('temp_df_clean.pickle', 'wb') as f:\n#     pickle.dump(temp_df_clean, f)"},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"1    4    7   10 13    16    19   22 total\n0    0    0    0    0  0     0     0  1.2   1.2\n1  4.4  0.2    5  2.6  0  17.4     0    0  29.6\n2    0    0    0    0  0     0     0    0     -\n3    0    0    0    0  0     0     0    0     -\n4    0  0.6  0.7  2.5  2   7.3  15.1  1.4  29.6\n    1   4   7  10  13  16  19  22 mean\n0  93  95  95  87  75  73  89  93   88\n1  94  95  94  94  87  91  94  95   93\n2  95  95  95  87  70  60  92  94   86\n3  96  95  94  81  70  62  81  85   83\n4  88  93  93  91  85  95  95  95   92\n      1     4     7    10    13    16    19    22  mean\n0  19.2  18.5  18.2    21  23.5  24.3  22.1  21.3    21\n1    21  20.9  20.8  21.2  23.5  22.5  21.2  20.5  21.5\n2  19.5    20  19.5  21.3  24.6  27.5  22.2  19.5  21.8\n3  19.4  19.6  19.8  21.7  24.2  26.3  23.4    22  22.1\n4  21.1  20.5  20.3    20    21  19.5  19.3  19.5  20.2\n   year  district  code  allarea  yieldarea      yield  yieldperarea\n0  1994         1    10    24562      16404   8366.040           510\n1  1995         1    10    22053      15021   5798.106           386\n2  1996         1    10    27955      18807   8068.203           429\n3  1997         1    10    31203      23278  11429.498           491\n4  1998         1    10    34200      23519   1481.697            63\n   1  2    3      4      5     6  7  8  9  10  11  12  total  year\n0  0  0    0     77  13875  4447  0  0  0   0   0   0  18399  2004\n1  0  0  120  15463   2352     3  0  0  0   0   0   0  17938  2005\n2  0  0  132  17044   2592     4  0  0  0   0   0   0  19773  2006\n3  0  0    0      0  16125  3861  0  0  0   0   0   0  19986  2007\n4  0  0    0     21  13448   586  0  0  0   0   0   0  14055  2008\n"}],"source":"print(rain_df.head(5))\nprint(humid_df.head(5))\nprint(temp_df.head(5))\nprint(area_df.head(5))\nprint(lychee_yield_df.head(5))"},{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":"<h1> Load Data from pickle </h1> since clean dataframe take very long time. So after we clean it, we save dataframe in pickle form."},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":"with open('rain_df_clean.pickle', 'rb') as f:\n    rain_df_clean = pickle.load(f)\nwith open('humid_df_clean.pickle', 'rb') as f:\n    humid_df_clean = pickle.load(f)\nwith open('temp_df_clean.pickle', 'rb') as f:\n    temp_df_clean = pickle.load(f)"},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":"def groupby_col(self, col):\n    '''\n    return \n        1 keys \n        2 dictionary of sub_df ที่ keys คือแต่ละ element ใน col name\n    '''\n\n    output_dic = {}\n    all_ele = sorted(list(set(self[col])))\n\n    for ele in all_ele:\n        sub_df = self.loc[self[col] == ele, :]\n        output_dic[ele] = sub_df\n\n    return all_ele, output_dic\n\ndef groupby_mean(self, col):\n    '''\n    return \n        1 keys \n        2 dictionary of sub_df ที่ keys คือแต่ละ element ใน col name\n    '''\n\n    output_dic = {}\n    all_ele = sorted(list(set(self[col])))\n\n    for ele in all_ele:\n        sub_df = self.loc[self[col] == ele, :].mean(axis=0)\n        output_dic[ele] = sub_df\n    \n    return all_ele, output_dic\n\ndef groupby_max(self, col):\n    '''\n    return \n        1 keys \n        2 dictionary of sub_df ที่ keys คือแต่ละ element ใน col name\n    '''\n\n    output_dic = {}\n    all_ele = sorted(list(set(self[col])))\n\n    for ele in all_ele:\n        sub_df = self.loc[self[col] == ele, :].max(axis = 0)\n        output_dic[ele] = sub_df\n    \n    return all_ele, output_dic\n\ndef groupby_min(self, col):\n    '''\n    return \n        1 keys \n        2 dictionary of sub_df ที่ keys คือแต่ละ element ใน col name\n    '''\n\n    output_dic = {}\n    all_ele = sorted(list(set(self[col])))\n\n    for ele in all_ele:\n        sub_df = self.loc[self[col] == ele, :].min(axis = 0)\n        output_dic[ele] = sub_df\n    \n    return all_ele, output_dic\n\ndef groupby_sum(self, col):\n    '''\n    return \n        1 keys \n        2 dictionary of sub_df ที่ keys คือแต่ละ element ใน col name\n    '''\n\n    output_dic = {}\n    all_ele = sorted(list(set(self[col])))\n\n    for ele in all_ele:\n        sub_df = self.loc[self[col] == ele, :].sum(axis = 0)\n        output_dic[ele] = sub_df\n    \n    return all_ele, output_dic\n\n# set method to class\nsetattr(pd.core.frame.DataFrame, 'groupby_col', groupby_col)\nsetattr(pd.core.frame.DataFrame, 'groupby_mean', groupby_mean)\nsetattr(pd.core.frame.DataFrame, 'groupby_sum', groupby_sum)\nsetattr(pd.core.frame.DataFrame, 'groupby_max', groupby_max)\nsetattr(pd.core.frame.DataFrame, 'groupby_min', groupby_min)"},{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":"<h1> Year Month Temp Humid Rain Yield Dayinmonth Area</h1>"},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"(200, 3)\n"}],"source":"## Temp 2004 - 2019\nmonthly_temp = np.array([1,1,1]).reshape(1,3)\n\nall_year, sub_year_dic = temp_df_clean.groupby_col('year')\n\nfor year in all_year:\n        all_month, sub_month_dic = sub_year_dic[year].groupby_mean('month')\n\n        for month in all_month:\n                # record year month and mean temp of each month\n                daily_temp = np.array([year, month, sub_month_dic[month].iloc[-1]]).reshape(1,3)\n                monthly_temp = np.append(monthly_temp, daily_temp, axis = 0)\n\nmonthly_temp = np.delete(monthly_temp, 0, axis = 0)\nprint(monthly_temp.shape)"},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"(200, 3)\n"}],"source":"## Humid 2004 - 2019\nmonthly_humid = np.array([1,1,1]).reshape(1,3)\n\nall_year, sub_year_dic = humid_df_clean.groupby_col('year')\n\nfor year in all_year:\n        all_month, sub_month_dic = sub_year_dic[year].groupby_mean('month')\n\n        for month in all_month:\n                # record year month and mean temp of each month\n                daily_humid = np.array([year, month, sub_month_dic[month].iloc[-1]]).reshape(1,3)\n                monthly_humid = np.append(monthly_humid, daily_humid, axis = 0)\n\nmonthly_humid = np.delete(monthly_humid, 0, axis = 0)\nprint(monthly_humid.shape)"},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"(200, 3)\n"}],"source":"## Rain 2004 - 2019\nmonthly_rain = np.array([1,1,1]).reshape(1,3)\n\nall_year, sub_year_dic = rain_df_clean.groupby_col('year')\n\nfor year in all_year:\n        all_month, sub_month_dic = sub_year_dic[year].groupby_mean('month')\n\n        for month in all_month:\n                # record year month and mean temp of each month\n                daily_rain = np.array([year, month, sub_month_dic[month].iloc[-1]]).reshape(1,3)\n                monthly_rain = np.append(monthly_rain, daily_rain, axis = 0)\n\nmonthly_rain = np.delete(monthly_rain, 0, axis = 0)\nprint(monthly_rain.shape)"},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"(180, 3)\n"}],"source":"## Lychee yield 2004 - 2018\nmonthly_lychee = np.array([1,1,1]).reshape(1,3)\n\nall_year, _ = rain_df_clean.groupby_col('year')\n\nfor year in all_year:\n        all_month, _ = sub_year_dic[year].groupby_mean('month')\n\n        for month in all_month:\n                # record year month and lychee yield of each month\n                monthly_lychee_temp = lychee_yield_df.loc[lychee_yield_df['year']==year,:]\n                if monthly_lychee_temp.size != 0:\n                    monthly_yield = np.array([year, month, monthly_lychee_temp.iloc[0, month-1]]).reshape(1,3)\n                    monthly_lychee = np.append(monthly_lychee, monthly_yield, axis = 0)\n\nmonthly_lychee = np.delete(monthly_lychee, 0, axis = 0)\nprint(monthly_lychee.shape)"},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"(192, 3)\n"}],"source":"## area yield 1994 - 2018\nmonthly_area = np.array([1,1,1]).reshape(1,3)\n\nall_year, _ = rain_df_clean.groupby_col('year')\n\nfor year in all_year:\n        all_month, _ = sub_year_dic[year].groupby_mean('month')\n\n        for month in all_month:\n                # record year month and lychee yield of each month\n                monthly_area_temp = area_df.loc[area_df['year']==year,:]\n                if monthly_area_temp.size != 0:\n                    monthly_area_temp = np.array([year, month, monthly_area_temp.iloc[0, -1]]).reshape(1,3)\n                    monthly_area = np.append(monthly_area, monthly_area_temp, axis = 0)\n\nmonthly_area = np.delete(monthly_area, 0, axis = 0)\nprint(monthly_area.shape)"},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"(200, 3)\n"}],"source":"## month range 2004 - 2019\nmonthly_numday = np.array([1,1,1]).reshape(1,3)\n\nall_year, _ = rain_df_clean.groupby_col('year')\n\nfor year in all_year:\n        all_month, _ = sub_year_dic[year].groupby_mean('month')\n\n        for month in all_month:\n                # record year month and lychee yield of each month\n                monthly_numday_temp = np.array([year, month, monthrange(year, month)[1]]).reshape(1,3)\n                monthly_numday = np.append(monthly_numday,monthly_numday_temp, axis = 0)\n\nmonthly_numday = np.delete(monthly_numday, 0, axis = 0)\nprint(monthly_numday.shape)"},{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":"Intersect year of all data is 2004 - 2018"},{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":"<h1> Method for getting X data </h1>"},{"cell_type":"code","execution_count":111,"metadata":{},"outputs":[],"source":"def rmse(y_true, y_pred):\n\n    ind_ignorezero = (y_true != 0).reshape(-1,)\n    error = (y_true - y_pred)\n    se = error**2\n    mse = np.mean(se)\n    rmse = mse**0.5\n    return rmse"},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":"def get_info_from(info, year_fr, month_fr, year_to, month_to):\n    '''\n    extract info since year and month from np array input\n    but the first 2 row have to be year and month respectively\n    '''\n\n    year2month = info[:, 0]*12 + info[:,1]\n    target_year2month = year_fr*12 + month_fr\n    target_year2month_to = year_to*12 + month_to\n\n    return info[np.logical_and(year2month >= target_year2month, year2month <= target_year2month_to)]"},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":"def get_X_thr(info, year_fr, month_fr, year_to, month_to):\n    # input\n    all_year = [i for i in range(2004, 2017)]\n    # temp as a input\n    X_temp_1 = get_info_from(info, year_fr, month_fr, year_to, month_to-1)\n    X_temp_2 = get_info_from(info, year_fr+1, (month_fr+1)%12, year_to, month_to)  \n\n    \n    # only consider month 12, 1, 2, 3\n    for i in [3, 4, 5, 6, 7, 8, 9, 10, 11]:\n        X_temp_1 = X_temp_1[X_temp_1[:, 1] != i]\n    for i in [ 4, 5, 6, 7, 8, 9, 10, 11, 12]:\n        X_temp_2 = X_temp_2[X_temp_2[:, 1] != i]\n    \n    # get rid of year and month\n    X_temp_1 = np.append(X_temp_1, X_temp_2[:, -1].reshape(-1,1), axis = 1)\n    \n    return X_temp_1"},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":"def get_X_area(info, year_fr, month_fr, year_to, month_to):\n    # input\n    all_year = [i for i in range(2004, 2017)]\n\n    X_temp_1 = get_info_from(info, year_fr, month_fr, year_to, month_to-1)\n\n    # only consider month 12, 1, 2, 3\n    for i in [4, 5, 6, 7, 8, 9, 10, 11, 12]:\n        X_temp_1 = X_temp_1[X_temp_1[:, 1] != i]    \n    \n    return X_temp_1"},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":"def get_X_dayinmonth(info, year_fr, month_fr, year_to, month_to):\n    # input\n    all_year = [i for i in range(2004, 2017)]\n\n    X_temp_1 = get_info_from(info, year_fr, month_fr, year_to, month_to-1)\n\n    # only consider month 12, 1, 2, 3\n    for i in [1, 2, 3, 7, 8, 9, 10, 11, 12]:\n        X_temp_1 = X_temp_1[X_temp_1[:, 1] != i]    \n    \n    return X_temp_1"},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":"def mae(y_true, y_pred):\n\n    error = y_true - y_pred\n    ae = np.abs(error)\n    mae = np.mean(ae)\n\n    return mae"},{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":"Get y"},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"(42,)\n"}],"source":"Y_all = get_X_dayinmonth(monthly_lychee, 2005,1, 2018,12)\n\nY = Y_all[:, -1]\nprint(Y.shape)"},{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":"<h1> Feature selection </h1>\nYear (of the target), Month (of the target), Avg.Temp (3 and 4 month before), Avg.Humid (3 and 4 month before),\nRain amount (3 and 4 month before), lychee yield per area (1 year before), number of the day in target month,\nlychee yield (of target month but 1 year before)"},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"(42, 4)\n(42, 4)\n(42, 4)\n(42, 3)\n(42, 3)\n(42, 3)\n(42, 10)\n"}],"source":"X_monthly_temp  = get_X_thr(monthly_temp, 2004, 12, 2018, 3)\nX_monthly_humid = get_X_thr(monthly_humid, 2004, 12, 2018, 3)\nX_monthly_rain  = get_X_thr(monthly_rain, 2004, 12, 2018, 3)\n\nX_monthly_area   = get_X_area(monthly_area, 2004,1, 2017,12)\nX_monthly_month_range = get_X_dayinmonth(monthly_numday, 2004,1, 2017,12)\nX_monthly_yield = get_X_dayinmonth(monthly_lychee, 2004,1, 2017,12)\n\nprint(X_monthly_temp.shape)\nprint(X_monthly_humid.shape)\nprint(X_monthly_rain.shape)\nprint(X_monthly_area.shape)\nprint(X_monthly_month_range.shape)\nprint(X_monthly_yield.shape)\n\n# X\n# Year (of the target), Month (of the target), Avg.Temp (3 and 4 month before), Avg.Humid (3 and 4 month before),\n# Rain amount (3 and 4 month before), lychee yield per area (1 year before), \n# lychee yield (of target month but 1 year before)\nX = np.concatenate([Y_all[:, 0:2], X_monthly_temp[:, 2:], X_monthly_humid[:,2:], X_monthly_rain[:, 2:], X_monthly_area[:, 2:], X_monthly_yield[:, 2:]], axis = 1)\n\nprint(X.shape)"},{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":"Seperate train set and test set"},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"train size\n(29, 10)\ntest size\n(13, 10)\n"}],"source":"X_train, X_test, Y_train, Y_test =  train_test_split(X, Y, test_size=0.3)\n# sss = StratifiedShuffleSplit(n_splits=5, test_size=0.27)\nprint('train size')\nprint(X_train.shape)\nprint('test size')\nprint(X_test.shape)"},{"cell_type":"markdown","execution_count":216,"metadata":{},"outputs":[{"ename":"SyntaxError","evalue":"invalid syntax (<ipython-input-216-4cb65ebd8512>, line 1)","output_type":"error","traceback":["\u001b[1;36m  File \u001b[1;32m\"<ipython-input-216-4cb65ebd8512>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    <h1> Ridge Model w/o Normalization </h1>\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"]}],"source":"<h1> Ridge Model w/o Normalization </h1>"},{"cell_type":"code","execution_count":114,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"Train set MAE 2233.27\nTest set MAE 3469.76\nTrain set RMSE 3027.22\nTest set RMSE 4866.62\n"}],"source":"# vector for record error\ntrain_mae = np.array([])\ntest_mae = np.array([])\n\ntrain_rmse = np.array([])\ntest_rmse = np.array([])\n\n# minmaxscaler\n\nfor i in range(100):\n\n    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3)\n\n    # scale data\n    reg_lr = Ridge(alpha = 0.5)\n    reg_lr.fit(X_train, Y_train)\n\n    Y_test_pred = reg_lr.predict(X_test)\n    Y_test_pred[Y_test_pred<0] = 0\n\n    Y_train_pred = reg_lr.predict(X_train)\n    Y_train_pred[Y_train_pred<0] = 0\n\n    train_mae = np.append(train_mae, mae(Y_train, Y_train_pred))\n    test_mae = np.append(test_mae, mae(Y_test, Y_test_pred))\n\n    train_rmse = np.append(train_rmse, rmse(Y_train, Y_train_pred))\n    test_rmse = np.append(test_rmse, rmse(Y_test, Y_test_pred))    \n\nprint('Train set MAE {:.2f}'.format(np.mean(train_mae)))\nprint('Test set MAE {:.2f}'.format(np.mean(test_mae)))\n\nprint('Train set RMSE {:.2f}'.format(np.mean(train_rmse)))\nprint('Test set RMSE {:.2f}'.format(np.mean(test_rmse)))"},{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":"<h1> Ridge Model w Normalization </h1>"},{"cell_type":"code","execution_count":124,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"Train set MAE 2361.28\nTest set MAE 3319.21\nTrain set RMSE 3234.11\nTest set RMSE 4551.77\n"}],"source":"# vector for record error\ntrain_mae = np.array([])\ntest_mae = np.array([])\n\ntrain_rmse = np.array([])\ntest_rmse = np.array([])\n\n# minmaxscaler\nscaler = MinMaxScaler()\n\nfor i in range(100):\n\n    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3)\n\n    # scale data\n    scaler.fit(X_train)\n    # reg = LinearRegression()\n    # reg_lr_norm = Lasso(alpha = 0.5)\n    reg_lr_norm = Ridge(alpha = 0.5)\n    reg_lr_norm.fit(scaler.transform(X_train), Y_train)\n\n    Y_test_pred = reg_lr_norm.predict(scaler.transform(X_test))\n    Y_test_pred[Y_test_pred<0] = 0\n\n    Y_train_pred = reg_lr_norm.predict(scaler.transform(X_train))\n    Y_train_pred[Y_train_pred<0] = 0\n\n    train_mae = np.append(train_mae, mae(Y_train, Y_train_pred))\n    test_mae = np.append(test_mae, mae(Y_test, Y_test_pred))\n\n    train_rmse = np.append(train_rmse, rmse(Y_train, Y_train_pred))\n    test_rmse = np.append(test_rmse, rmse(Y_test, Y_test_pred))    \n\nprint('Train set MAE {:.2f}'.format(np.mean(train_mae)))\nprint('Test set MAE {:.2f}'.format(np.mean(test_mae)))\n\nprint('Train set RMSE {:.2f}'.format(np.mean(train_rmse)))\nprint('Test set RMSE {:.2f}'.format(np.mean(test_rmse)))"},{"cell_type":"code","execution_count":125,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"lambda -2835.61 feature : Year (of the target)\nlambda 3929.55 feature :  Month (of the target)\nlambda -7367.51 feature : Avg.Temp (3 and 4 month before)\nlambda -3908.33 feature :  Avg.Humid (3 and 4 month before)\nlambda 112.08 feature : Rain amount (3 and 4 month before)\nlambda -1146.56 feature : lychee yield per area (1 year before)\nlambda -24.64 feature : lychee yield (of target month but 1 year before)\n"}],"source":"# show coef of each feature\nfeature_list = ['Year (of the target)',' Month (of the target)', 'Avg.Temp (3 and 4 month before)',' Avg.Humid (3 and 4 month before)', 'Rain amount (3 and 4 month before)', 'lychee yield per area (1 year before)','lychee yield (of target month but 1 year before)']\nfor coef, feature in zip(reg_lr_norm.coef_, feature_list):\n    print('lambda {:.2f} feature : {:s}'.format(coef, feature))"},{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":"<h1> Support Vector Regression w/o Normalization </h1>"},{"cell_type":"code","execution_count":119,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"Train set MAE 2307.27\nTest set MAE 2663.03\nTrain set RMSE 4175.42\nTest set RMSE 4479.70\n"}],"source":"# vector for record error\ntrain_mae = np.array([])\ntest_mae = np.array([])\n\ntrain_rmse = np.array([])\ntest_rmse = np.array([])\n\n# minmaxscaler\n\nfor i in range(50):\n\n    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3)\n\n    # scale data\n    reg_svr = SVR(kernel = 'linear' ,gamma = 'auto', C=1)\n    reg_svr.fit(X_train, Y_train)\n\n    Y_test_pred = reg_svr.predict(X_test)\n    Y_test_pred[Y_test_pred<0] = 0\n\n    Y_train_pred = reg_svr.predict(X_train)\n    Y_train_pred[Y_train_pred<0] = 0\n\n    train_mae = np.append(train_mae, mae(Y_train, Y_train_pred))\n    test_mae = np.append(test_mae, mae(Y_test, Y_test_pred))\n\n    train_rmse = np.append(train_rmse, rmse(Y_train, Y_train_pred))\n    test_rmse = np.append(test_rmse, rmse(Y_test, Y_test_pred))    \n\nprint('Train set MAE {:.2f}'.format(np.mean(train_mae)))\nprint('Test set MAE {:.2f}'.format(np.mean(test_mae)))\n\nprint('Train set RMSE {:.2f}'.format(np.mean(train_rmse)))\nprint('Test set RMSE {:.2f}'.format(np.mean(test_rmse)))"},{"cell_type":"code","execution_count":120,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"year 2005 month 4 true : 15463\tpred : 852\nyear 2005 month 5 true : 2352\tpred : 11779\nyear 2005 month 6 true : 3\tpred : 4404\nyear 2006 month 4 true : 17044\tpred : 12662\nyear 2006 month 5 true : 2592\tpred : 2587\nyear 2006 month 6 true : 4\tpred : 877\nyear 2007 month 4 true : 0\tpred : 14035\nyear 2007 month 5 true : 16125\tpred : 2968\nyear 2007 month 6 true : 3861\tpred : 1066\nyear 2008 month 4 true : 21\tpred : 544\nyear 2008 month 5 true : 13448\tpred : 13133\nyear 2008 month 6 true : 586\tpred : 3717\nyear 2009 month 4 true : 5430\tpred : 641\nyear 2009 month 5 true : 11197\tpred : 11188\nyear 2009 month 6 true : 1625\tpred : 1260\nyear 2010 month 4 true : 0\tpred : 4882\nyear 2010 month 5 true : 6476\tpred : 9589\nyear 2010 month 6 true : 2775\tpred : 2205\nyear 2011 month 4 true : 0\tpred : 429\nyear 2011 month 5 true : 2867\tpred : 5682\nyear 2011 month 6 true : 5236\tpred : 2765\nyear 2012 month 4 true : 155\tpred : 418\nyear 2012 month 5 true : 6486\tpred : 2815\nyear 2012 month 6 true : 4683\tpred : 4682\nyear 2013 month 4 true : 0\tpred : 493\nyear 2013 month 5 true : 5469\tpred : 5467\nyear 2013 month 6 true : 2794\tpred : 4107\nyear 2014 month 4 true : 354\tpred : 355\nyear 2014 month 5 true : 5172\tpred : 4865\nyear 2014 month 6 true : 1558\tpred : 2818\nyear 2015 month 4 true : 0\tpred : 658\nyear 2015 month 5 true : 5309\tpred : 4576\nyear 2015 month 6 true : 590\tpred : 1805\nyear 2016 month 4 true : 48\tpred : 371\nyear 2016 month 5 true : 4059\tpred : 4699\nyear 2016 month 6 true : 725\tpred : 1180\nyear 2017 month 4 true : 211\tpred : 212\nyear 2017 month 5 true : 4551\tpred : 3584\nyear 2017 month 6 true : 646\tpred : 1230\nyear 2018 month 4 true : 221\tpred : 402\nyear 2018 month 5 true : 4754\tpred : 3930\nyear 2018 month 6 true : 675\tpred : 934\n"}],"source":"Y_all_test = reg_svr.predict(X)\nY_all_test[Y_all_test<0] = 0\nfor year, month, y_true, y_pred in zip(Y_all[:,0], Y_all[:,1], Y, Y_all_test):\n    print('year {:.0f} month {:.0f} true : {:.0f}\\tpred : {:.0f}'.format(year, month, y_true, y_pred))"},{"cell_type":"markdown","execution_count":51,"metadata":{},"outputs":[{"ename":"SyntaxError","evalue":"invalid syntax (<ipython-input-51-caf24b3276ae>, line 1)","output_type":"error","traceback":["\u001b[1;36m  File \u001b[1;32m\"<ipython-input-51-caf24b3276ae>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    <h1> Support Vector Regression w Normalization </h1>\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"]}],"source":"<h1> Support Vector Regression w Normalization </h1>"},{"cell_type":"code","execution_count":121,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"Train set MAE 3163.94\nTest set MAE 3500.16\nTrain set RMSE 4775.26\nTest set RMSE 4881.38\n"}],"source":"# vector for record error\ntrain_mae = np.array([])\ntest_mae = np.array([])\n\ntrain_rmse = np.array([])\ntest_rmse = np.array([])\n\n# minmaxscaler\nscaler = StandardScaler()\n\nfor i in range(50):\n\n    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3)\n\n    # scale data\n    scaler.fit(X_train)\n    reg_svr_norm = SVR(kernel = 'poly' ,gamma = 'scale', C=1)\n    reg_svr_norm.fit(scaler.transform(X_train), Y_train)\n\n    Y_test_pred = reg_svr_norm.predict(scaler.transform(X_test))\n    Y_test_pred[Y_test_pred<0] = 0\n\n    Y_train_pred = reg_svr_norm.predict(scaler.transform(X_train))\n    Y_train_pred[Y_train_pred<0] = 0\n\n    train_mae = np.append(train_mae, mae(Y_train, Y_train_pred))\n    test_mae = np.append(test_mae, mae(Y_test, Y_test_pred))\n\n    train_rmse = np.append(train_rmse, rmse(Y_train, Y_train_pred))\n    test_rmse = np.append(test_rmse, rmse(Y_test, Y_test_pred))    \n\nprint('Train set MAE {:.2f}'.format(np.mean(train_mae)))\nprint('Test set MAE {:.2f}'.format(np.mean(test_mae)))\n\nprint('Train set RMSE {:.2f}'.format(np.mean(train_rmse)))\nprint('Test set RMSE {:.2f}'.format(np.mean(test_rmse)))"},{"cell_type":"code","execution_count":122,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"year 2005 month 4 true : 15463\tpred : 852\nyear 2005 month 5 true : 2352\tpred : 11779\nyear 2005 month 6 true : 3\tpred : 4404\nyear 2006 month 4 true : 17044\tpred : 12662\nyear 2006 month 5 true : 2592\tpred : 2587\nyear 2006 month 6 true : 4\tpred : 877\nyear 2007 month 4 true : 0\tpred : 14035\nyear 2007 month 5 true : 16125\tpred : 2968\nyear 2007 month 6 true : 3861\tpred : 1066\nyear 2008 month 4 true : 21\tpred : 544\nyear 2008 month 5 true : 13448\tpred : 13133\nyear 2008 month 6 true : 586\tpred : 3717\nyear 2009 month 4 true : 5430\tpred : 641\nyear 2009 month 5 true : 11197\tpred : 11188\nyear 2009 month 6 true : 1625\tpred : 1260\nyear 2010 month 4 true : 0\tpred : 4882\nyear 2010 month 5 true : 6476\tpred : 9589\nyear 2010 month 6 true : 2775\tpred : 2205\nyear 2011 month 4 true : 0\tpred : 429\nyear 2011 month 5 true : 2867\tpred : 5682\nyear 2011 month 6 true : 5236\tpred : 2765\nyear 2012 month 4 true : 155\tpred : 418\nyear 2012 month 5 true : 6486\tpred : 2815\nyear 2012 month 6 true : 4683\tpred : 4682\nyear 2013 month 4 true : 0\tpred : 493\nyear 2013 month 5 true : 5469\tpred : 5467\nyear 2013 month 6 true : 2794\tpred : 4107\nyear 2014 month 4 true : 354\tpred : 355\nyear 2014 month 5 true : 5172\tpred : 4865\nyear 2014 month 6 true : 1558\tpred : 2818\nyear 2015 month 4 true : 0\tpred : 658\nyear 2015 month 5 true : 5309\tpred : 4576\nyear 2015 month 6 true : 590\tpred : 1805\nyear 2016 month 4 true : 48\tpred : 371\nyear 2016 month 5 true : 4059\tpred : 4699\nyear 2016 month 6 true : 725\tpred : 1180\nyear 2017 month 4 true : 211\tpred : 212\nyear 2017 month 5 true : 4551\tpred : 3584\nyear 2017 month 6 true : 646\tpred : 1230\nyear 2018 month 4 true : 221\tpred : 402\nyear 2018 month 5 true : 4754\tpred : 3930\nyear 2018 month 6 true : 675\tpred : 934\n"}],"source":"Y_all_test = reg_svr.predict(X)\nY_all_test[Y_all_test<0] = 0\nfor year, month, y_true, y_pred in zip(Y_all[:,0], Y_all[:,1], Y, Y_all_test):\n    print('year {:.0f} month {:.0f} true : {:.0f}\\tpred : {:.0f}'.format(year, month, y_true, y_pred))"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":""}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}