{"cells":[{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":["<h1> Code for Lychee Yield Prediction </h1>"]},{"cell_type":"code","execution_count":105,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib.cm as cm\n","# multivariate linear regression with regularization\n","from sklearn.linear_model import LinearRegression, Ridge, Lasso\n","# support vector machine regression\n","from sklearn.svm import SVR\n","from sklearn.metrics import r2_score\n","# neural network\n","import tensorflow\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import LSTM, GRU, Dense, Dropout, Bidirectional, BatchNormalization\n","# normalization\n","from sklearn.preprocessing import MinMaxScaler, StandardScaler, PowerTransformer\n","from sklearn.pipeline import Pipeline\n","from sklearn.decomposition import PCA\n","# score\n","from sklearn.metrics import mean_absolute_error\n","from sklearn.model_selection import train_test_split, StratifiedShuffleSplit, GridSearchCV, RandomizedSearchCV\n","# import keras\n","import tensorflow.keras\n","from tensorflow.keras import optimizers, regularizers\n","# import regularizer\n","from tensorflow.keras.regularizers import l1, l2\n","# import matplotlib\n","import matplotlib.pyplot as plt\n","# os\n","import os\n","\n","import pickle\n","from calendar import monthrange"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["def clean_text_to_number(df):\n","    '''\n","    convert all text to 0\n","    '''\n","    cols = df.columns\n","    type_list = []\n","    for col in cols:\n","        print(col)\n","        try:\n","            df[col].astype(float)\n","        except:\n","            for i in range(df[col].shape[0]):\n","                if isinstance(df[col].iloc[i], str):\n","                    df[col].iloc[i] = 0\n","    return df"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"rain amount dataframe\n(5051, 9)\nhumid dataframe\n(5051, 9)\ntemperature dataframe\n(5051, 9)\nrain dataframe sample\n   1  4  7 10 13 16 19 22 total\n0  0  0  0  0  0  0  0  0     -\n1  0  0  0  0  0  0  0  0     -\n2  0  0  0  0  0  0  0  0     -\n3  0  0  0  0  0  0  0  0     -\n4  0  0  0  0  0  0  0  0     -\narea dataframe sample\n   year  district  code  allarea  yieldarea  yield  yieldperarea\n0  1994         1   110     1983       1295    739         571.0\n1  1995         1   110     3001       1457    994         682.0\n2  1996         1   110     3260       1584   1050         663.0\n3  1997         1   110     4385       2041   1265         620.0\n4  1998         1   110     7810       3059   1208         395.0\n"}],"source":["# import data frame\n","rain_df     = pd.read_excel('rain_amount_2006-2019.xlsx')\n","humid_df    = pd.read_excel('relative_humid_2006-2019.xlsx')\n","temp_df     = pd.read_excel('temp_2006-2019.xlsx')\n","area_df     = pd.read_excel('area_1994-2018.xls', sheet_name = 'Sheet1')\n","lychee_yield_df = pd.read_excel('lycheeproduct.xlsx')\n","\n","# extract data\n","rain_df     = rain_df.iloc[5:, :]\n","humid_df    = humid_df.iloc[5:, :]\n","temp_df     = temp_df.iloc[5:, :]\n","\n","# reset index\n","rain_df     = rain_df.reset_index().drop(columns=['index'])\n","humid_df    = humid_df.reset_index().drop(columns=['index'])\n","temp_df     = temp_df.reset_index().drop(columns=['index'])\n","\n","# set column name\n","rain_df.columns     = ['days', 'location', 'date', '1', '4', '7', '10', '13', '16', '19', '22', 'total']\n","humid_df.columns    = ['days', 'location', 'date', '1', '4', '7', '10', '13', '16', '19', '22', 'mean']\n","temp_df.columns     = ['days', 'location', 'date', '1', '4', '7', '10', '13', '16', '19', '22', 'mean']\n","lychee_yield_df.columns = ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', 'total', 'year']\n","area_df.columns     = ['year', 'district', 'code', 'province', 'allarea', 'yieldarea', 'yield', 'yieldperarea']\n","area_df['year']     = area_df['year'] - 543\n","\n","# ดึงค่า date เก็บไว้ก่อน\n","all_datetime    = pd.to_datetime(rain_df['date'])\n","\n","rain_df     = rain_df.drop(columns = ['location', 'days', 'date'])\n","humid_df    = humid_df.drop(columns =['location', 'days', 'date'])\n","temp_df     = temp_df.drop(columns =['location', 'days', 'date'])\n","area_df     = area_df.drop(columns = ['province'])\n","\n","print('rain amount dataframe')\n","print(rain_df.shape)\n","print('humid dataframe')\n","print(humid_df.shape)\n","print('temperature dataframe')\n","print(temp_df.shape)\n","print('rain dataframe sample')\n","print(rain_df.head(5))\n","print('area dataframe sample')\n","print(area_df.head(5))"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["# # get datetime from 3 hour data set\n","# all_year        = pd.DataFrame(all_datetime.dt.year)\n","# all_month       = pd.DataFrame(all_datetime.dt.month)\n","# all_day         = pd.DataFrame(all_datetime.dt.day)\n","\n","# all_year.columns    = ['year']\n","# all_month.columns   = ['month']\n","# all_day.columns     = ['day']\n","# # concat to existing dataframe\n","# rain_df = pd.concat([all_year, all_month, all_day, rain_df], axis = 1)\n","# humid_df = pd.concat([all_year, all_month, all_day, humid_df], axis = 1)\n","# temp_df = pd.concat([all_year, all_month, all_day, temp_df], axis = 1)\n","\n","# # clean text element and save in pickle form\n","\n","# rain_df_clean = clean_text_to_number(rain_df)\n","# with open('rain_df_clean.pickle', 'wb') as f:\n","#     pickle.dump(rain_df_clean, f)\n","# humid_df_clean = clean_text_to_number(humid_df)\n","# with open('humid_df_clean.pickle', 'wb') as f:\n","#     pickle.dump(humid_df_clean, f)\n","# temp_df_clean = clean_text_to_number(temp_df)\n","# with open('temp_df_clean.pickle', 'wb') as f:\n","#     pickle.dump(temp_df_clean, f)"]},{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":["<h1> Load Data from pickle </h1> since clean dataframe take very long time. So after we clean it, we save dataframe in pickle form."]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["with open('rain_df_clean.pickle', 'rb') as f:\n","    rain_df_clean = pickle.load(f)\n","with open('humid_df_clean.pickle', 'rb') as f:\n","    humid_df_clean = pickle.load(f)\n","with open('temp_df_clean.pickle', 'rb') as f:\n","    temp_df_clean = pickle.load(f)"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"--- rain amount dataframe sample ---\n      year  month  day  1    4  7 10 13 16 19 22 total\n5046  2019     10   26  0    0  0  0  0  0  0  0     0\n5047  2019     10   27  0    0  0  0  0  0  0  0     0\n5048  2019     10   28  0    0  0  0  0  0  0  0     0\n5049  2019     10   29  0  3.3  0  0  0  0  0  0   3.3\n5050  2019     10   30  0    0  0  0  0  0  0  0     0\n --- humid dataframe sample ---\n   year  month  day   1   4   7  10  13  16  19  22 mean\n0  2006      1    1  93  94  95  71  46  43  69  87   75\n1  2006      2    1  94  95  95  82  47  36  73  86   76\n2  2006      3    1  93  93  96  81  50  42  69  87   76\n3  2006      4    1  89  96  94  81  45  38  71  85   75\n4  2006      5    1  92  94  98  91  53  38  72  85   78\n --- temperature dataframe sample ---\n   year  month  day     1     4     7    10    13    16    19    22  mean\n0  2006      1    1  16.7    15    14    21  28.9  31.3  24.2  20.3  21.4\n1  2006      2    1  18.3  16.5  15.5  20.5    29    31  22.5  19.7  21.6\n2  2006      3    1  17.3  15.6    15    20  28.5  30.5  23.5  18.8  21.2\n3  2006      4    1    16    13  12.5  18.8  27.7  30.2  22.6  18.5  19.9\n4  2006      5    1  15.6  13.5  12.6    16  25.2  31.2  22.4  17.5  19.3\n --- area dataframe sample ---\n   year  district  code  allarea  yieldarea  yield  yieldperarea\n0  1994         1   110     1983       1295    739         571.0\n1  1995         1   110     3001       1457    994         682.0\n2  1996         1   110     3260       1584   1050         663.0\n3  1997         1   110     4385       2041   1265         620.0\n4  1998         1   110     7810       3059   1208         395.0\n --- lychee yield dataframe sample ---\n      1     2     3     4     5     6     7     8     9    10    11    12  \\\n0  8435  8435  8435  8435  8435  8435  8435  8435  8435  8435  8435  8435   \n1  7591  7591  7591  7591  7591  7591  7591  7591  7591  7591  7591  7591   \n2  6813  6813  6813  6813  6813  6813  6813  6813  6813  6813  6813  6813   \n3  7307  7307  7307  7307  7307  7307  7307  7307  7307  7307  7307  7307   \n4  4338  4338  4338  4338  4338  4338  4338  4338  4338  4338  4338  4338   \n\n   total  year  \n0   8435  2004  \n1   7591  2005  \n2   6813  2006  \n3   7307  2007  \n4   4338  2008  \n"}],"source":["print(' --- rain amount dataframe sample ---')\n","print(rain_df_clean.tail(5))\n","print(' --- humid dataframe sample ---')\n","print(humid_df_clean.head(5))\n","print(' --- temperature dataframe sample ---')\n","print(temp_df_clean.head(5))\n","print(' --- area dataframe sample ---')\n","print(area_df.head(5))\n","print(' --- lychee yield dataframe sample ---')\n","print(lychee_yield_df.head(5))"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["def groupby_col(self, col):\n","    '''\n","    return \n","        1 keys \n","        2 dictionary of sub_df ที่ keys คือแต่ละ element ใน col name\n","    '''\n","\n","    output_dic = {}\n","    all_ele = sorted(list(set(self[col])))\n","\n","    for ele in all_ele:\n","        sub_df = self.loc[self[col] == ele, :]\n","        output_dic[ele] = sub_df\n","\n","    return all_ele, output_dic\n","\n","def groupby_mean(self, col):\n","    '''\n","    return \n","        1 keys \n","        2 dictionary of sub_df ที่ keys คือแต่ละ element ใน col name\n","    '''\n","\n","    output_dic = {}\n","    all_ele = sorted(list(set(self[col])))\n","    for ele in all_ele:\n","        sub_df = self.loc[self[col] == ele, :].mean(axis=0)\n","        output_dic[ele] = sub_df\n","    \n","    return all_ele, output_dic\n","\n","def groupby_max(self, col):\n","    '''\n","    return \n","        1 keys \n","        2 dictionary of sub_df ที่ keys คือแต่ละ element ใน col name\n","    '''\n","\n","    output_dic = {}\n","    all_ele = sorted(list(set(self[col])))\n","\n","    for ele in all_ele:\n","        sub_df = self.loc[self[col] == ele, :].max(axis = 0)\n","        output_dic[ele] = sub_df\n","    \n","    return all_ele, output_dic\n","\n","def groupby_min(self, col):\n","    '''\n","    return \n","        1 keys \n","        2 dictionary of sub_df ที่ keys คือแต่ละ element ใน col name\n","    '''\n","\n","    output_dic = {}\n","    all_ele = sorted(list(set(self[col])))\n","\n","    for ele in all_ele:\n","        sub_df = self.loc[self[col] == ele, :].min(axis = 0)\n","        output_dic[ele] = sub_df\n","    \n","    return all_ele, output_dic\n","\n","def groupby_sum(self, col):\n","    '''\n","    return \n","        1 keys \n","        2 dictionary of sub_df ที่ keys คือแต่ละ element ใน col name\n","    '''\n","\n","    output_dic = {}\n","    all_ele = sorted(list(set(self[col])))\n","\n","    for ele in all_ele:\n","        sub_df = self.loc[self[col] == ele, :].sum(axis = 0)\n","        output_dic[ele] = sub_df\n","    \n","    return all_ele, output_dic\n","\n","# set method to class\n","setattr(pd.core.frame.DataFrame, 'groupby_col', groupby_col)\n","setattr(pd.core.frame.DataFrame, 'groupby_mean', groupby_mean)\n","setattr(pd.core.frame.DataFrame, 'groupby_sum', groupby_sum)\n","setattr(pd.core.frame.DataFrame, 'groupby_max', groupby_max)\n","setattr(pd.core.frame.DataFrame, 'groupby_min', groupby_min)"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["def export_output(filename, year_train, month_train, y_train_true, y_train_pred, year_test, month_test, y_test_true, y_test_pred):\n","    \n","    dic_train = {\n","        'year':year_train.reshape(-1),\n","        'month':month_train.reshape(-1),\n","        'y_true': y_train_true.reshape(-1),\n","        'y_pred': y_train_pred.reshape(-1)\n","    }\n","\n","    dic_test = {\n","        'year':year_test.reshape(-1),\n","        'month':month_test.reshape(-1),\n","        'y_true': y_test_true.reshape(-1),\n","        'y_pred': y_test_pred.reshape(-1)\n","    }\n","    \n","    df_train = pd.DataFrame(dic_train)\n","    df_test = pd.DataFrame(dic_test)\n","    \n","    # Create a Pandas Excel writer using XlsxWriter as the engine.\n","    writer = pd.ExcelWriter(filename, engine='xlsxwriter')\n","    # Write centroids sheet\n","    df_train.to_excel(writer, sheet_name='train set')\n","    df_test.to_excel(writer, sheet_name='test set')\n","    # save output\n","    writer.save()\n"]},{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":["<h1> Rearrange for monthly data </h1>"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"(168, 3)\n"}],"source":["## montly Temp 2006 - 2019\n","monthly_temp = np.array([1,1,1]).reshape(1,3)\n","\n","all_year, sub_year_dic = temp_df_clean.groupby_col('year')\n","\n","for year in all_year:\n","        all_month, sub_month_dic = sub_year_dic[year].groupby_mean('month')\n","        for month in all_month:\n","                # record year month and mean temp of each month\n","                daily_temp = np.array([year, month, sub_month_dic[month].iloc[-1]]).reshape(1,3)\n","                monthly_temp = np.append(monthly_temp, daily_temp, axis = 0)\n","\n","monthly_temp = np.delete(monthly_temp, 0, axis = 0)\n","print(monthly_temp.shape)"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"(168, 3)\n"}],"source":["## montly Humid 2006 - 2019\n","monthly_humid = np.array([1,1,1]).reshape(1,3)\n","\n","all_year, sub_year_dic = humid_df_clean.groupby_col('year')\n","\n","for year in all_year:\n","        all_month, sub_month_dic = sub_year_dic[year].groupby_mean('month')\n","\n","        for month in all_month:\n","                # record year month and mean temp of each month\n","                daily_humid = np.array([year, month, sub_month_dic[month].iloc[-1]]).reshape(1,3)\n","                monthly_humid = np.append(monthly_humid, daily_humid, axis = 0)\n","\n","monthly_humid = np.delete(monthly_humid, 0, axis = 0)\n","print(monthly_humid.shape)"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"(168, 3)\n"}],"source":["## monthly Rain 2006 - 2019\n","monthly_rain = np.array([1,1,1]).reshape(1,3)\n","\n","all_year, sub_year_dic = rain_df_clean.groupby_col('year')\n","\n","for year in all_year:\n","        all_month, sub_month_dic = sub_year_dic[year].groupby_mean('month')\n","\n","        for month in all_month:\n","                # record year month and mean temp of each month\n","                daily_rain = np.array([year, month, sub_month_dic[month].iloc[-1]]).reshape(1,3)\n","                monthly_rain = np.append(monthly_rain, daily_rain, axis = 0)\n","\n","monthly_rain = np.delete(monthly_rain, 0, axis = 0)\n","print(monthly_rain.shape)"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"(156, 3)\n"}],"source":["## monthly Lychee yield 2004 - 2018\n","monthly_lychee = np.array([1,1,1]).reshape(1,3)\n","\n","all_year, sub_year_dic = rain_df_clean.groupby_col('year')\n","\n","for year in all_year:\n","        all_month, _ = sub_year_dic[year].groupby_mean('month')\n","\n","        for month in all_month:\n","                # record year month and lychee yield of each month\n","                monthly_lychee_temp = lychee_yield_df.loc[lychee_yield_df['year']==year,:]\n","                if monthly_lychee_temp.size != 0:\n","                    monthly_yield = np.array([year, month, monthly_lychee_temp.iloc[0, month-1]]).reshape(1,3)\n","                    monthly_lychee = np.append(monthly_lychee, monthly_yield, axis = 0)\n","\n","monthly_lychee = np.delete(monthly_lychee, 0, axis = 0)\n","print(monthly_lychee.shape)"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"[[2006    1 6813]\n [2006    2 6813]\n [2006    3 6813]\n [2006    4 6813]\n [2006    5 6813]\n [2006    6 6813]\n [2006    7 6813]\n [2006    8 6813]\n [2006    9 6813]\n [2006   10 6813]\n [2006   11 6813]\n [2006   12 6813]\n [2007    1 7307]\n [2007    2 7307]\n [2007    3 7307]\n [2007    4 7307]\n [2007    5 7307]\n [2007    6 7307]\n [2007    7 7307]\n [2007    8 7307]\n [2007    9 7307]\n [2007   10 7307]\n [2007   11 7307]\n [2007   12 7307]\n [2008    1 4338]\n [2008    2 4338]\n [2008    3 4338]\n [2008    4 4338]\n [2008    5 4338]\n [2008    6 4338]\n [2008    7 4338]\n [2008    8 4338]\n [2008    9 4338]\n [2008   10 4338]\n [2008   11 4338]\n [2008   12 4338]\n [2009    1 9581]\n [2009    2 9581]\n [2009    3 9581]\n [2009    4 9581]\n [2009    5 9581]\n [2009    6 9581]\n [2009    7 9581]\n [2009    8 9581]\n [2009    9 9581]\n [2009   10 9581]\n [2009   11 9581]\n [2009   12 9581]\n [2010    1 5277]\n [2010    2 5277]\n [2010    3 5277]\n [2010    4 5277]\n [2010    5 5277]\n [2010    6 5277]\n [2010    7 5277]\n [2010    8 5277]\n [2010    9 5277]\n [2010   10 5277]\n [2010   11 5277]\n [2010   12 5277]\n [2011    1 3454]\n [2011    2 3454]\n [2011    3 3454]\n [2011    4 3454]\n [2011    5 3454]\n [2011    6 3454]\n [2011    7 3454]\n [2011    8 3454]\n [2011    9 3454]\n [2011   10 3454]\n [2011   11 3454]\n [2011   12 3454]\n [2012    1 5696]\n [2012    2 5696]\n [2012    3 5696]\n [2012    4 5696]\n [2012    5 5696]\n [2012    6 5696]\n [2012    7 5696]\n [2012    8 5696]\n [2012    9 5696]\n [2012   10 5696]\n [2012   11 5696]\n [2012   12 5696]\n [2013    1 4865]\n [2013    2 4865]\n [2013    3 4865]\n [2013    4 4865]\n [2013    5 4865]\n [2013    6 4865]\n [2013    7 4865]\n [2013    8 4865]\n [2013    9 4865]\n [2013   10 4865]\n [2013   11 4865]\n [2013   12 4865]\n [2014    1 6029]\n [2014    2 6029]\n [2014    3 6029]\n [2014    4 6029]\n [2014    5 6029]\n [2014    6 6029]\n [2014    7 6029]\n [2014    8 6029]\n [2014    9 6029]\n [2014   10 6029]\n [2014   11 6029]\n [2014   12 6029]\n [2015    1 4909]\n [2015    2 4909]\n [2015    3 4909]\n [2015    4 4909]\n [2015    5 4909]\n [2015    6 4909]\n [2015    7 4909]\n [2015    8 4909]\n [2015    9 4909]\n [2015   10 4909]\n [2015   11 4909]\n [2015   12 4909]\n [2016    1 2505]\n [2016    2 2505]\n [2016    3 2505]\n [2016    4 2505]\n [2016    5 2505]\n [2016    6 2505]\n [2016    7 2505]\n [2016    8 2505]\n [2016    9 2505]\n [2016   10 2505]\n [2016   11 2505]\n [2016   12 2505]\n [2017    1 5060]\n [2017    2 5060]\n [2017    3 5060]\n [2017    4 5060]\n [2017    5 5060]\n [2017    6 5060]\n [2017    7 5060]\n [2017    8 5060]\n [2017    9 5060]\n [2017   10 5060]\n [2017   11 5060]\n [2017   12 5060]\n [2018    1 4551]\n [2018    2 4551]\n [2018    3 4551]\n [2018    4 4551]\n [2018    5 4551]\n [2018    6 4551]\n [2018    7 4551]\n [2018    8 4551]\n [2018    9 4551]\n [2018   10 4551]\n [2018   11 4551]\n [2018   12 4551]]\n"}],"source":["## monthly Lychee yield 2004 - 2018 but use yearly yield\n","monthly_lychee_yearlyyield = np.array([1,1,1]).reshape(1,3)\n","\n","all_year, sub_year_dic = rain_df_clean.groupby_col('year')\n","\n","for year in all_year:\n","        all_month, _ = sub_year_dic[year].groupby_mean('month')\n","\n","        for month in all_month:\n","                # record year month and lychee yield of each month\n","                monthly_lychee_temp = lychee_yield_df.loc[lychee_yield_df['year']==year,:]\n","                if monthly_lychee_temp.size != 0:\n","                    monthly_yield = np.array([year, month, monthly_lychee_temp.iloc[0, -2]]).reshape(1,3)\n","                    monthly_lychee_yearlyyield = np.append(monthly_lychee_yearlyyield, monthly_yield, axis = 0)\n","\n","monthly_lychee_yearlyyield = np.delete(monthly_lychee_yearlyyield, 0, axis = 0)\n","print(monthly_lychee_yearlyyield)"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"(156, 3)\n"}],"source":["## monthly yield per area 2006 - 2018\n","monthly_area = np.array([1,1,1]).reshape(1,3)\n","\n","all_year, _ = rain_df_clean.groupby_col('year')\n","for year in all_year:\n","        all_month, _ = sub_year_dic[year].groupby_mean('month')\n","\n","        for month in all_month:\n","                # record year month and lychee yield of each month\n","                monthly_area_temp = area_df.loc[area_df['year']==year,:]\n","                if monthly_area_temp.size != 0:\n","                    monthly_area_temp = np.array([year, month, monthly_area_temp.iloc[0, -1]]).reshape(1,3)\n","                    monthly_area = np.append(monthly_area, monthly_area_temp, axis = 0)\n","\n","monthly_area = np.delete(monthly_area, 0, axis = 0)\n","print(monthly_area.shape)"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"(156, 3)\n"}],"source":["## monthly all yield area 2006 - 2018\n","monthly_yieldarea = np.array([1,1,1]).reshape(1,3)\n","\n","all_year, _ = rain_df_clean.groupby_col('year')\n","\n","for year in all_year:\n","        all_month, _ = sub_year_dic[year].groupby_mean('month')\n","\n","        for month in all_month:\n","                # record year month and lychee yield of each month\n","                monthly_area_temp = area_df.loc[area_df['year']==year,:]\n","                if monthly_area_temp.size != 0:\n","                    monthly_area_temp = np.array([year, month, monthly_area_temp.iloc[0, 4]]).reshape(1,3)\n","                    monthly_yieldarea = np.append(monthly_yieldarea, monthly_area_temp, axis = 0)\n","\n","monthly_yieldarea = np.delete(monthly_yieldarea, 0, axis = 0)\n","print(monthly_area.shape)"]},{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":["<h1> Rearrange for daily data </h1>"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"[[2.006e+03 1.000e+00 1.000e+00 2.140e+01]\n [2.006e+03 1.000e+00 2.000e+00 2.280e+01]\n [2.006e+03 1.000e+00 3.000e+00 2.580e+01]\n [2.006e+03 1.000e+00 4.000e+00 2.570e+01]\n [2.006e+03 1.000e+00 5.000e+00 2.860e+01]\n [2.006e+03 1.000e+00 6.000e+00 2.870e+01]]\n"}],"source":["## daily Temp 2006 - 2019\n","daily_temp = np.array([1,1,1,1]).reshape(1,4)\n","\n","# get yearly dic\n","all_year, sub_year_dic = temp_df_clean.groupby_col('year')\n","\n","for year in all_year:\n","        # get monthly dic\n","        all_month, sub_month_dic = sub_year_dic[year].groupby_col('month')\n","\n","        for month in all_month:\n","            # get daily dic\n","            all_day, sub_day_dic = sub_month_dic[month].groupby_mean('day')       \n","\n","            for day in all_day:\n","                # get daily dataframe\n","                sub_day_df = sub_day_dic[day]\n","                daily_tempo = np.array([year, month, day, sub_day_df.iloc[-1]]).reshape(1,4)\n","                daily_temp = np.append(daily_temp, daily_tempo, axis = 0)\n","\n","daily_temp = np.delete(daily_temp, 0, axis = 0)\n","print(daily_temp[:6, :])"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"(5051, 4)\n"}],"source":["## daily humid 2006 - 2019\n","daily_humid = np.array([1,1,1,1]).reshape(1,4)\n","\n","# get yearly dic\n","all_year, sub_year_dic = humid_df_clean.groupby_col('year')\n","\n","for year in all_year:\n","        # get monthly dic\n","        all_month, sub_month_dic = sub_year_dic[year].groupby_col('month')\n","\n","        for month in all_month:\n","            # get daily dic\n","            all_day, sub_day_dic = sub_month_dic[month].groupby_mean('day')       \n","\n","            for day in all_day:\n","                # get daily dataframe\n","                sub_day_df = sub_day_dic[day]\n","                daily_tempo = np.array([year, month, day, sub_day_df.iloc[-1]]).reshape(1,4)\n","                daily_humid = np.append(daily_humid, daily_tempo, axis = 0)\n","\n","daily_humid = np.delete(daily_humid, 0, axis = 0)\n","print(daily_humid.shape)"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"(5051, 4)\n"}],"source":["## daily rain 2006 - 2019\n","daily_rain = np.array([1,1,1,1]).reshape(1,4)\n","\n","# get yearly dic\n","all_year, sub_year_dic = rain_df_clean.groupby_col('year')\n","\n","for year in all_year:\n","        # get monthly dic\n","        all_month, sub_month_dic = sub_year_dic[year].groupby_col('month')\n","\n","        for month in all_month:\n","            # get daily dic\n","            all_day, sub_day_dic = sub_month_dic[month].groupby_mean('day')       \n","\n","            for day in all_day:\n","                # get daily dataframe\n","                sub_day_df = sub_day_dic[day]\n","                daily_tempo = np.array([year, month, day, sub_day_df.iloc[-1]]).reshape(1,4)\n","                daily_rain = np.append(daily_rain, daily_tempo, axis = 0)\n","\n","daily_rain = np.delete(daily_rain, 0, axis = 0)\n","print(daily_rain.shape)"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"[[2006    1    1 6813]\n [2006    1    2 6813]\n [2006    1    3 6813]\n [2006    1    4 6813]\n [2006    1    5 6813]\n [2006    1    6 6813]]\n"}],"source":["## daily Lychee yield 2006 - 2018\n","daily_lychee = np.array([1,1,1,1]).reshape(1,4)\n","\n","all_year, sub_year_dic = rain_df_clean.groupby_col('year')\n","\n","for year in all_year:\n","        all_month, sub_month_dic = sub_year_dic[year].groupby_col('month')\n","        # record year month and lychee yield of each month\n","        daily_lychee_temp = lychee_yield_df.loc[lychee_yield_df['year']==year,:]\n","\n","        for month in all_month:\n","\n","                # get daily dic\n","                all_day, _ = sub_month_dic[month].groupby_mean('day')       \n","\n","                for day in all_day:    \n","\n","                    if daily_lychee_temp.size != 0:\n","                        # print(year, ' : ', month)\n","                        # print(daily_lychee_temp.iloc[0, month-1])\n","                        daily_yield = np.array([year, month, day, daily_lychee_temp.iloc[0, month-1]]).reshape(1,4)\n","                        daily_lychee = np.append(daily_lychee, daily_yield, axis = 0)\n","\n","daily_lychee = np.delete(daily_lychee, 0, axis = 0)\n","print(daily_lychee[:6, :])"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"[[2006    1    1 6813]\n [2006    1    2 6813]\n [2006    1    3 6813]\n [2006    1    4 6813]\n [2006    1    5 6813]\n [2006    1    6 6813]]\n"}],"source":["## daily Lychee yield 2006 - 2018 yearlyyield\n","daily_lychee_yearlyyield = np.array([1,1,1,1]).reshape(1,4)\n","all_year, sub_year_dic = rain_df_clean.groupby_col('year')\n","\n","for year in all_year:\n","        all_month, sub_month_dic = sub_year_dic[year].groupby_col('month')\n","        # record year month and lychee yield of each month\n","        daily_lychee_temp = lychee_yield_df.loc[lychee_yield_df['year']==year,:]\n","\n","        for month in all_month:\n","\n","                # get daily dic\n","                all_day, _ = sub_month_dic[month].groupby_mean('day')       \n","\n","                for day in all_day:    \n","\n","                    if daily_lychee_temp.size != 0:\n","                        # print(year, ' : ', month)\n","                        # print(daily_lychee_temp.iloc[0, month-1])\n","                        daily_yield = np.array([year, month, day, daily_lychee_temp.iloc[0, -2]]).reshape(1,4)\n","                        daily_lychee_yearlyyield = np.append(daily_lychee_yearlyyield, daily_yield, axis = 0)\n","\n","daily_lychee_yearlyyield = np.delete(daily_lychee_yearlyyield, 0, axis = 0)\n","print(daily_lychee_yearlyyield[:6, :])"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"(4748, 4)\n"}],"source":["## daily yield per area 2006 - 2018\n","daily_area = np.array([1,1,1,1]).reshape(1,4)\n","\n","all_year, sub_year_dic = rain_df_clean.groupby_col('year')\n","\n","for year in all_year:\n","        all_month, sub_month_dic = sub_year_dic[year].groupby_col('month')\n","        # record year month and lychee yield of each month\n","        area_temp = area_df.loc[area_df['year']==year,:]        \n","\n","        for month in all_month:\n","\n","                # get daily dic\n","                all_day, _ = sub_month_dic[month].groupby_mean('day')       \n","\n","                for day in all_day:    \n","\n","                    if area_temp.size != 0:\n","                        daily_area_temp = np.array([year, month, day, area_temp.iloc[0, -1]]).reshape(1,4)\n","                        daily_area = np.append(daily_area, daily_area_temp, axis = 0)\n","\n","daily_area = np.delete(daily_area, 0, axis = 0)\n","print(daily_area.shape)"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"(4748, 4)\n"}],"source":["## daily yield per area 2006 - 2018\n","daily_yieldarea = np.array([1,1,1,1]).reshape(1,4)\n","\n","all_year, sub_year_dic = rain_df_clean.groupby_col('year')\n","\n","for year in all_year:\n","        all_month, sub_month_dic = sub_year_dic[year].groupby_col('month')\n","        # record year month and lychee yield of each month\n","        area_temp = area_df.loc[area_df['year']==year,:]        \n","\n","        for month in all_month:\n","\n","                # get daily dic\n","                all_day, _ = sub_month_dic[month].groupby_mean('day')       \n","\n","                for day in all_day:    \n","\n","                    if area_temp.size != 0:\n","                        daily_area_temp = np.array([year, month, day, area_temp.iloc[0, 4]]).reshape(1,4)\n","                        daily_yieldarea = np.append(daily_yieldarea, daily_area_temp, axis = 0)\n","\n","daily_yieldarea = np.delete(daily_yieldarea, 0, axis = 0)\n","print(daily_yieldarea.shape)"]},{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":["<h1> Rearrange for 3-hourly data </h1>"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["## hourly Temp 2004 - 2019\n","threehourly_temp = np.array([1,1,1,1,1]).reshape(1,5)\n","\n","# get yearly dic\n","all_year, sub_year_dic = temp_df_clean.groupby_col('year')\n","\n","for year in all_year:\n","        # get monthly dic\n","        all_month, sub_month_dic = sub_year_dic[year].groupby_col('month')\n","\n","        for month in all_month:\n","            # get daily dic\n","            all_day, sub_day_dic = sub_month_dic[month].groupby_col('day')       \n","\n","            for day in all_day:\n","                # get daily dataframe\n","                sub_day_df = sub_day_dic[day]\n","\n","                for hour in ['1', '4', '7', '10', '13', '16', '19', '22']:\n","                    threehourly_tempo = np.array([year, month, day, int(hour), sub_day_df[hour]]).reshape(1,5)\n","                    threehourly_temp = np.append(threehourly_temp, threehourly_tempo, axis = 0)\n","\n","threehourly_temp = np.delete(threehourly_temp, 0, axis = 0)\n","print(threehourly_temp.shape)"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["## hourly Humid 2004 - 2019\n","threehourly_humid = np.array([1,1,1,1,1]).reshape(1,5)\n","\n","# get yearly dic\n","all_year, sub_year_dic = humid_df_clean.groupby_col('year')\n","\n","for year in all_year:\n","        # get monthly dic\n","        all_month, sub_month_dic = sub_year_dic[year].groupby_col('month')\n","\n","        for month in all_month:\n","            # get daily dic\n","            all_day, sub_day_dic = sub_month_dic[month].groupby_col('day')       \n","\n","            for day in all_day:\n","                # get daily dataframe\n","                sub_day_df = sub_day_dic[day]\n","\n","                for hour in ['1', '4', '7', '10', '13', '16', '19', '22']:\n","                    threehourly_tempo = np.array([year, month, day, int(hour), sub_day_df[hour]]).reshape(1,5)\n","                    threehourly_humid = np.append(threehourly_humid, threehourly_tempo, axis = 0)\n","\n","threehourly_humid = np.delete(threehourly_humid, 0, axis = 0)\n","print(threehourly_humid.shape)"]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[],"source":["## hourly Rain 2004 - 2019\n","threehourly_rain = np.array([1,1,1,1,1]).reshape(1,5)\n","\n","# get yearly dic\n","all_year, sub_year_dic = rain_df_clean.groupby_col('year')\n","\n","for year in all_year:\n","        # get monthly dic\n","        all_month, sub_month_dic = sub_year_dic[year].groupby_col('month')\n","\n","        for month in all_month:\n","            # get daily dic\n","            all_day, sub_day_dic = sub_month_dic[month].groupby_col('day')       \n","\n","            for day in all_day:\n","                # get daily dataframe\n","                sub_day_df = sub_day_dic[day]\n","\n","                for hour in ['1', '4', '7', '10', '13', '16', '19', '22']:\n","                    threehourly_tempo = np.array([year, month, day, int(hour), sub_day_df[hour]]).reshape(1,5)\n","                    threehourly_rain = np.append(threehourly_rain, threehourly_tempo, axis = 0)\n","\n","threehourly_rain = np.delete(threehourly_rain, 0, axis = 0)\n","print(threehourly_rain.shape)"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[],"source":["## hourly Lychee yield 2004 - 2018\n","threehourly_lychee = np.array([1,1,1,1,1]).reshape(1,5)\n","\n","all_year, sub_year_dic = rain_df_clean.groupby_col('year')\n","\n","for year in all_year:\n","    all_month, sub_month_dic = sub_year_dic[year].groupby_col('month')\n","    monthly_lychee_temp = lychee_yield_df.loc[lychee_yield_df['year']==year,:]\n","\n","    for month in all_month:\n","        # get daily dic\n","        all_day, _ = sub_month_dic[month].groupby_col('day')       \n","\n","        for day in all_day:                \n","            for hour in ['1', '4', '7', '10', '13', '16', '19', '22']:\n","                if monthly_lychee_temp.size != 0:\n","                    threehourly_yield = np.array([year, month, day, int(hour), monthly_lychee_temp.iloc[0, month-1]]).reshape(1,5)\n","                    threehourly_lychee = np.append(threehourly_lychee, threehourly_yield, axis = 0)\n","\n","threehourly_lychee = np.delete(threehourly_lychee, 0, axis = 0)\n","print(threehourly_lychee.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## hourly Lychee yield 2004 - 2018 yearlyyield\n","threehourly_lychee_lycheeyield = np.array([1,1,1,1,1]).reshape(1,5)\n","\n","all_year, sub_year_dic = rain_df_clean.groupby_col('year')\n","\n","for year in all_year:\n","    all_month, sub_month_dic = sub_year_dic[year].groupby_col('month')\n","    monthly_lychee_temp = lychee_yield_df.loc[lychee_yield_df['year']==year,:]\n","\n","    for month in all_month:\n","        # get daily dic\n","        all_day, _ = sub_month_dic[month].groupby_col('day')       \n","\n","        for day in all_day:                \n","            for hour in ['1', '4', '7', '10', '13', '16', '19', '22']:\n","                if monthly_lychee_temp.size != 0:\n","                    threehourly_yield = np.array([year, month, day, int(hour), monthly_lychee_temp.iloc[0, month-1]]).reshape(1,5)\n","                    threehourly_lychee_lycheeyield = np.append(threehourly_lychee_lycheeyield, threehourly_yield, axis = 0)\n","\n","threehourly_lychee_lycheeyield = np.delete(threehourly_lychee_lycheeyield, 0, axis = 0)\n","print(threehourly_lychee_lycheeyield[:6,:])"]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[],"source":["## hourly yield per area 2004 - 2018\n","threehourly_area = np.array([1,1,1,1,1]).reshape(1,5)\n","\n","all_year, sub_year_dic = rain_df_clean.groupby_col('year')\n","\n","for year in all_year:\n","    all_month, sub_month_dic    = sub_year_dic[year].groupby_col('month')\n","    monthly_area_temp         = area_df.loc[area_df['year']==year,:]\n","\n","    for month in all_month:\n","        # get daily dic\n","        all_day, _ = sub_month_dic[month].groupby_col('day')       \n","\n","        for day in all_day:                \n","            for hour in ['1', '4', '7', '10', '13', '16', '19', '22']:\n","                if monthly_area_temp.size != 0:\n","                    threehourly_area_temp = np.array([year, month, day, int(hour), monthly_area_temp.iloc[0, -1]]).reshape(1,5)\n","                    threehourly_area = np.append(threehourly_area, threehourly_area_temp, axis = 0)\n","\n","threehourly_area = np.delete(threehourly_area, 0, axis = 0)\n","print(threehourly_area.shape)"]},{"cell_type":"code","execution_count":39,"metadata":{},"outputs":[],"source":["## hourly all area 2004 - 2018\n","threehourly_yieldarea = np.array([1,1,1,1,1]).reshape(1,5)\n","\n","all_year, sub_year_dic = rain_df_clean.groupby_col('year')\n","\n","for year in all_year:\n","    all_month, sub_month_dic    = sub_year_dic[year].groupby_col('month')\n","    monthly_area_temp           = area_df.loc[area_df['year']==year,:]\n","\n","    for month in all_month:\n","        # get daily dic\n","        all_day, _ = sub_month_dic[month].groupby_col('day')       \n","\n","        for day in all_day:                \n","            for hour in ['1', '4', '7', '10', '13', '16', '19', '22']:\n","                if monthly_area_temp.size != 0:\n","                    threehourly_area_temp = np.array([year, month, day, int(hour), monthly_area_temp.iloc[0, 4]]).reshape(1,5)\n","                    threehourly_yieldarea = np.append(threehourly_yieldarea, threehourly_area_temp, axis = 0)\n","\n","threehourly_yieldarea = np.delete(threehourly_yieldarea, 0, axis = 0)\n","print(threehourly_yieldarea.shape)"]},{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":["Intersected\n"," year of all data is 2004 - 2018"]},{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":["<h1> Method for getting X data </h1>"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[],"source":["def split_x_sequence(X, n_steps, ind_output):\n","    \n","    X_seq = np.ones((1, n_steps))\n","\n","    for i in range(X.shape[0]):\n","        \n","        if i+n_steps > X.shape[0] - 1:\n","            break\n","        x_seq_temp = X[i:i+n_steps, ind_output].reshape(1,-1)\n","        X_seq = np.append(X_seq, x_seq_temp, axis = 0)\n","    \n","    return X_seq[1:,:]\n","\n","def split_y_sequence(X, n_steps, ind_output, repeat):\n","    \n","    # repeat = False return only target\n","    # repeat = true return target with multiple row\n","    X_seq = np.ones((1, 1)) if repeat == False else np.ones((1, n_steps))\n","\n","    for i in range(X.shape[0]):\n","        \n","        if i+n_steps > X.shape[0] - 1:\n","            break\n","        x_seq_temp = X[i+n_steps, ind_output].reshape(1, -1) if repeat == False else  X[i+n_steps, ind_output]*np.ones((1, n_steps))\n","        X_seq = np.append(X_seq, x_seq_temp, axis = 0)\n","    \n","    return X_seq[1:,:]"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[],"source":["def get_XY_fr_resolution(df_list_input, df_list_output, n_steps, req_m_input = [1, 2], req_month = [4, 5, 6], axis = 1, yearlyyield = False):\n","\n","    df_copy_list  = list()\n","    X             = list()\n","\n","    # extract X\n","    count = 0\n","    for df, xy_split in df_list_input:\n","        df_copy = df.copy()\n","        ind_2004_2018 = np.logical_and(df_copy[:, 0] >= 2004, df_copy[:, 0] <= 2018)\n","        df_copy = df_copy[ind_2004_2018,:]\n","\n","        # find index only for required input month\n","        if yearlyyield and count == 0:\n","            count = count + 1\n","            req_m_ind = np.zeros((df_copy.shape[0],))\n","            for i in req_m_input:\n","                req_m_ind = np.logical_or(req_m_ind, (df_copy[:,1] == i).reshape(-1,))\n","\n","        df_copy = df_copy[req_m_ind, :]\n","\n","        if xy_split == 'x':\n","            X_temp = split_x_sequence(df_copy, n_steps, -1)\n","            print('true')\n","            print(X_temp.shape)\n","        if xy_split == 'y':\n","            X_temp = split_y_sequence(df_copy, n_steps, -1, True) if axis == 2 else split_y_sequence(df_copy, n_steps, -1, False)\n","      \n","        X_temp = X_temp.reshape(X_temp.shape[0], X_temp.shape[1], 1)\n","        X.append(X_temp)\n","\n","    # axis = 2 for rnn and axis = 1 for lr and svr\n","    X = np.concatenate(X, axis = axis)\n","\n","    # extract y\n","    Y = split_y_sequence(df_list_output[0], n_steps, -1, False) if yearlyyield == False else split_y_sequence(df_list_output[0][req_m_ind, :], n_steps, -1, False)  \n","\n","    # get only the data from required month\n","    all_year    = np.unique(df_copy[:, 0])\n","    all_month   = np.unique(df_copy[:, 1]) if yearlyyield == False else np.array([])\n","    req_ind     = np.zeros((X_temp.shape[0], 1))\n","    for year in all_year:\n","        for month in req_month:\n","            year_ind = df_copy[n_steps:, 0] == year\n","            \n","            if yearlyyield == False:\n","                month_ind = df_copy[n_steps:, 1] == month\n","                ym_ind = year_ind*month_ind\n","            else:\n","                ym_ind = year_ind\n","\n","            ym_ind_where = np.where(ym_ind == 1)\n","            \n","            if len(ym_ind_where[0]) != 0:\n","                if yearlyyield == False:\n","                    # get only the data from required month only at the first index\n","                    first_ind = ym_ind_where[0][0]\n","\n","                else:\n","                    # get only the data from the last index of each year\n","                    first_ind = ym_ind_where[0][0]                  \n","\n","                ym_ind = np.zeros((ym_ind.shape[0], 1))\n","                \n","                try:\n","                    ym_ind[first_ind] = 1\n","                except:\n","                    pass\n","\n","                ym_ind  = ym_ind.reshape(-1, 1)\n","                req_ind = req_ind + ym_ind\n","\n","    req_ind = req_ind.astype(bool).reshape(-1)\n","    X = X[req_ind, :, :]\n","    Y = Y[req_ind]\n","    if axis == 1:\n","        X = X.reshape(X.shape[0], X.shape[1])\n","        Y = Y.reshape(Y.shape[0])\n","\n","    n_features = X.shape[2] if axis == 2 else X.shape[1]\n","    n_size      = X.shape[0]\n","\n","    year_target = df_copy[n_steps:, 0][req_ind]\n","    month_target = df_copy[n_steps:, 1][req_ind] if yearlyyield == False else np.array([])\n","\n","    return X, Y, n_features, n_size, n_steps, year_target, month_target"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[],"source":["def rmse(y_true, y_pred):\n","\n","    ind_ignorezero = (y_true != 0).reshape(-1,)\n","    error = (y_true - y_pred)\n","    se = error**2\n","    mse = np.mean(se)\n","    rmse = mse**0.5\n","    return rmse"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[],"source":["def mape(y_true, y_pred):\n","    error = y_true - y_pred\n","    pe     = (y_true - y_pred)/y_true*100\n","    ape = np.abs(pe)\n","    mape = np.mean(ape)\n","\n","    return mape    "]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[],"source":["def mae(y_true, y_pred):\n","\n","    error = y_true - y_pred\n","    ae = np.abs(error)\n","    mae = np.mean(ae)\n","\n","    return mae"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[],"source":["def r2(y_true, y_pred):\n","    y_mean  = np.mean(y_true)\n","    Stot    = np.sum((y_true - y_mean)**2)\n","    Sres    = np.sum((y_true - y_pred)**2)\n","    r_square    = 1 - Sres/Stot\n","\n","    return r_square"]},{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":["Get y"]},{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":["<h1> Feature selection </h1>\n","Year (of the target), Month (of the target), Avg.Temp (3 and 4 month before), Avg.Humid (3 and 4 month before),\n","Rain amount (3 and 4 month before), lychee yield per area (1 year before), number of the day in target month,\n","lychee yield (of target month but 1 year before)"]},{"cell_type":"code","execution_count":79,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"true\n(24, 2)\n"}],"source":["choose = 'monthly_yearlyyield_wyear'\n","\n","if choose == 'monthly_yearlyyield_wyear':\n","    yearlyyield = True\n","    input_vec = [\n","        [monthly_temp, 'x'],\n","        # [monthly_humid, 'x'], \n","        # [monthly_rain, 'x'], \n","        # [monthly_area, 'x'], \n","        # [monthly_yieldarea, 'x'], \n","        # [monthly_lychee, 'x'],\n","        [monthly_yieldarea[:,0].reshape(-1,1), 'y']]   # target year\n","\n","    output_vec = [monthly_lychee_yearlyyield]\n","\n","if choose == 'monthly_yearlyyield_woyear':\n","    yearlyyield = True\n","    input_vec = [\n","        [monthly_temp, 'x'],\n","        # [monthly_humid, 'x'], \n","        # [monthly_rain, 'x'], \n","        # [monthly_area, 'x'], \n","        # [monthly_yieldarea, 'x'], \n","        # [monthly_lychee, 'x'],\n","        ]#[monthly_yieldarea[:,0].reshape(-1,1), 'y']]   # target year\n","\n","    output_vec = [monthly_lychee_yearlyyield]\n","\n","if choose == 'test':\n","    input_vec = [\n","        [daily_temp, 'x'], \n","        [daily_yieldarea[:,0].reshape(-1,1), 'y'],   # target year\n","        [daily_yieldarea[:,0:2].reshape(-1,2), 'y']] # target month\n","\n","    output_vec = [daily_lychee]\n","\n","if choose == 'monthly':\n","    yearlyyield = False\n","    input_vec = [\n","        [monthly_temp, 'x'],\n","        # [monthly_humid, 'x'], \n","        # [monthly_rain, 'x'], \n","        # [monthly_area, 'x'], \n","        [monthly_yieldarea, 'x'], \n","        [monthly_lychee, 'x'], \n","        [monthly_yieldarea[:,0].reshape(-1,1), 'y'],   # target year\n","        [monthly_yieldarea[:,0:2].reshape(-1,2), 'y']] # target month\n","    \n","    output_vec = [monthly_lychee]\n","\n","if choose == 'daily':\n","    yearlyyield = False\n","    input_vec = [\n","        [daily_temp, 'x'],\n","        [daily_humid, 'x'], \n","        # [daily_rain, 'x'], \n","        # [daily_area, 'x'], \n","        # [daily_yieldarea, 'x'], \n","        [daily_lychee, 'x'], \n","        [daily_yieldarea[:,0].reshape(-1,1), 'y'],   # target year\n","        [daily_yieldarea[:,0:2].reshape(-1,2), 'y']] # target month\n","\n","    output_vec = [daily_lychee]\n","\n","if choose == 'hourly':\n","    yearlyyield = False\n","    input_vec = [\n","        [hourly_temp, 'x'],\n","        # [hourly_humid, 'x'], \n","        # [hourly_rain, 'x'], \n","        # [hourly_area, 'x'], \n","        [hourly_yieldarea, 'x'], \n","        [hourly_lychee, 'x'], \n","        [hourly_yieldarea[:,0].reshape(-1,1), 'y'],   # target year\n","        [hourly_yieldarea[:,0:2].reshape(-1,2), 'y']] # target month\n","\n","    output_vec = [hourly_lychee]\n","\n","# daily choose n_steps = 240\n","# hourly choose n_steps = 1920\n","# monthly choose n_steps = 4\n","# axis = 2 for rnn\n","\n","X, Y, n_features, n_size, n_steps, year_target, month_target = get_XY_fr_resolution(input_vec, output_vec, n_steps = 2, axis = 1, req_m_input = [1, 2], req_month = [4, 5, 6], yearlyyield = yearlyyield)"]},{"cell_type":"code","execution_count":80,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"X Shape\n(12, 3)\nY Shape\n(12,)\nn features\n3\nsample size\n12\n"}],"source":["print('X Shape')\n","print(X.shape)\n","print('Y Shape')\n","print(Y.shape)\n","print('n features')\n","print(n_features)\n","print('sample size')\n","print(n_size)"]},{"cell_type":"code","execution_count":81,"metadata":{},"outputs":[],"source":["# print(X)"]},{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":["Seperate train set and test set for displaying"]},{"cell_type":"code","execution_count":82,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"train size\n(8, 3)\ntest size\n(4, 3)\n"}],"source":["X_train, X_test, Y_train, Y_test =  train_test_split(X, Y, test_size=0.3)\n","X_train_ord = X[:int(n_size*(1-0.3)), :]\n","X_test_ord  = X[int(n_size*(1-0.3)):, :]\n","Y_train_ord = Y[:int(n_size*(1-0.3))]\n","Y_test_ord  = Y[int(n_size*(1-0.3)):]\n","print('train size')\n","print(X_train.shape)\n","print('test size')\n","print(X_test.shape)"]},{"cell_type":"markdown","execution_count":216,"metadata":{},"outputs":[],"source":["<h1> Ridge Model w/o Normalization </h1>"]},{"cell_type":"code","execution_count":83,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"(12, 3)\nRidge(alpha=100, copy_X=True, fit_intercept=True, max_iter=None,\n   normalize=False, random_state=None, solver='auto', tol=0.001)\n"}],"source":["# vector for record error\n","train_mae = np.array([])\n","test_mae = np.array([])\n","\n","train_rmse = np.array([])\n","test_rmse = np.array([])\n","\n","train_r2 = np.array([])\n","test_r2 = np.array([])\n","\n","# using grid searchcv to optimize hyper param\n","reg_lr  = Ridge()\n","param   = {'alpha':[0.01, 0.001, 0.1, 0.5, 1, 5, 10, 100, 200, 300, 400, 1000, 10e4, 10e5]}\n","gsc     = GridSearchCV(reg_lr, param, cv = 3)\n","print(X.shape)\n","gsc.fit(X, np.log1p(Y))\n","\n","reg_lr  = gsc.best_estimator_\n","print(gsc.best_estimator_)"]},{"cell_type":"code","execution_count":84,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"train MAE 1335.38\ttest MAE 1018.48\ntrain RMSE 1747.48\ttest RMSE 1453.48\ntrain MAPE 23.29\ttest MAPE 34.63\n=========================\nyear 2007 true : 7307\tpred : 5767\nyear 2008 true : 4338\tpred : 5733\nyear 2009 true : 9581\tpred : 5710\nyear 2010 true : 5277\tpred : 5633\nyear 2011 true : 3454\tpred : 5483\nyear 2012 true : 5696\tpred : 5496\nyear 2013 true : 4865\tpred : 5437\nyear 2014 true : 6029\tpred : 5309\nyear 2015 true : 4909\tpred : 5377\nyear 2016 true : 2505\tpred : 5302\nyear 2017 true : 5060\tpred : 5263\nyear 2018 true : 4551\tpred : 5157\n"}],"source":["reg_lr.fit(X_train_ord, np.log1p(Y_train_ord))\n","\n","Y_all_test = reg_lr.predict(X)\n","Y_all_test[Y_all_test<0] = 0\n","\n","Y_all_test = np.expm1(Y_all_test)\n","\n","train_mae = mae(Y[:int(n_size*(1-0.3))], Y_all_test[:int(n_size*(1-0.3))])\n","test_mae = mae(Y[int(n_size*(1-0.3)):], Y_all_test[int(n_size*(1-0.3)):])\n","\n","train_rmse = rmse(Y[:int(n_size*(1-0.3))], Y_all_test[:int(n_size*(1-0.3))])\n","test_rmse = rmse(Y[int(n_size*(1-0.3)):], Y_all_test[int(n_size*(1-0.3)):])\n","\n","train_mape = mape(Y[:int(n_size*(1-0.3))], Y_all_test[:int(n_size*(1-0.3))])\n","test_mape = mape(Y[int(n_size*(1-0.3)):], Y_all_test[int(n_size*(1-0.3)):])\n","\n","print('train MAE {:.2f}\\ttest MAE {:.2f}'.format(train_mae, test_mae))\n","print('train RMSE {:.2f}\\ttest RMSE {:.2f}'.format(train_rmse, test_rmse))\n","print('train MAPE {:.2f}\\ttest MAPE {:.2f}'.format(train_mape, test_mape))\n","print('=========================')\n","\n","if yearlyyield == False:\n","    for year, month, y_true, y_pred in zip(year_target, month_target, Y, Y_all_test):\n","        print('year {:.0f} month {:.0f} true : {:.0f}\\tpred : {:.0f}'.format(year, month, y_true, y_pred))\n","else:\n","    for year, y_true, y_pred in zip(year_target, Y, Y_all_test):\n","        print('year {:.0f} true : {:.0f}\\tpred : {:.0f}'.format(year, y_true, y_pred))   "]},{"cell_type":"code","execution_count":49,"metadata":{},"outputs":[],"source":["# export output\n","# X_rnn[:int(train_ratio*n_size), :, :]\n","year_train  = year_target[:int(n_size*(1-0.3))]\n","month_train = month_target[:int(n_size*(1-0.3))] if yearlyyield == False else year_train\n","year_test   = year_target[int(n_size*(1-0.3)):]\n","month_test  = month_target[int(n_size*(1-0.3)):] if yearlyyield == False else year_test\n","y_train_true = Y[:int(n_size*(1-0.3))]\n","y_train_pred = Y_all_test[:int(n_size*(1-0.3))]\n","y_test_true = Y[int(n_size*(1-0.3)):]\n","y_test_pred = Y_all_test[int(n_size*(1-0.3)):]\n","export_output('ridge_wonorm_results_monthly_input_yearly_output.xlsx', year_train, month_train, y_train_true, y_train_pred, year_test, month_test, y_test_true, y_test_pred)"]},{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":["<h1> Ridge Model w Normalization </h1>"]},{"cell_type":"code","execution_count":106,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\stats\\morestats.py:902: RuntimeWarning: divide by zero encountered in log\n  llf -= N / 2.0 * np.log(np.sum((y - y_mean)**2. / N, axis=0))\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\stats\\morestats.py:902: RuntimeWarning: divide by zero encountered in log\n  llf -= N / 2.0 * np.log(np.sum((y - y_mean)**2. / N, axis=0))\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\stats\\morestats.py:902: RuntimeWarning: divide by zero encountered in log\n  llf -= N / 2.0 * np.log(np.sum((y - y_mean)**2. / N, axis=0))\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\stats\\morestats.py:902: RuntimeWarning: divide by zero encountered in log\n  llf -= N / 2.0 * np.log(np.sum((y - y_mean)**2. / N, axis=0))\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\stats\\morestats.py:902: RuntimeWarning: divide by zero encountered in log\n  llf -= N / 2.0 * np.log(np.sum((y - y_mean)**2. / N, axis=0))\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\stats\\morestats.py:902: RuntimeWarning: divide by zero encountered in log\n  llf -= N / 2.0 * np.log(np.sum((y - y_mean)**2. / N, axis=0))\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\stats\\morestats.py:902: RuntimeWarning: divide by zero encountered in log\n  llf -= N / 2.0 * np.log(np.sum((y - y_mean)**2. / N, axis=0))\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\stats\\morestats.py:902: RuntimeWarning: divide by zero encountered in log\n  llf -= N / 2.0 * np.log(np.sum((y - y_mean)**2. / N, axis=0))\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\stats\\morestats.py:902: RuntimeWarning: divide by zero encountered in log\n  llf -= N / 2.0 * np.log(np.sum((y - y_mean)**2. / N, axis=0))\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\stats\\morestats.py:902: RuntimeWarning: divide by zero encountered in log\n  llf -= N / 2.0 * np.log(np.sum((y - y_mean)**2. / N, axis=0))\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\stats\\morestats.py:902: RuntimeWarning: divide by zero encountered in log\n  llf -= N / 2.0 * np.log(np.sum((y - y_mean)**2. / N, axis=0))\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\stats\\morestats.py:902: RuntimeWarning: divide by zero encountered in log\n  llf -= N / 2.0 * np.log(np.sum((y - y_mean)**2. / N, axis=0))\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\stats\\morestats.py:902: RuntimeWarning: divide by zero encountered in log\n  llf -= N / 2.0 * np.log(np.sum((y - y_mean)**2. / N, axis=0))\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\stats\\morestats.py:902: RuntimeWarning: divide by zero encountered in log\n  llf -= N / 2.0 * np.log(np.sum((y - y_mean)**2. / N, axis=0))\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\stats\\morestats.py:902: RuntimeWarning: divide by zero encountered in log\n  llf -= N / 2.0 * np.log(np.sum((y - y_mean)**2. / N, axis=0))\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\stats\\morestats.py:902: RuntimeWarning: divide by zero encountered in log\n  llf -= N / 2.0 * np.log(np.sum((y - y_mean)**2. / N, axis=0))\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\stats\\morestats.py:902: RuntimeWarning: divide by zero encountered in log\n  llf -= N / 2.0 * np.log(np.sum((y - y_mean)**2. / N, axis=0))\nPipeline(memory=None,\n     steps=[('normalize', PowerTransformer(copy=True, method='box-cox', standardize=True)), ('lr', Ridge(alpha=100000.0, copy_X=True, fit_intercept=True, max_iter=None,\n   normalize=False, random_state=None, solver='auto', tol=0.001))])\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\stats\\morestats.py:902: RuntimeWarning: divide by zero encountered in log\n  llf -= N / 2.0 * np.log(np.sum((y - y_mean)**2. / N, axis=0))\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\stats\\morestats.py:902: RuntimeWarning: divide by zero encountered in log\n  llf -= N / 2.0 * np.log(np.sum((y - y_mean)**2. / N, axis=0))\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\stats\\morestats.py:902: RuntimeWarning: divide by zero encountered in log\n  llf -= N / 2.0 * np.log(np.sum((y - y_mean)**2. / N, axis=0))\n"}],"source":["# vector for record error\n","train_mae = np.array([])\n","test_mae = np.array([])\n","\n","train_rmse = np.array([])\n","test_rmse = np.array([])\n","\n","train_r2 = np.array([])\n","test_r2 = np.array([])\n","\n","# using grid searchcv to optimize hyper param\n","estimators = [('normalize', PCA()), ('lr', Ridge())]\n","pipe    = Pipeline(estimators)\n","param   = dict(lr__alpha=[0.01, 0.001, 0.1, 0.5, 1, 5, 10, 100, 10e3, 10e4])\n","\n","gsc     = GridSearchCV(pipe, param, cv = 3)\n","gsc.fit(X, np.log1p(Y))\n","\n","reg_lr_norm  = gsc.best_estimator_\n","print(gsc.best_estimator_)"]},{"cell_type":"code","execution_count":107,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"train MAE 1334.88\ttest MAE 1312.42\ntrain RMSE 1799.78\ttest RMSE 1667.01\ntrain MAPE 23.14\ttest MAPE 42.04\n=========================\nyear 2007 true : 7307\tpred : 5569\nyear 2008 true : 4338\tpred : 5569\nyear 2009 true : 9581\tpred : 5569\nyear 2010 true : 5277\tpred : 5569\nyear 2011 true : 3454\tpred : 5569\nyear 2012 true : 5696\tpred : 5569\nyear 2013 true : 4865\tpred : 5569\nyear 2014 true : 6029\tpred : 5569\nyear 2015 true : 4909\tpred : 5569\nyear 2016 true : 2505\tpred : 5569\nyear 2017 true : 5060\tpred : 5569\nyear 2018 true : 4551\tpred : 5569\n"}],"source":["reg_lr_norm.fit(X_train_ord, np.log1p(Y_train_ord))\n","\n","Y_all_test = reg_lr_norm.predict(X)\n","Y_all_test[Y_all_test<0] = 0\n","Y_all_test = np.expm1(Y_all_test)\n","\n","train_mae = mae(Y[:int(n_size*(1-0.3))], Y_all_test[:int(n_size*(1-0.3))])\n","test_mae = mae(Y[int(n_size*(1-0.3)):], Y_all_test[int(n_size*(1-0.3)):])\n","\n","train_rmse = rmse(Y[:int(n_size*(1-0.3))], Y_all_test[:int(n_size*(1-0.3))])\n","test_rmse = rmse(Y[int(n_size*(1-0.3)):], Y_all_test[int(n_size*(1-0.3)):])\n","\n","train_mape = mape(Y[:int(n_size*(1-0.3))], Y_all_test[:int(n_size*(1-0.3))])\n","test_mape = mape(Y[int(n_size*(1-0.3)):], Y_all_test[int(n_size*(1-0.3)):])\n","\n","print('train MAE {:.2f}\\ttest MAE {:.2f}'.format(train_mae, test_mae))\n","print('train RMSE {:.2f}\\ttest RMSE {:.2f}'.format(train_rmse, test_rmse))\n","print('train MAPE {:.2f}\\ttest MAPE {:.2f}'.format(train_mape, test_mape))\n","print('=========================')\n","\n","if yearlyyield == False:\n","    for year, month, y_true, y_pred in zip(year_target, month_target, Y, Y_all_test):\n","        print('year {:.0f} month {:.0f} true : {:.0f}\\tpred : {:.0f}'.format(year, month, y_true, y_pred))\n","else:\n","    for year, y_true, y_pred in zip(year_target, Y, Y_all_test):\n","        print('year {:.0f} true : {:.0f}\\tpred : {:.0f}'.format(year, y_true, y_pred))   "]},{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":["<h1> Support Vector Regression w/o Normalization </h1>"]},{"cell_type":"code","execution_count":95,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"Pipeline(memory=None,\n     steps=[('svr', SVR(C=0.001, cache_size=200, coef0=0.0, degree=3, epsilon=0.001,\n  gamma='scale', kernel='linear', max_iter=-1, shrinking=True, tol=0.001,\n  verbose=False))])\n"}],"source":["# vector for record error\n","train_mae = np.array([])\n","test_mae = np.array([])\n","\n","train_rmse = np.array([])\n","test_rmse = np.array([])\n","\n","train_r2 = np.array([])\n","test_r2 = np.array([])\n","\n","# using grid searchcv to optimize hyper param\n","estimators = [('svr', SVR(kernel = 'linear', gamma = 'scale'))]\n","pipe    = Pipeline(estimators)\n","param   = dict(\n","    svr__C=[0.001, 0.01, 0.1, 0.5, 1, 5, 100],\n","    svr__epsilon = [0.001, 0.01, 0.1, 0.5, 1])\n","\n","gsc     = GridSearchCV(pipe, param, cv = 3)\n","# gsc.fit(X, np.log1p(Y))\n","gsc.fit(X, Y)\n","\n","reg_svr  = gsc.best_estimator_\n","print(gsc.best_estimator_)"]},{"cell_type":"code","execution_count":96,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"train MAE 1334.80\ttest MAE 1226.89\ntrain RMSE 1814.14\ttest RMSE 1600.82\ntrain MAPE 22.79\ttest MAPE 39.86\n=========================\nyear 2007 month 12 true : 7307\tpred : 5482\nyear 2008 month 12 true : 4338\tpred : 5482\nyear 2009 month 12 true : 9581\tpred : 5483\nyear 2010 month 12 true : 5277\tpred : 5481\nyear 2011 month 12 true : 3454\tpred : 5486\nyear 2012 month 12 true : 5696\tpred : 5483\nyear 2013 month 12 true : 4865\tpred : 5483\nyear 2014 month 12 true : 6029\tpred : 5484\nyear 2015 month 12 true : 4909\tpred : 5481\nyear 2016 month 12 true : 2505\tpred : 5483\nyear 2017 month 12 true : 5060\tpred : 5482\nyear 2018 month 12 true : 4551\tpred : 5486\n"}],"source":["reg_svr.fit(X_train_ord, np.log1p(Y_train_ord))\n","# reg_svr.fit(X_train_ord, Y_train_ord)\n","\n","Y_all_test = reg_svr.predict(X)\n","Y_all_test[Y_all_test<0] = 0\n","Y_all_test = np.expm1(Y_all_test)\n","\n","train_mae = mae(Y[:int(n_size*(1-0.3))], Y_all_test[:int(n_size*(1-0.3))])\n","test_mae = mae(Y[int(n_size*(1-0.3)):], Y_all_test[int(n_size*(1-0.3)):])\n","\n","train_rmse = rmse(Y[:int(n_size*(1-0.3))], Y_all_test[:int(n_size*(1-0.3))])\n","test_rmse = rmse(Y[int(n_size*(1-0.3)):], Y_all_test[int(n_size*(1-0.3)):])\n","\n","train_mape = mape(Y[:int(n_size*(1-0.3))], Y_all_test[:int(n_size*(1-0.3))])\n","test_mape = mape(Y[int(n_size*(1-0.3)):], Y_all_test[int(n_size*(1-0.3)):])\n","\n","print('train MAE {:.2f}\\ttest MAE {:.2f}'.format(train_mae, test_mae))\n","print('train RMSE {:.2f}\\ttest RMSE {:.2f}'.format(train_rmse, test_rmse))\n","print('train MAPE {:.2f}\\ttest MAPE {:.2f}'.format(train_mape, test_mape))\n","print('=========================')\n","\n","if yearlyyield == False:\n","    for year, month, y_true, y_pred in zip(year_target, month_target, Y, Y_all_test):\n","        print('year {:.0f} month {:.0f} true : {:.0f}\\tpred : {:.0f}'.format(year, month, y_true, y_pred))\n","else:\n","    for year, y_true, y_pred in zip(year_target, Y, Y_all_test):\n","        print('year {:.0f} month {:.0f} true : {:.0f}\\tpred : {:.0f}'.format(year, month, y_true, y_pred))   "]},{"cell_type":"markdown","execution_count":51,"metadata":{},"outputs":[],"source":["<h1> Support Vector Regression w Normalization </h1>"]},{"cell_type":"code","execution_count":103,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"Pipeline(memory=None,\n     steps=[('normalize', PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n  svd_solver='auto', tol=0.0, whiten=False)), ('svr', SVR(C=0.01, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n  kernel='linear', max_iter=-1, shrinking=True, tol=0.001, verbose=False))])\n"}],"source":["# vector for record error\n","train_mae = np.array([])\n","test_mae = np.array([])\n","\n","train_rmse = np.array([])\n","test_rmse = np.array([])\n","\n","train_r2 = np.array([])\n","test_r2 = np.array([])\n","\n","# using grid searchcv to optimize hyper param\n","estimators = [('normalize', PCA()),('svr', SVR(kernel = 'linear', gamma = 'scale'))]\n","pipe    = Pipeline(estimators)\n","param   = dict(\n","    svr__C=[0.001, 0.01, 0.1, 0.5, 1, 5, 100],\n","    svr__epsilon = [0.001, 0.01, 0.1, 0.5, 1])\n","\n","gsc     = GridSearchCV(pipe, param, cv = 2)\n","gsc.fit(X, np.log1p(Y))\n","\n","reg_svr_norm  = gsc.best_estimator_\n","print(gsc.best_estimator_)"]},{"cell_type":"code","execution_count":104,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"train MAE 1335.05\ttest MAE 799.16\ntrain RMSE 1720.26\ttest RMSE 1297.94\ntrain MAPE 23.82\t\ttest MAPE 28.90\n=========================\nyear 2007 month 12 true : 7307\tpred : 6130\nyear 2008 month 12 true : 4338\tpred : 5997\nyear 2009 month 12 true : 9581\tpred : 5831\nyear 2010 month 12 true : 5277\tpred : 5810\nyear 2011 month 12 true : 3454\tpred : 5524\nyear 2012 month 12 true : 5696\tpred : 5499\nyear 2013 month 12 true : 4865\tpred : 5397\nyear 2014 month 12 true : 6029\tpred : 5267\nyear 2015 month 12 true : 4909\tpred : 5233\nyear 2016 month 12 true : 2505\tpred : 5067\nyear 2017 month 12 true : 5060\tpred : 5011\nyear 2018 month 12 true : 4551\tpred : 4813\n"}],"source":["reg_svr_norm.fit(X_train_ord, np.log1p(Y_train_ord))\n","\n","Y_all_test = reg_svr_norm.predict(X)\n","Y_all_test[Y_all_test<0] = 0\n","Y_all_test = np.expm1(Y_all_test)\n","\n","train_mae = mae(Y[:int(n_size*(1-0.3))], Y_all_test[:int(n_size*(1-0.3))])\n","test_mae = mae(Y[int(n_size*(1-0.3)):], Y_all_test[int(n_size*(1-0.3)):])\n","\n","train_rmse = rmse(Y[:int(n_size*(1-0.3))], Y_all_test[:int(n_size*(1-0.3))])\n","test_rmse = rmse(Y[int(n_size*(1-0.3)):], Y_all_test[int(n_size*(1-0.3)):])\n","\n","train_mape = mape(Y[:int(n_size*(1-0.3))], Y_all_test[:int(n_size*(1-0.3))])\n","test_mape = mape(Y[int(n_size*(1-0.3)):], Y_all_test[int(n_size*(1-0.3)):])\n","\n","print('train MAE {:.2f}\\ttest MAE {:.2f}'.format(train_mae, test_mae))\n","print('train RMSE {:.2f}\\ttest RMSE {:.2f}'.format(train_rmse, test_rmse))\n","print('train MAPE {:.2f}\\t\\ttest MAPE {:.2f}'.format(train_mape, test_mape))\n","print('=========================')\n","\n","if yearlyyield == False:\n","    for year, month, y_true, y_pred in zip(year_target, month_target, Y, Y_all_test):\n","        print('year {:.0f} month {:.0f} true : {:.0f}\\tpred : {:.0f}'.format(year, month, y_true, y_pred))\n","else:\n","    for year, y_true, y_pred in zip(year_target, Y, Y_all_test):\n","        print('year {:.0f} month {:.0f} true : {:.0f}\\tpred : {:.0f}'.format(year, month, y_true, y_pred))   "]},{"cell_type":"code","execution_count":321,"metadata":{},"outputs":[],"source":["# export output\n","year_train  = year_target[:int(n_size*(1-0.3))]\n","month_train = month_target[:int(n_size*(1-0.3))] if yearlyyield == False else year_train\n","year_test   = year_target[int(n_size*(1-0.3)):]\n","month_test  = month_target[int(n_size*(1-0.3)):] if yearlyyield == False else year_test\n","y_train_true = Y[:int(n_size*(1-0.3))]\n","y_train_pred = Y_all_test[:int(n_size*(1-0.3))]\n","y_test_true = Y[int(n_size*(1-0.3)):]\n","y_test_pred = Y_all_test[int(n_size*(1-0.3)):]\n","export_output('svr_wonorm_results_monthly_input_yearly_output_v3.xlsx', year_train, month_train, y_train_true, y_train_pred, year_test, month_test, y_test_true, y_test_pred)"]},{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":["<h1>Get X and y for Recurrent Neural Network</h1>"]},{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":["method for getting x data for rnn"]},{"cell_type":"code","execution_count":324,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"true\n(24, 2)\nn_steps : 2 n_features : 2 n_size : 12\n"}],"source":["choose = 'monthly_yearlyyield'\n","\n","if choose == 'test':\n","    input_vec = [\n","        [daily_temp, 'x'], \n","        [daily_yieldarea[:,0].reshape(-1,1), 'y'],   # target year\n","        [daily_yieldarea[:,0:2].reshape(-1,2), 'y']] # target month\n","\n","    output_vec = [daily_lychee]\n","\n","if choose == 'monthly':\n","    yearlyyield = False\n","    input_vec = [\n","        [monthly_temp, 'x'],\n","        # [monthly_humid, 'x'], \n","        # [monthly_rain, 'x'], \n","        # [monthly_area, 'x'], \n","        [monthly_yieldarea, 'x'], \n","        [monthly_lychee, 'x'], \n","        [monthly_yieldarea[:,0].reshape(-1,1), 'y'],   # target year\n","        [monthly_yieldarea[:,0:2].reshape(-1,2), 'y']] # target month\n","    \n","    output_vec = [monthly_lychee]\n","\n","if choose == 'monthly_yearlyyield':\n","    yearlyyield = True\n","    input_vec = [\n","        [monthly_temp, 'x'],\n","        # [monthly_humid, 'x'], \n","        # [monthly_rain, 'x'], \n","        # [monthly_area, 'x'], \n","        # [monthly_yieldarea, 'x'], \n","        # [monthly_lychee, 'x'], \n","        [monthly_yieldarea[:,0].reshape(-1,1), 'y']]   # target year\n","\n","    output_vec = [monthly_lychee_yearlyyield]\n","\n","if choose == 'daily':\n","    yearlyyield = False\n","    input_vec = [\n","        [daily_temp, 'x'],\n","        [daily_humid, 'x'], \n","        # [daily_rain, 'x'], \n","        # [daily_area, 'x'], \n","        # [daily_yieldarea, 'x'], \n","        [daily_lychee, 'x'], \n","        [daily_yieldarea[:,0].reshape(-1,1), 'y'],   # target year\n","        [daily_yieldarea[:,0:2].reshape(-1,2), 'y']] # target month\n","\n","    output_vec = [daily_lychee]\n","\n","if choose == 'hourly':\n","    yearlyyield = False\n","    input_vec = [\n","        [hourly_temp, 'x'],\n","        # [hourly_humid, 'x'], \n","        # [hourly_rain, 'x'], \n","        # [hourly_area, 'x'], \n","        [hourly_yieldarea, 'x'], \n","        [hourly_lychee, 'x'], \n","        [hourly_yieldarea[:,0].reshape(-1,1), 'y'],   # target year\n","        [hourly_yieldarea[:,0:2].reshape(-1,2), 'y']] # target month\n","\n","    output_vec = [hourly_lychee]\n","\n","# daily choose n_steps = 240\n","# hourly choose n_steps = 1920\n","# monthly choose n_steps = 4\n","# axis = 2 for rnn\n","\n","########## choose architecture of neural network\n","\n","choose = 'gru'\n","\n","X_rnn, Y_rnn, n_features, n_size, n_steps, year_target, month_target = get_XY_fr_resolution(input_vec, output_vec, n_steps = 2, axis = 1 if choose == 'ann' else 2, req_m_input = [1, 2], req_month = [4, 5, 6], yearlyyield = yearlyyield)\n","\n","print('n_steps : {:d} n_features : {:d} n_size : {:d}'.format(n_steps, n_features, n_size))"]},{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":["Seperate train set and test set with unshuffle for displaying</br>\n","test size = 53\n","train size = 124"]},{"cell_type":"code","execution_count":325,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"(8,)\n"}],"source":["train_ratio = 0.7\n","\n","X_train_ord         = X_rnn[:int(train_ratio*n_size), :] if choose == 'ann' else X_rnn[:int(train_ratio*n_size), :, :]\n","X_test_ord          = X_rnn[int(train_ratio*n_size):, :] if choose == 'ann' else X_rnn[int(train_ratio*n_size):, :, :]\n","Y_train_ord         = Y_rnn[:int(train_ratio*n_size)].reshape(-1)\n","Y_test_ord          = Y_rnn[int(train_ratio*n_size):].reshape(-1)\n","print(Y_train_ord.shape)"]},{"cell_type":"code","execution_count":326,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"(8, 2, 2)\n(8,)\n"}],"source":["X_train     = X_train_ord\n","X_test      = X_test_ord\n","Y_train     = Y_train_ord\n","Y_test      = Y_test_ord\n","\n","print(X_train.shape)\n","print(Y_train.shape)"]},{"cell_type":"markdown","execution_count":132,"metadata":{},"outputs":[],"source":["<h1> Recurrent Neural Network w/o Normalization </h1>"]},{"cell_type":"code","execution_count":327,"metadata":{},"outputs":[],"source":["class Scaler3D():\n","\n","    def __init__(self):\n","        self.scaler_list = {}\n","\n","    def fit(self, x):\n","        self.x = x\n","        \n","        min_list = np.array([])\n","        max_list = np.array([])\n","\n","        len_feature = x.shape[-1]\n","\n","        for i in range(len_feature):\n","            self.scaler_list[i] = MinMaxScaler()\n","            self.scaler_list[i].fit(x[:, :, i])\n","\n","    def transform(self, x):\n","        x_copy = x.copy()\n","\n","        len_feature = x.shape[-1]\n","\n","        for i in range(len_feature):\n","            x_copy[:,:,i] = self.scaler_list[i].transform(x[:, :, i])\n","\n","        return x_copy"]},{"cell_type":"code","execution_count":328,"metadata":{},"outputs":[],"source":["def create_model_lstm(n_steps, n_features):\n","    rnn = Sequential()\n","    rnn.add(LSTM(10, activation='relu', return_sequences=True, input_shape=(n_steps, n_features)))\n","    rnn.add(Dropout(0.2))\n","    rnn.add(LSTM(50, activation='relu'))\n","    rnn.add(Dropout(0.2))\n","    rnn.add(Dense(50, activation='relu'))\n","    rnn.add(Dropout(0.2))\n","    rnn.add(Dense(1, activation='relu'))\n","    rnn.compile(optimizer='adam', loss='mse')\n","\n","    return rnn  "]},{"cell_type":"code","execution_count":329,"metadata":{},"outputs":[],"source":["def create_model_gru(n_steps, n_features):\n","    \n","    rnn = Sequential()\n","    rnn.add(GRU(100, activation='relu', return_sequences=True, input_shape=(n_steps, n_features)))\n","    rnn.add(Dropout(0.4))\n","    rnn.add(GRU(100, activation='relu', return_sequences=True))\n","    rnn.add(Dropout(0.4))\n","    rnn.add(GRU(100, activation='relu'))    \n","    # rnn.add(BatchNormalization())    \n","    rnn.add(Dropout(0.4))\n","    rnn.add(Dense(50, activation='relu'))\n","    rnn.add(Dropout(0.4))    \n","    rnn.add(Dense(1, activation='relu'))\n","    rnn.compile(optimizer='adam', loss='mse')\n","    return rnn  "]},{"cell_type":"code","execution_count":330,"metadata":{},"outputs":[],"source":["def create_model_ann(n_steps, n_features):\n","    reg = l1(0.01)\n","    rnn = Sequential()\n","    # input layer\n","    rnn.add(Dense(128, activation='relu', input_dim=n_features))\n","    # hidden layer\n","    rnn.add(Dense(256, activation='relu',\n","                kernel_regularizer=reg)) \n","    rnn.add(Dropout(0.4))\n","    rnn.add(Dense(256, activation='relu',\n","                kernel_regularizer=reg))   \n","    rnn.add(Dropout(0.4)) \n","    rnn.add(Dense(256, activation='relu',\n","                kernel_regularizer=reg))   \n","    rnn.add(Dropout(0.4))     \n","    # output layer\n","    rnn.add(Dense(1, activation='relu'))\n","    rnn.compile(optimizer='adam', loss='mse')\n","    return rnn  "]},{"cell_type":"markdown","execution_count":220,"metadata":{},"outputs":[],"source":["<h1> Recurrent Neural Network w Normalization </h1>"]},{"cell_type":"code","execution_count":331,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ngru (GRU)                    (None, 2, 100)            31200     \n_________________________________________________________________\ndropout (Dropout)            (None, 2, 100)            0         \n_________________________________________________________________\ngru_1 (GRU)                  (None, 2, 100)            60600     \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 2, 100)            0         \n_________________________________________________________________\ngru_2 (GRU)                  (None, 100)               60600     \n_________________________________________________________________\ndropout_2 (Dropout)          (None, 100)               0         \n_________________________________________________________________\ndense (Dense)                (None, 50)                5050      \n_________________________________________________________________\ndropout_3 (Dropout)          (None, 50)                0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 1)                 51        \n=================================================================\nTotal params: 157,501\nTrainable params: 157,501\nNon-trainable params: 0\n_________________________________________________________________\n"}],"source":["# Create a callback that saves the model's weights\n","if choose == 'lstm':\n","    checkpoint_path = './checkpoint_path_lstm'\n","    rnn = create_model_lstm(n_steps, n_features)   \n","elif choose == 'gru':\n","    checkpoint_path = './checkpoint_path_gru_3layer_monthly_yearlyyield.ckpt'\n","    rnn = create_model_gru(n_steps, n_features)   \n","else:\n","    checkpoint_path = './checkpoint_path_ann_3layer_monthly_yearlyyield.ckpt'\n","    rnn = create_model_ann(n_steps, n_features)       \n","\n","cp_callback     = tensorflow.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n","                                                 save_weights_only=True,\n","                                                 verbose=0)        \n","rnn.summary()        "]},{"cell_type":"code","execution_count":332,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"---- Iter : 0 ----\nTrain set MAE 20505.00\nTest set MAE 46438.19\nTrain set RMSE 21961.20\nTest set RMSE 71451.04\n---- Iter : 10 ----\nTrain set MAE 16166.93\nTest set MAE 8702.25\nTrain set RMSE 17460.50\nTest set RMSE 9607.88\n---- Iter : 20 ----\nTrain set MAE 9495.80\nTest set MAE 3054.53\nTrain set RMSE 11368.43\nTest set RMSE 3737.16\n---- Iter : 30 ----\nTrain set MAE 8794.44\nTest set MAE 3481.92\nTrain set RMSE 10656.41\nTest set RMSE 4137.10\n---- Iter : 40 ----\nTrain set MAE 12152.86\nTest set MAE 7767.97\nTrain set RMSE 13845.34\nTest set RMSE 8524.87\n---- Iter : 50 ----\nTrain set MAE 7923.54\nTest set MAE 3682.76\nTrain set RMSE 9665.56\nTest set RMSE 4325.19\n---- Iter : 60 ----\nTrain set MAE 6315.72\nTest set MAE 6806.90\nTrain set RMSE 7523.40\nTest set RMSE 8140.53\n---- Iter : 70 ----\nTrain set MAE 10558.58\nTest set MAE 6972.15\nTrain set RMSE 12397.24\nTest set RMSE 7725.56\n---- Iter : 80 ----\nTrain set MAE 7756.18\nTest set MAE 4451.76\nTrain set RMSE 9426.63\nTest set RMSE 5067.83\n---- Iter : 90 ----\nTrain set MAE 7337.08\nTest set MAE 4156.22\nTrain set RMSE 8945.87\nTest set RMSE 5191.73\n---- Iter : 100 ----\nTrain set MAE 8105.50\nTest set MAE 6265.23\nTrain set RMSE 9899.11\nTest set RMSE 8083.76\n---- Iter : 110 ----\nTrain set MAE 7118.25\nTest set MAE 15773.87\nTrain set RMSE 8682.47\nTest set RMSE 18047.05\n---- Iter : 120 ----\nTrain set MAE 7801.60\nTest set MAE 5443.87\nTrain set RMSE 9518.59\nTest set RMSE 7220.16\n---- Iter : 130 ----\nTrain set MAE 9413.51\nTest set MAE 6775.98\nTrain set RMSE 11266.87\nTest set RMSE 7832.76\n---- Iter : 140 ----\nTrain set MAE 7119.06\nTest set MAE 6049.85\nTrain set RMSE 8703.11\nTest set RMSE 8044.21\n---- Iter : 150 ----\nTrain set MAE 7454.15\nTest set MAE 5111.18\nTrain set RMSE 9033.52\nTest set RMSE 5954.87\n---- Iter : 160 ----\nTrain set MAE 8358.10\nTest set MAE 6235.15\nTrain set RMSE 10129.80\nTest set RMSE 7273.22\n---- Iter : 170 ----\nTrain set MAE 8356.19\nTest set MAE 5716.00\nTrain set RMSE 10119.08\nTest set RMSE 6477.69\n---- Iter : 180 ----\nTrain set MAE 7003.34\nTest set MAE 4910.67\nTrain set RMSE 8538.71\nTest set RMSE 5712.03\n---- Iter : 190 ----\nTrain set MAE 7372.38\nTest set MAE 7500.96\nTrain set RMSE 9029.60\nTest set RMSE 9455.62\n---- Iter : 200 ----\nTrain set MAE 6852.47\nTest set MAE 6135.03\nTrain set RMSE 8379.19\nTest set RMSE 7511.31\n---- Iter : 210 ----\nTrain set MAE 8263.34\nTest set MAE 6654.67\nTrain set RMSE 10034.54\nTest set RMSE 7761.94\n---- Iter : 220 ----\nTrain set MAE 7287.01\nTest set MAE 5674.18\nTrain set RMSE 8813.31\nTest set RMSE 6710.76\n---- Iter : 230 ----\nTrain set MAE 8030.45\nTest set MAE 6739.97\nTrain set RMSE 9766.02\nTest set RMSE 7654.25\n---- Iter : 240 ----\nTrain set MAE 7731.82\nTest set MAE 6812.19\nTrain set RMSE 9480.63\nTest set RMSE 7551.33\n---- Iter : 250 ----\nTrain set MAE 7054.02\nTest set MAE 6085.91\nTrain set RMSE 8676.95\nTest set RMSE 6794.73\n"},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[1;32m<ipython-input-332-24ac670eceb5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mchoose\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'ann'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m             \u001b[0mrnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog1p\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#, callbacks=[cp_callback])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m             \u001b[0mY_test_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 728\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    729\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    730\u001b[0m   def evaluate(self,\n","\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[0;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 324\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    122\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 86\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    485\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    486\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 487\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    488\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    489\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1821\u001b[0m     \u001b[1;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1823\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1824\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1825\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1141\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1143\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1222\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[1;32m-> 1224\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1225\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    512\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# vector for record error\n","train_mae = np.array([])\n","test_mae = np.array([])\n","\n","train_rmse = np.array([])\n","test_rmse = np.array([])\n","\n","train_r2 = np.array([])\n","test_r2 = np.array([])\n","\n","# minmaxscaler\n","scaler = Scaler3D()\n","scaler.fit(X_train)\n","\n","for i in range(300):\n","\n","    # if os.path.isfile(checkpoint_path):\n","    #     rnn.load_weights(checkpoint_path)\n","\n","        if choose != 'ann':\n","            rnn.fit(scaler.transform(X_train), np.log1p(Y_train), epochs=50, verbose=0, batch_size=32)#, callbacks=[cp_callback])\n","\n","            Y_test_pred = rnn.predict(scaler.transform(X_test))\n","            Y_test_pred[Y_test_pred<0] = 0\n","\n","            Y_train_pred = rnn.predict(scaler.transform(X_train))\n","            Y_train_pred[Y_train_pred<0] = 0\n","\n","            Y_test_pred = np.expm1(Y_test_pred)\n","            Y_train_pred = np.expm1(Y_train_pred)\n","\n","        else:\n","            rnn.fit(scaler.transform(X_train), np.log1p(Y_train), epochs=1, verbose=1, batch_size=32)#, callbacks=[cp_callback])\n","\n","            Y_test_pred = rnn.predict(X_test)\n","            Y_test_pred[Y_test_pred<0] = 0\n","\n","            Y_train_pred = rnn.predict(X_train)\n","            Y_train_pred[Y_train_pred<0] = 0\n","\n","            Y_test_pred = np.expm1(Y_test_pred)\n","            Y_train_pred = np.expm1(Y_train_pred)\n","\n","            Y_train = np.expm1(Y_train)\n","            Y_test  = np.expm1(Y_test)\n","\n","        train_mae = np.append(train_mae, mae(Y_train, Y_train_pred))\n","        test_mae = np.append(test_mae, mae(Y_test, Y_test_pred))\n","\n","        train_rmse = np.append(train_rmse, rmse(Y_train, Y_train_pred))\n","        test_rmse = np.append(test_rmse, rmse(Y_test, Y_test_pred)) \n","\n","        if i%10 == 0:\n","            print('---- Iter : {:d} ----'.format(i))\n","\n","            print('Train set MAE {:.2f}'.format(np.mean(train_mae[-1])))\n","            print('Test set MAE {:.2f}'.format(np.mean(test_mae[-1])))\n","\n","            print('Train set RMSE {:.2f}'.format(np.mean(train_rmse[-1])))\n","            print('Test set RMSE {:.2f}'.format(np.mean(test_rmse[-1])))  "]},{"cell_type":"code","execution_count":206,"metadata":{},"outputs":[],"source":["Y_all_test = rnn.predict(scaler.transform(X_rnn))\n","Y_all_test[Y_all_test<0] = 0\n","\n","Y_all_test = np.expm1(Y_all_test)\n","# Y_all_test = scaler_Y.inverse_transform(Y_all_test)\n","\n","train_mae = mae(Y_rnn[:int(n_size*(1-0.3))], Y_all_test[:int(n_size*(1-0.3))])\n","test_mae = mae(Y_rnn[int(n_size*(1-0.3)):], Y_all_test[int(n_size*(1-0.3)):])\n","\n","train_rmse = rmse(Y_rnn[:int(n_size*(1-0.3))], Y_all_test[:int(n_size*(1-0.3))])\n","test_rmse = rmse(Y_rnn[int(n_size*(1-0.3)):], Y_all_test[int(n_size*(1-0.3)):])\n","\n","train_mape = mape(Y[:int(n_size*(1-0.3))], Y_all_test[:int(n_size*(1-0.3))])\n","test_mape = mape(Y[int(n_size*(1-0.3)):], Y_all_test[int(n_size*(1-0.3)):])\n","\n","print('train MAE {:.2f}\\ttest MAE {:.2f}'.format(train_mae, test_mae))\n","print('train RMSE {:.2f}\\ttest RMSE {:.2f}'.format(train_rmse, test_rmse))\n","print('train MAPE {:.2f}\\t\\ttest MAPE {:.2f}'.format(train_mape, test_mape))\n","print('=========================')\n","\n","if yearlyyield == False:\n","    for year, month, y_true, y_pred in zip(year_target, month_target, Y, Y_all_test):\n","        print('year {:.0f} month {:.0f} true : {:.0f}\\tpred : {:.0f}'.format(year, month, y_true, y_pred))\n","else:\n","    for year, y_true, y_pred in zip(year_target, Y, Y_all_test):\n","        print('year {:.0f} true : {:.0f}\\tpred : {:.0f}'.format(year, y_true, y_pred[0]))   "]},{"cell_type":"code","execution_count":252,"metadata":{},"outputs":[],"source":["# export output\n","# X_rnn[:int(train_ratio*n_size), :, :]\n","year_train  = year_target[:int(n_size*(1-0.3))]\n","month_train = month_target[:int(n_size*(1-0.3))] if yearlyyield == False else year_train\n","year_test   = year_target[int(n_size*(1-0.3)):]\n","month_test  = month_target[int(n_size*(1-0.3)):] if yearlyyield == False else year_test\n","y_train_true = Y[:int(n_size*(1-0.3))]\n","y_train_pred = Y_all_test[:int(n_size*(1-0.3))]\n","y_test_true = Y[int(n_size*(1-0.3)):]\n","y_test_pred = Y_all_test[int(n_size*(1-0.3)):]\n","export_output('rnn_results_monthly_input_yearly_output.xlsx', year_train, month_train, y_train_true, y_train_pred, year_test, month_test, y_test_true, y_test_pred)"]}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}