{"cells":[{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":["<h1> Code for Lychee Yield Prediction </h1>"]},{"cell_type":"code","execution_count":213,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib.cm as cm\n","# multivariate linear regression with regularization\n","from sklearn.linear_model import LinearRegression, Ridge, Lasso\n","# support vector machine regression\n","from sklearn.svm import SVR\n","from sklearn.metrics import r2_score\n","# neural network\n","import tensorflow\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import LSTM, GRU, Dense, Dropout, Bidirectional, BatchNormalization\n","# normalization\n","from sklearn.preprocessing import MinMaxScaler, StandardScaler\n","from sklearn.pipeline import Pipeline\n","# score\n","from sklearn.metrics import mean_absolute_error\n","from sklearn.model_selection import train_test_split, StratifiedShuffleSplit, GridSearchCV, RandomizedSearchCV\n","# import keras\n","import tensorflow.keras\n","from tensorflow.keras import optimizers, regularizers\n","# import regularizer\n","from tensorflow.keras.regularizers import l1, l2\n","# import matplotlib\n","import matplotlib.pyplot as plt\n","# os\n","import os\n","\n","import pickle\n","from calendar import monthrange"]},{"cell_type":"code","execution_count":214,"metadata":{},"outputs":[],"source":["def clean_text_to_number(df):\n","    '''\n","    convert all text to 0\n","    '''\n","    cols = df.columns\n","    type_list = []\n","    for col in cols:\n","        print(col)\n","        try:\n","            df[col].astype(float)\n","        except:\n","            for i in range(df[col].shape[0]):\n","                if isinstance(df[col].iloc[i], str):\n","                    df[col].iloc[i] = 0\n","    return df"]},{"cell_type":"code","execution_count":215,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"rain amount dataframe\n(5051, 9)\nhumid dataframe\n(5051, 9)\ntemperature dataframe\n(5051, 9)\nrain dataframe sample\n   1  4  7 10 13 16 19 22 total\n0  0  0  0  0  0  0  0  0     -\n1  0  0  0  0  0  0  0  0     -\n2  0  0  0  0  0  0  0  0     -\n3  0  0  0  0  0  0  0  0     -\n4  0  0  0  0  0  0  0  0     -\narea dataframe sample\n   year  district  code  allarea  yieldarea  yield  yieldperarea\n0  1994         1    50    27127      22158  18856         851.0\n1  1995         1    50    27470      23197  15078         650.0\n2  1996         1    50    33049      24793  23281         939.0\n3  1997         1    50    36736      26612  20385         766.0\n4  1998         1    50    40725      27214   1769          65.0\n"}],"source":["# import data frame\n","rain_df     = pd.read_excel('rain_amount_2006-2019.xlsx')\n","humid_df    = pd.read_excel('relative_humid_2006-2019.xlsx')\n","temp_df     = pd.read_excel('temp_2006-2019.xlsx')\n","area_df     = pd.read_excel('area_1994-2018.xls', sheet_name = 'Sheet1')\n","lychee_yield_df = pd.read_excel('lycheeproduct.xlsx')\n","\n","# extract data\n","rain_df     = rain_df.iloc[5:, :]\n","humid_df    = humid_df.iloc[5:, :]\n","temp_df     = temp_df.iloc[5:, :]\n","\n","# reset index\n","rain_df     = rain_df.reset_index().drop(columns=['index'])\n","humid_df    = humid_df.reset_index().drop(columns=['index'])\n","temp_df     = temp_df.reset_index().drop(columns=['index'])\n","\n","# set column name\n","rain_df.columns     = ['days', 'location', 'date', '1', '4', '7', '10', '13', '16', '19', '22', 'total']\n","humid_df.columns    = ['days', 'location', 'date', '1', '4', '7', '10', '13', '16', '19', '22', 'mean']\n","temp_df.columns     = ['days', 'location', 'date', '1', '4', '7', '10', '13', '16', '19', '22', 'mean']\n","lychee_yield_df.columns = ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', 'total', 'year']\n","area_df.columns     = ['year', 'district', 'code', 'province', 'allarea', 'yieldarea', 'yield', 'yieldperarea']\n","area_df['year']     = area_df['year'] - 543\n","\n","# ดึงค่า date เก็บไว้ก่อน\n","all_datetime    = pd.to_datetime(rain_df['date'])\n","\n","rain_df     = rain_df.drop(columns = ['location', 'days', 'date'])\n","humid_df    = humid_df.drop(columns =['location', 'days', 'date'])\n","temp_df     = temp_df.drop(columns =['location', 'days', 'date'])\n","area_df     = area_df.drop(columns = ['province'])\n","\n","print('rain amount dataframe')\n","print(rain_df.shape)\n","print('humid dataframe')\n","print(humid_df.shape)\n","print('temperature dataframe')\n","print(temp_df.shape)\n","print('rain dataframe sample')\n","print(rain_df.head(5))\n","print('area dataframe sample')\n","print(area_df.head(5))"]},{"cell_type":"code","execution_count":216,"metadata":{},"outputs":[],"source":["# # get datetime from 3 hour data set\n","# all_year        = pd.DataFrame(all_datetime.dt.year)\n","# all_month       = pd.DataFrame(all_datetime.dt.month)\n","# all_day         = pd.DataFrame(all_datetime.dt.day)\n","\n","# all_year.columns    = ['year']\n","# all_month.columns   = ['month']\n","# all_day.columns     = ['day']\n","# # concat to existing dataframe\n","# rain_df = pd.concat([all_year, all_month, all_day, rain_df], axis = 1)\n","# humid_df = pd.concat([all_year, all_month, all_day, humid_df], axis = 1)\n","# temp_df = pd.concat([all_year, all_month, all_day, temp_df], axis = 1)\n","\n","# # clean text element and save in pickle form\n","\n","# rain_df_clean = clean_text_to_number(rain_df)\n","# with open('rain_df_clean.pickle', 'wb') as f:\n","#     pickle.dump(rain_df_clean, f)\n","# humid_df_clean = clean_text_to_number(humid_df)\n","# with open('humid_df_clean.pickle', 'wb') as f:\n","#     pickle.dump(humid_df_clean, f)\n","# temp_df_clean = clean_text_to_number(temp_df)\n","# with open('temp_df_clean.pickle', 'wb') as f:\n","#     pickle.dump(temp_df_clean, f)"]},{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":["<h1> Load Data from pickle </h1> since clean dataframe take very long time. So after we clean it, we save dataframe in pickle form."]},{"cell_type":"code","execution_count":217,"metadata":{},"outputs":[],"source":["with open('rain_df_clean.pickle', 'rb') as f:\n","    rain_df_clean = pickle.load(f)\n","with open('humid_df_clean.pickle', 'rb') as f:\n","    humid_df_clean = pickle.load(f)\n","with open('temp_df_clean.pickle', 'rb') as f:\n","    temp_df_clean = pickle.load(f)"]},{"cell_type":"code","execution_count":218,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"--- rain amount dataframe sample ---\n      year  month  day  1     4  7 10 13 16 19 22 total\n5046  2019     10   26  0     0  0  0  0  0  0  0     0\n5047  2019     10   27  0     0  0  0  0  0  0  0     0\n5048  2019     10   28  0     0  0  0  0  0  0  0     0\n5049  2019     10   29  0     0  0  0  0  0  0  0     0\n5050  2019     10   30  4  11.5  0  0  0  0  0  0  15.5\n --- humid dataframe sample ---\n   year  month  day   1   4   7  10  13  16  19  22 mean\n0  2006      1    1  97  98  98  78  52  47  79  88   80\n1  2006      1    2  97  99  99  76  52  48  82  91   81\n2  2006      1    3  95  99  99  69  55  50  77  93   80\n3  2006      1    4  97  99  99  70  52  49  80  91   80\n4  2006      1    5  93  98  99  67  50  41  75  78   75\n --- temperature dataframe sample ---\n   year  month  day     1     4     7    10    13    16    19    22  mean\n0  2006      1    1  16.2  15.2  13.9  21.6  28.7  29.9  21.2  18.8  20.7\n1  2006      1    2  16.9  15.8  14.6  22.8  28.5  29.1  20.6  17.6  20.7\n2  2006      1    3  16.6  15.1  14.6  22.9  26.6  27.9  21.4    18  20.4\n3  2006      1    4  16.7  15.6  14.1  22.2  28.1  28.8  20.6  17.7  20.5\n4  2006      1    5  15.6  14.2  13.7  22.6  28.4  30.7  20.4  17.8  20.4\n --- area dataframe sample ---\n   year  district  code  allarea  yieldarea  yield  yieldperarea\n0  1994         1    50    27127      22158  18856         851.0\n1  1995         1    50    27470      23197  15078         650.0\n2  1996         1    50    33049      24793  23281         939.0\n3  1997         1    50    36736      26612  20385         766.0\n4  1998         1    50    40725      27214   1769          65.0\n --- lychee yield dataframe sample ---\n       1      2      3      4      5      6      7      8      9     10  \\\n0  28964  28964  28964  28964  28964  28964  28964  28964  28964  28964   \n1  25990  25990  25990  25990  25990  25990  25990  25990  25990  25990   \n2  24451  24451  24451  24451  24451  24451  24451  24451  24451  24451   \n3  23229  23229  23229  23229  23229  23229  23229  23229  23229  23229   \n4  19089  19089  19089  19089  19089  19089  19089  19089  19089  19089   \n\n      11     12  total  year  \n0  28964  28964  28964  2004  \n1  25990  25990  25990  2005  \n2  24451  24451  24451  2006  \n3  23229  23229  23229  2007  \n4  19089  19089  19089  2008  \n"}],"source":["print(' --- rain amount dataframe sample ---')\n","print(rain_df_clean.tail(5))\n","print(' --- humid dataframe sample ---')\n","print(humid_df_clean.head(5))\n","print(' --- temperature dataframe sample ---')\n","print(temp_df_clean.head(5))\n","print(' --- area dataframe sample ---')\n","print(area_df.head(5))\n","print(' --- lychee yield dataframe sample ---')\n","print(lychee_yield_df.head(5))"]},{"cell_type":"code","execution_count":219,"metadata":{},"outputs":[],"source":["def groupby_col(self, col):\n","    '''\n","    return \n","        1 keys \n","        2 dictionary of sub_df ที่ keys คือแต่ละ element ใน col name\n","    '''\n","\n","    output_dic = {}\n","    all_ele = sorted(list(set(self[col])))\n","\n","    for ele in all_ele:\n","        sub_df = self.loc[self[col] == ele, :]\n","        output_dic[ele] = sub_df\n","\n","    return all_ele, output_dic\n","\n","def groupby_mean(self, col):\n","    '''\n","    return \n","        1 keys \n","        2 dictionary of sub_df ที่ keys คือแต่ละ element ใน col name\n","    '''\n","\n","    output_dic = {}\n","    all_ele = sorted(list(set(self[col])))\n","    for ele in all_ele:\n","        sub_df = self.loc[self[col] == ele, :].mean(axis=0)\n","        output_dic[ele] = sub_df\n","    \n","    return all_ele, output_dic\n","\n","def groupby_max(self, col):\n","    '''\n","    return \n","        1 keys \n","        2 dictionary of sub_df ที่ keys คือแต่ละ element ใน col name\n","    '''\n","\n","    output_dic = {}\n","    all_ele = sorted(list(set(self[col])))\n","\n","    for ele in all_ele:\n","        sub_df = self.loc[self[col] == ele, :].max(axis = 0)\n","        output_dic[ele] = sub_df\n","    \n","    return all_ele, output_dic\n","\n","def groupby_min(self, col):\n","    '''\n","    return \n","        1 keys \n","        2 dictionary of sub_df ที่ keys คือแต่ละ element ใน col name\n","    '''\n","\n","    output_dic = {}\n","    all_ele = sorted(list(set(self[col])))\n","\n","    for ele in all_ele:\n","        sub_df = self.loc[self[col] == ele, :].min(axis = 0)\n","        output_dic[ele] = sub_df\n","    \n","    return all_ele, output_dic\n","\n","def groupby_sum(self, col):\n","    '''\n","    return \n","        1 keys \n","        2 dictionary of sub_df ที่ keys คือแต่ละ element ใน col name\n","    '''\n","\n","    output_dic = {}\n","    all_ele = sorted(list(set(self[col])))\n","\n","    for ele in all_ele:\n","        sub_df = self.loc[self[col] == ele, :].sum(axis = 0)\n","        output_dic[ele] = sub_df\n","    \n","    return all_ele, output_dic\n","\n","# set method to class\n","setattr(pd.core.frame.DataFrame, 'groupby_col', groupby_col)\n","setattr(pd.core.frame.DataFrame, 'groupby_mean', groupby_mean)\n","setattr(pd.core.frame.DataFrame, 'groupby_sum', groupby_sum)\n","setattr(pd.core.frame.DataFrame, 'groupby_max', groupby_max)\n","setattr(pd.core.frame.DataFrame, 'groupby_min', groupby_min)"]},{"cell_type":"code","execution_count":220,"metadata":{},"outputs":[],"source":["def export_output(filename, year_train, month_train, y_train_true, y_train_pred, year_test, month_test, y_test_true, y_test_pred):\n","    \n","    dic_train = {\n","        'year':year_train.reshape(-1),\n","        'month':month_train.reshape(-1),\n","        'y_true': y_train_true.reshape(-1),\n","        'y_pred': y_train_pred.reshape(-1)\n","    }\n","\n","    dic_test = {\n","        'year':year_test.reshape(-1),\n","        'month':month_test.reshape(-1),\n","        'y_true': y_test_true.reshape(-1),\n","        'y_pred': y_test_pred.reshape(-1)\n","    }\n","    \n","    df_train = pd.DataFrame(dic_train)\n","    df_test = pd.DataFrame(dic_test)\n","    \n","    # Create a Pandas Excel writer using XlsxWriter as the engine.\n","    writer = pd.ExcelWriter(filename, engine='xlsxwriter')\n","    # Write centroids sheet\n","    df_train.to_excel(writer, sheet_name='train set')\n","    df_test.to_excel(writer, sheet_name='test set')\n","    # save output\n","    writer.save()\n"]},{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":["<h1> Rearrange for monthly data </h1>"]},{"cell_type":"code","execution_count":221,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"(166, 3)\n"}],"source":["## montly Temp 2006 - 2019\n","monthly_temp = np.array([1,1,1]).reshape(1,3)\n","\n","all_year, sub_year_dic = temp_df_clean.groupby_col('year')\n","\n","for year in all_year:\n","        all_month, sub_month_dic = sub_year_dic[year].groupby_mean('month')\n","        for month in all_month:\n","                # record year month and mean temp of each month\n","                daily_temp = np.array([year, month, sub_month_dic[month].iloc[-1]]).reshape(1,3)\n","                monthly_temp = np.append(monthly_temp, daily_temp, axis = 0)\n","\n","monthly_temp = np.delete(monthly_temp, 0, axis = 0)\n","print(monthly_temp.shape)"]},{"cell_type":"code","execution_count":222,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"(166, 3)\n"}],"source":["## montly Humid 2006 - 2019\n","monthly_humid = np.array([1,1,1]).reshape(1,3)\n","\n","all_year, sub_year_dic = humid_df_clean.groupby_col('year')\n","\n","for year in all_year:\n","        all_month, sub_month_dic = sub_year_dic[year].groupby_mean('month')\n","\n","        for month in all_month:\n","                # record year month and mean temp of each month\n","                daily_humid = np.array([year, month, sub_month_dic[month].iloc[-1]]).reshape(1,3)\n","                monthly_humid = np.append(monthly_humid, daily_humid, axis = 0)\n","\n","monthly_humid = np.delete(monthly_humid, 0, axis = 0)\n","print(monthly_humid.shape)"]},{"cell_type":"code","execution_count":223,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"(166, 3)\n"}],"source":["## monthly Rain 2006 - 2019\n","monthly_rain = np.array([1,1,1]).reshape(1,3)\n","\n","all_year, sub_year_dic = rain_df_clean.groupby_col('year')\n","\n","for year in all_year:\n","        all_month, sub_month_dic = sub_year_dic[year].groupby_mean('month')\n","\n","        for month in all_month:\n","                # record year month and mean temp of each month\n","                daily_rain = np.array([year, month, sub_month_dic[month].iloc[-1]]).reshape(1,3)\n","                monthly_rain = np.append(monthly_rain, daily_rain, axis = 0)\n","\n","monthly_rain = np.delete(monthly_rain, 0, axis = 0)\n","print(monthly_rain.shape)"]},{"cell_type":"code","execution_count":224,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"(156, 3)\n"}],"source":["## monthly Lychee yield 2004 - 2018\n","monthly_lychee = np.array([1,1,1]).reshape(1,3)\n","\n","all_year, sub_year_dic = rain_df_clean.groupby_col('year')\n","\n","for year in all_year:\n","        all_month, _ = sub_year_dic[year].groupby_mean('month')\n","\n","        for month in all_month:\n","                # record year month and lychee yield of each month\n","                monthly_lychee_temp = lychee_yield_df.loc[lychee_yield_df['year']==year,:]\n","                if monthly_lychee_temp.size != 0:\n","                    monthly_yield = np.array([year, month, monthly_lychee_temp.iloc[0, month-1]]).reshape(1,3)\n","                    monthly_lychee = np.append(monthly_lychee, monthly_yield, axis = 0)\n","\n","monthly_lychee = np.delete(monthly_lychee, 0, axis = 0)\n","print(monthly_lychee.shape)"]},{"cell_type":"code","execution_count":225,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"[[ 2006     1 24451]\n [ 2006     2 24451]\n [ 2006     3 24451]\n [ 2006     4 24451]\n [ 2006     5 24451]\n [ 2006     6 24451]\n [ 2006     7 24451]\n [ 2006     8 24451]\n [ 2006     9 24451]\n [ 2006    10 24451]\n [ 2006    11 24451]\n [ 2006    12 24451]\n [ 2007     1 23229]\n [ 2007     2 23229]\n [ 2007     3 23229]\n [ 2007     4 23229]\n [ 2007     5 23229]\n [ 2007     6 23229]\n [ 2007     7 23229]\n [ 2007     8 23229]\n [ 2007     9 23229]\n [ 2007    10 23229]\n [ 2007    11 23229]\n [ 2007    12 23229]\n [ 2008     1 19089]\n [ 2008     2 19089]\n [ 2008     3 19089]\n [ 2008     4 19089]\n [ 2008     5 19089]\n [ 2008     6 19089]\n [ 2008     7 19089]\n [ 2008     8 19089]\n [ 2008     9 19089]\n [ 2008    10 19089]\n [ 2008    11 19089]\n [ 2008    12 19089]\n [ 2009     1 27922]\n [ 2009     2 27922]\n [ 2009     3 27922]\n [ 2009     4 27922]\n [ 2009     5 27922]\n [ 2009     6 27922]\n [ 2009     7 27922]\n [ 2009     8 27922]\n [ 2009     9 27922]\n [ 2009    10 27922]\n [ 2009    11 27922]\n [ 2009    12 27922]\n [ 2010     1 16052]\n [ 2010     2 16052]\n [ 2010     3 16052]\n [ 2010     4 16052]\n [ 2010     5 16052]\n [ 2010     6 16052]\n [ 2010     7 16052]\n [ 2010     8 16052]\n [ 2010     9 16052]\n [ 2010    10 16052]\n [ 2010    11 16052]\n [ 2010    12 16052]\n [ 2011     1 14033]\n [ 2011     2 14033]\n [ 2011     3 14033]\n [ 2011     4 14033]\n [ 2011     5 14033]\n [ 2011     6 14033]\n [ 2011     7 14033]\n [ 2011     8 14033]\n [ 2011     9 14033]\n [ 2011    10 14033]\n [ 2011    11 14033]\n [ 2011    12 14033]\n [ 2012     1 30097]\n [ 2012     2 30097]\n [ 2012     3 30097]\n [ 2012     4 30097]\n [ 2012     5 30097]\n [ 2012     6 30097]\n [ 2012     7 30097]\n [ 2012     8 30097]\n [ 2012     9 30097]\n [ 2012    10 30097]\n [ 2012    11 30097]\n [ 2012    12 30097]\n [ 2013     1 24997]\n [ 2013     2 24997]\n [ 2013     3 24997]\n [ 2013     4 24997]\n [ 2013     5 24997]\n [ 2013     6 24997]\n [ 2013     7 24997]\n [ 2013     8 24997]\n [ 2013     9 24997]\n [ 2013    10 24997]\n [ 2013    11 24997]\n [ 2013    12 24997]\n [ 2014     1 33525]\n [ 2014     2 33525]\n [ 2014     3 33525]\n [ 2014     4 33525]\n [ 2014     5 33525]\n [ 2014     6 33525]\n [ 2014     7 33525]\n [ 2014     8 33525]\n [ 2014     9 33525]\n [ 2014    10 33525]\n [ 2014    11 33525]\n [ 2014    12 33525]\n [ 2015     1 27016]\n [ 2015     2 27016]\n [ 2015     3 27016]\n [ 2015     4 27016]\n [ 2015     5 27016]\n [ 2015     6 27016]\n [ 2015     7 27016]\n [ 2015     8 27016]\n [ 2015     9 27016]\n [ 2015    10 27016]\n [ 2015    11 27016]\n [ 2015    12 27016]\n [ 2016     1 19180]\n [ 2016     2 19180]\n [ 2016     3 19180]\n [ 2016     4 19180]\n [ 2016     5 19180]\n [ 2016     6 19180]\n [ 2016     7 19180]\n [ 2016     8 19180]\n [ 2016     9 19180]\n [ 2016    10 19180]\n [ 2016    11 19180]\n [ 2016    12 19180]\n [ 2017     1 25349]\n [ 2017     2 25349]\n [ 2017     3 25349]\n [ 2017     4 25349]\n [ 2017     5 25349]\n [ 2017     6 25349]\n [ 2017     7 25349]\n [ 2017     8 25349]\n [ 2017     9 25349]\n [ 2017    10 25349]\n [ 2017    11 25349]\n [ 2017    12 25349]\n [ 2018     1 24130]\n [ 2018     2 24130]\n [ 2018     3 24130]\n [ 2018     4 24130]\n [ 2018     5 24130]\n [ 2018     6 24130]\n [ 2018     7 24130]\n [ 2018     8 24130]\n [ 2018     9 24130]\n [ 2018    10 24130]\n [ 2018    11 24130]\n [ 2018    12 24130]]\n"}],"source":["## monthly Lychee yield 2004 - 2018 but use yearly yield\n","monthly_lychee_yearlyyield = np.array([1,1,1]).reshape(1,3)\n","\n","all_year, sub_year_dic = rain_df_clean.groupby_col('year')\n","\n","for year in all_year:\n","        all_month, _ = sub_year_dic[year].groupby_mean('month')\n","\n","        for month in all_month:\n","                # record year month and lychee yield of each month\n","                monthly_lychee_temp = lychee_yield_df.loc[lychee_yield_df['year']==year,:]\n","                if monthly_lychee_temp.size != 0:\n","                    monthly_yield = np.array([year, month, monthly_lychee_temp.iloc[0, -2]]).reshape(1,3)\n","                    monthly_lychee_yearlyyield = np.append(monthly_lychee_yearlyyield, monthly_yield, axis = 0)\n","\n","monthly_lychee_yearlyyield = np.delete(monthly_lychee_yearlyyield, 0, axis = 0)\n","print(monthly_lychee_yearlyyield)"]},{"cell_type":"code","execution_count":226,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"(156, 3)\n"}],"source":["## monthly yield per area 2006 - 2018\n","monthly_area = np.array([1,1,1]).reshape(1,3)\n","\n","all_year, _ = rain_df_clean.groupby_col('year')\n","for year in all_year:\n","        all_month, _ = sub_year_dic[year].groupby_mean('month')\n","\n","        for month in all_month:\n","                # record year month and lychee yield of each month\n","                monthly_area_temp = area_df.loc[area_df['year']==year,:]\n","                if monthly_area_temp.size != 0:\n","                    monthly_area_temp = np.array([year, month, monthly_area_temp.iloc[0, -1]]).reshape(1,3)\n","                    monthly_area = np.append(monthly_area, monthly_area_temp, axis = 0)\n","\n","monthly_area = np.delete(monthly_area, 0, axis = 0)\n","print(monthly_area.shape)"]},{"cell_type":"code","execution_count":227,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"(156, 3)\n"}],"source":["## monthly all yield area 2006 - 2018\n","monthly_yieldarea = np.array([1,1,1]).reshape(1,3)\n","\n","all_year, _ = rain_df_clean.groupby_col('year')\n","\n","for year in all_year:\n","        all_month, _ = sub_year_dic[year].groupby_mean('month')\n","\n","        for month in all_month:\n","                # record year month and lychee yield of each month\n","                monthly_area_temp = area_df.loc[area_df['year']==year,:]\n","                if monthly_area_temp.size != 0:\n","                    monthly_area_temp = np.array([year, month, monthly_area_temp.iloc[0, 4]]).reshape(1,3)\n","                    monthly_yieldarea = np.append(monthly_yieldarea, monthly_area_temp, axis = 0)\n","\n","monthly_yieldarea = np.delete(monthly_yieldarea, 0, axis = 0)\n","print(monthly_area.shape)"]},{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":["<h1> Rearrange for daily data </h1>"]},{"cell_type":"code","execution_count":60,"metadata":{},"outputs":[],"source":["## daily Temp 2006 - 2019\n","daily_temp = np.array([1,1,1,1]).reshape(1,4)\n","\n","# get yearly dic\n","all_year, sub_year_dic = temp_df_clean.groupby_col('year')\n","\n","for year in all_year:\n","        # get monthly dic\n","        all_month, sub_month_dic = sub_year_dic[year].groupby_col('month')\n","\n","        for month in all_month:\n","            # get daily dic\n","            all_day, sub_day_dic = sub_month_dic[month].groupby_mean('day')       \n","\n","            for day in all_day:\n","                # get daily dataframe\n","                sub_day_df = sub_day_dic[day]\n","                daily_tempo = np.array([year, month, day, sub_day_df.iloc[-1]]).reshape(1,4)\n","                daily_temp = np.append(daily_temp, daily_tempo, axis = 0)\n","\n","daily_temp = np.delete(daily_temp, 0, axis = 0)\n","print(daily_temp[:6, :])"]},{"cell_type":"code","execution_count":61,"metadata":{},"outputs":[],"source":["## daily humid 2006 - 2019\n","daily_humid = np.array([1,1,1,1]).reshape(1,4)\n","\n","# get yearly dic\n","all_year, sub_year_dic = humid_df_clean.groupby_col('year')\n","\n","for year in all_year:\n","        # get monthly dic\n","        all_month, sub_month_dic = sub_year_dic[year].groupby_col('month')\n","\n","        for month in all_month:\n","            # get daily dic\n","            all_day, sub_day_dic = sub_month_dic[month].groupby_mean('day')       \n","\n","            for day in all_day:\n","                # get daily dataframe\n","                sub_day_df = sub_day_dic[day]\n","                daily_tempo = np.array([year, month, day, sub_day_df.iloc[-1]]).reshape(1,4)\n","                daily_humid = np.append(daily_humid, daily_tempo, axis = 0)\n","\n","daily_humid = np.delete(daily_humid, 0, axis = 0)\n","print(daily_humid.shape)"]},{"cell_type":"code","execution_count":62,"metadata":{},"outputs":[],"source":["## daily rain 2006 - 2019\n","daily_rain = np.array([1,1,1,1]).reshape(1,4)\n","\n","# get yearly dic\n","all_year, sub_year_dic = rain_df_clean.groupby_col('year')\n","\n","for year in all_year:\n","        # get monthly dic\n","        all_month, sub_month_dic = sub_year_dic[year].groupby_col('month')\n","\n","        for month in all_month:\n","            # get daily dic\n","            all_day, sub_day_dic = sub_month_dic[month].groupby_mean('day')       \n","\n","            for day in all_day:\n","                # get daily dataframe\n","                sub_day_df = sub_day_dic[day]\n","                daily_tempo = np.array([year, month, day, sub_day_df.iloc[-1]]).reshape(1,4)\n","                daily_rain = np.append(daily_rain, daily_tempo, axis = 0)\n","\n","daily_rain = np.delete(daily_rain, 0, axis = 0)\n","print(daily_rain.shape)"]},{"cell_type":"code","execution_count":63,"metadata":{},"outputs":[],"source":["## daily Lychee yield 2006 - 2018\n","daily_lychee = np.array([1,1,1,1]).reshape(1,4)\n","\n","all_year, sub_year_dic = rain_df_clean.groupby_col('year')\n","\n","for year in all_year:\n","        all_month, sub_month_dic = sub_year_dic[year].groupby_col('month')\n","        # record year month and lychee yield of each month\n","        daily_lychee_temp = lychee_yield_df.loc[lychee_yield_df['year']==year,:]\n","\n","        for month in all_month:\n","\n","                # get daily dic\n","                all_day, _ = sub_month_dic[month].groupby_mean('day')       \n","\n","                for day in all_day:    \n","\n","                    if daily_lychee_temp.size != 0:\n","                        # print(year, ' : ', month)\n","                        # print(daily_lychee_temp.iloc[0, month-1])\n","                        daily_yield = np.array([year, month, day, daily_lychee_temp.iloc[0, month-1]]).reshape(1,4)\n","                        daily_lychee = np.append(daily_lychee, daily_yield, axis = 0)\n","\n","daily_lychee = np.delete(daily_lychee, 0, axis = 0)\n","print(daily_lychee[:6, :])"]},{"cell_type":"code","execution_count":64,"metadata":{},"outputs":[],"source":["## daily Lychee yield 2006 - 2018 yearlyyield\n","daily_lychee_yearlyyield = np.array([1,1,1,1]).reshape(1,4)\n","all_year, sub_year_dic = rain_df_clean.groupby_col('year')\n","\n","for year in all_year:\n","        all_month, sub_month_dic = sub_year_dic[year].groupby_col('month')\n","        # record year month and lychee yield of each month\n","        daily_lychee_temp = lychee_yield_df.loc[lychee_yield_df['year']==year,:]\n","\n","        for month in all_month:\n","\n","                # get daily dic\n","                all_day, _ = sub_month_dic[month].groupby_mean('day')       \n","\n","                for day in all_day:    \n","\n","                    if daily_lychee_temp.size != 0:\n","                        # print(year, ' : ', month)\n","                        # print(daily_lychee_temp.iloc[0, month-1])\n","                        daily_yield = np.array([year, month, day, daily_lychee_temp.iloc[0, -2]]).reshape(1,4)\n","                        daily_lychee_yearlyyield = np.append(daily_lychee_yearlyyield, daily_yield, axis = 0)\n","\n","daily_lychee_yearlyyield = np.delete(daily_lychee_yearlyyield, 0, axis = 0)\n","print(daily_lychee_yearlyyield[:6, :])"]},{"cell_type":"code","execution_count":65,"metadata":{},"outputs":[],"source":["## daily yield per area 2006 - 2018\n","daily_area = np.array([1,1,1,1]).reshape(1,4)\n","\n","all_year, sub_year_dic = rain_df_clean.groupby_col('year')\n","\n","for year in all_year:\n","        all_month, sub_month_dic = sub_year_dic[year].groupby_col('month')\n","        # record year month and lychee yield of each month\n","        area_temp = area_df.loc[area_df['year']==year,:]        \n","\n","        for month in all_month:\n","\n","                # get daily dic\n","                all_day, _ = sub_month_dic[month].groupby_mean('day')       \n","\n","                for day in all_day:    \n","\n","                    if area_temp.size != 0:\n","                        daily_area_temp = np.array([year, month, day, area_temp.iloc[0, -1]]).reshape(1,4)\n","                        daily_area = np.append(daily_area, daily_area_temp, axis = 0)\n","\n","daily_area = np.delete(daily_area, 0, axis = 0)\n","print(daily_area.shape)"]},{"cell_type":"code","execution_count":66,"metadata":{},"outputs":[],"source":["## daily yield per area 2006 - 2018\n","daily_yieldarea = np.array([1,1,1,1]).reshape(1,4)\n","\n","all_year, sub_year_dic = rain_df_clean.groupby_col('year')\n","\n","for year in all_year:\n","        all_month, sub_month_dic = sub_year_dic[year].groupby_col('month')\n","        # record year month and lychee yield of each month\n","        area_temp = area_df.loc[area_df['year']==year,:]        \n","\n","        for month in all_month:\n","\n","                # get daily dic\n","                all_day, _ = sub_month_dic[month].groupby_mean('day')       \n","\n","                for day in all_day:    \n","\n","                    if area_temp.size != 0:\n","                        daily_area_temp = np.array([year, month, day, area_temp.iloc[0, 4]]).reshape(1,4)\n","                        daily_yieldarea = np.append(daily_yieldarea, daily_area_temp, axis = 0)\n","\n","daily_yieldarea = np.delete(daily_yieldarea, 0, axis = 0)\n","print(daily_yieldarea.shape)"]},{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":["<h1> Rearrange for 3-hourly data </h1>"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["## hourly Temp 2004 - 2019\n","threehourly_temp = np.array([1,1,1,1,1]).reshape(1,5)\n","\n","# get yearly dic\n","all_year, sub_year_dic = temp_df_clean.groupby_col('year')\n","\n","for year in all_year:\n","        # get monthly dic\n","        all_month, sub_month_dic = sub_year_dic[year].groupby_col('month')\n","\n","        for month in all_month:\n","            # get daily dic\n","            all_day, sub_day_dic = sub_month_dic[month].groupby_col('day')       \n","\n","            for day in all_day:\n","                # get daily dataframe\n","                sub_day_df = sub_day_dic[day]\n","\n","                for hour in ['1', '4', '7', '10', '13', '16', '19', '22']:\n","                    threehourly_tempo = np.array([year, month, day, int(hour), sub_day_df[hour]]).reshape(1,5)\n","                    threehourly_temp = np.append(threehourly_temp, threehourly_tempo, axis = 0)\n","\n","threehourly_temp = np.delete(threehourly_temp, 0, axis = 0)\n","print(threehourly_temp.shape)"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["## hourly Humid 2004 - 2019\n","threehourly_humid = np.array([1,1,1,1,1]).reshape(1,5)\n","\n","# get yearly dic\n","all_year, sub_year_dic = humid_df_clean.groupby_col('year')\n","\n","for year in all_year:\n","        # get monthly dic\n","        all_month, sub_month_dic = sub_year_dic[year].groupby_col('month')\n","\n","        for month in all_month:\n","            # get daily dic\n","            all_day, sub_day_dic = sub_month_dic[month].groupby_col('day')       \n","\n","            for day in all_day:\n","                # get daily dataframe\n","                sub_day_df = sub_day_dic[day]\n","\n","                for hour in ['1', '4', '7', '10', '13', '16', '19', '22']:\n","                    threehourly_tempo = np.array([year, month, day, int(hour), sub_day_df[hour]]).reshape(1,5)\n","                    threehourly_humid = np.append(threehourly_humid, threehourly_tempo, axis = 0)\n","\n","threehourly_humid = np.delete(threehourly_humid, 0, axis = 0)\n","print(threehourly_humid.shape)"]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[],"source":["## hourly Rain 2004 - 2019\n","threehourly_rain = np.array([1,1,1,1,1]).reshape(1,5)\n","\n","# get yearly dic\n","all_year, sub_year_dic = rain_df_clean.groupby_col('year')\n","\n","for year in all_year:\n","        # get monthly dic\n","        all_month, sub_month_dic = sub_year_dic[year].groupby_col('month')\n","\n","        for month in all_month:\n","            # get daily dic\n","            all_day, sub_day_dic = sub_month_dic[month].groupby_col('day')       \n","\n","            for day in all_day:\n","                # get daily dataframe\n","                sub_day_df = sub_day_dic[day]\n","\n","                for hour in ['1', '4', '7', '10', '13', '16', '19', '22']:\n","                    threehourly_tempo = np.array([year, month, day, int(hour), sub_day_df[hour]]).reshape(1,5)\n","                    threehourly_rain = np.append(threehourly_rain, threehourly_tempo, axis = 0)\n","\n","threehourly_rain = np.delete(threehourly_rain, 0, axis = 0)\n","print(threehourly_rain.shape)"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[],"source":["## hourly Lychee yield 2004 - 2018\n","threehourly_lychee = np.array([1,1,1,1,1]).reshape(1,5)\n","\n","all_year, sub_year_dic = rain_df_clean.groupby_col('year')\n","\n","for year in all_year:\n","    all_month, sub_month_dic = sub_year_dic[year].groupby_col('month')\n","    monthly_lychee_temp = lychee_yield_df.loc[lychee_yield_df['year']==year,:]\n","\n","    for month in all_month:\n","        # get daily dic\n","        all_day, _ = sub_month_dic[month].groupby_col('day')       \n","\n","        for day in all_day:                \n","            for hour in ['1', '4', '7', '10', '13', '16', '19', '22']:\n","                if monthly_lychee_temp.size != 0:\n","                    threehourly_yield = np.array([year, month, day, int(hour), monthly_lychee_temp.iloc[0, month-1]]).reshape(1,5)\n","                    threehourly_lychee = np.append(threehourly_lychee, threehourly_yield, axis = 0)\n","\n","threehourly_lychee = np.delete(threehourly_lychee, 0, axis = 0)\n","print(threehourly_lychee.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## hourly Lychee yield 2004 - 2018 yearlyyield\n","threehourly_lychee_lycheeyield = np.array([1,1,1,1,1]).reshape(1,5)\n","\n","all_year, sub_year_dic = rain_df_clean.groupby_col('year')\n","\n","for year in all_year:\n","    all_month, sub_month_dic = sub_year_dic[year].groupby_col('month')\n","    monthly_lychee_temp = lychee_yield_df.loc[lychee_yield_df['year']==year,:]\n","\n","    for month in all_month:\n","        # get daily dic\n","        all_day, _ = sub_month_dic[month].groupby_col('day')       \n","\n","        for day in all_day:                \n","            for hour in ['1', '4', '7', '10', '13', '16', '19', '22']:\n","                if monthly_lychee_temp.size != 0:\n","                    threehourly_yield = np.array([year, month, day, int(hour), monthly_lychee_temp.iloc[0, month-1]]).reshape(1,5)\n","                    threehourly_lychee_lycheeyield = np.append(threehourly_lychee_lycheeyield, threehourly_yield, axis = 0)\n","\n","threehourly_lychee_lycheeyield = np.delete(threehourly_lychee_lycheeyield, 0, axis = 0)\n","print(threehourly_lychee_lycheeyield[:6,:])"]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[],"source":["## hourly yield per area 2004 - 2018\n","threehourly_area = np.array([1,1,1,1,1]).reshape(1,5)\n","\n","all_year, sub_year_dic = rain_df_clean.groupby_col('year')\n","\n","for year in all_year:\n","    all_month, sub_month_dic    = sub_year_dic[year].groupby_col('month')\n","    monthly_area_temp         = area_df.loc[area_df['year']==year,:]\n","\n","    for month in all_month:\n","        # get daily dic\n","        all_day, _ = sub_month_dic[month].groupby_col('day')       \n","\n","        for day in all_day:                \n","            for hour in ['1', '4', '7', '10', '13', '16', '19', '22']:\n","                if monthly_area_temp.size != 0:\n","                    threehourly_area_temp = np.array([year, month, day, int(hour), monthly_area_temp.iloc[0, -1]]).reshape(1,5)\n","                    threehourly_area = np.append(threehourly_area, threehourly_area_temp, axis = 0)\n","\n","threehourly_area = np.delete(threehourly_area, 0, axis = 0)\n","print(threehourly_area.shape)"]},{"cell_type":"code","execution_count":39,"metadata":{},"outputs":[],"source":["## hourly all area 2004 - 2018\n","threehourly_yieldarea = np.array([1,1,1,1,1]).reshape(1,5)\n","\n","all_year, sub_year_dic = rain_df_clean.groupby_col('year')\n","\n","for year in all_year:\n","    all_month, sub_month_dic    = sub_year_dic[year].groupby_col('month')\n","    monthly_area_temp           = area_df.loc[area_df['year']==year,:]\n","\n","    for month in all_month:\n","        # get daily dic\n","        all_day, _ = sub_month_dic[month].groupby_col('day')       \n","\n","        for day in all_day:                \n","            for hour in ['1', '4', '7', '10', '13', '16', '19', '22']:\n","                if monthly_area_temp.size != 0:\n","                    threehourly_area_temp = np.array([year, month, day, int(hour), monthly_area_temp.iloc[0, 4]]).reshape(1,5)\n","                    threehourly_yieldarea = np.append(threehourly_yieldarea, threehourly_area_temp, axis = 0)\n","\n","threehourly_yieldarea = np.delete(threehourly_yieldarea, 0, axis = 0)\n","print(threehourly_yieldarea.shape)"]},{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":["Intersected\n"," year of all data is 2004 - 2018"]},{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":["<h1> Method for getting X data </h1>"]},{"cell_type":"code","execution_count":228,"metadata":{},"outputs":[],"source":["def split_x_sequence(X, n_steps, ind_output):\n","    \n","    X_seq = np.ones((1, n_steps))\n","\n","    for i in range(X.shape[0]):\n","        \n","        if i+n_steps > X.shape[0] - 1:\n","            break\n","        x_seq_temp = X[i:i+n_steps, ind_output].reshape(1,-1)\n","        X_seq = np.append(X_seq, x_seq_temp, axis = 0)\n","    \n","    return X_seq[1:,:]\n","\n","def split_y_sequence(X, n_steps, ind_output, repeat):\n","    \n","    # repeat = False return only target\n","    # repeat = true return target with multiple row\n","    X_seq = np.ones((1, 1)) if repeat == False else np.ones((1, n_steps))\n","\n","    for i in range(X.shape[0]):\n","        \n","        if i+n_steps > X.shape[0] - 1:\n","            break\n","        x_seq_temp = X[i+n_steps, ind_output].reshape(1, -1) if repeat == False else  X[i+n_steps, ind_output]*np.ones((1, n_steps))\n","        X_seq = np.append(X_seq, x_seq_temp, axis = 0)\n","    \n","    return X_seq[1:,:]"]},{"cell_type":"code","execution_count":229,"metadata":{},"outputs":[],"source":["def get_XY_fr_resolution(df_list_input, df_list_output, n_steps, req_m_input = [1, 2], req_month = [4, 5, 6], axis = 1, yearlyyield = False):\n","\n","    df_copy_list  = list()\n","    X             = list()\n","\n","    # extract X\n","    count = 0\n","    for df, xy_split in df_list_input:\n","        df_copy = df.copy()\n","        ind_2004_2018 = np.logical_and(df_copy[:, 0] >= 2004, df_copy[:, 0] <= 2018)\n","        df_copy = df_copy[ind_2004_2018,:]\n","\n","        # find index only for required input month\n","        if yearlyyield and count == 0:\n","            count = count + 1\n","            req_m_ind = np.zeros((df_copy.shape[0],))\n","            for i in req_m_input:\n","                req_m_ind = np.logical_or(req_m_ind, (df_copy[:,1] == i).reshape(-1,))\n","\n","        df_copy = df_copy[req_m_ind, :]\n","\n","        if xy_split == 'x':\n","            X_temp = split_x_sequence(df_copy, n_steps, -1)\n","            print('true')\n","            print(X_temp.shape)\n","        if xy_split == 'y':\n","            X_temp = split_y_sequence(df_copy, n_steps, -1, True) if axis == 2 else split_y_sequence(df_copy, n_steps, -1, False)\n","      \n","        X_temp = X_temp.reshape(X_temp.shape[0], X_temp.shape[1], 1)\n","        X.append(X_temp)\n","\n","    # axis = 2 for rnn and axis = 1 for lr and svr\n","    X = np.concatenate(X, axis = axis)\n","\n","    # extract y\n","    Y = split_y_sequence(df_list_output[0], n_steps, -1, False) if yearlyyield == False else split_y_sequence(df_list_output[0][req_m_ind, :], n_steps, -1, False)  \n","\n","    # get only the data from required month\n","    all_year    = np.unique(df_copy[:, 0])\n","    all_month   = np.unique(df_copy[:, 1]) if yearlyyield == False else np.array([])\n","    req_ind     = np.zeros((X_temp.shape[0], 1))\n","    for year in all_year:\n","        for month in req_month:\n","            year_ind = df_copy[n_steps:, 0] == year\n","            \n","            if yearlyyield == False:\n","                month_ind = df_copy[n_steps:, 1] == month\n","                ym_ind = year_ind*month_ind\n","            else:\n","                ym_ind = year_ind\n","\n","            ym_ind_where = np.where(ym_ind == 1)\n","            \n","            if len(ym_ind_where[0]) != 0:\n","                if yearlyyield == False:\n","                    # get only the data from required month only at the first index\n","                    first_ind = ym_ind_where[0][0]\n","\n","                else:\n","                    # get only the data from the last index of each year\n","                    first_ind = ym_ind_where[0][0]                  \n","\n","                ym_ind = np.zeros((ym_ind.shape[0], 1))\n","                \n","                try:\n","                    ym_ind[first_ind] = 1\n","                except:\n","                    pass\n","\n","                ym_ind  = ym_ind.reshape(-1, 1)\n","                req_ind = req_ind + ym_ind\n","\n","    req_ind = req_ind.astype(bool).reshape(-1)\n","    X = X[req_ind, :, :]\n","    Y = Y[req_ind]\n","    if axis == 1:\n","        X = X.reshape(X.shape[0], X.shape[1])\n","        Y = Y.reshape(Y.shape[0])\n","\n","    n_features = X.shape[2] if axis == 2 else X.shape[1]\n","    n_size      = X.shape[0]\n","\n","    year_target = df_copy[n_steps:, 0][req_ind]\n","    month_target = df_copy[n_steps:, 1][req_ind] if yearlyyield == False else np.array([])\n","\n","    return X, Y, n_features, n_size, n_steps, year_target, month_target"]},{"cell_type":"code","execution_count":230,"metadata":{},"outputs":[],"source":["def rmse(y_true, y_pred):\n","\n","    ind_ignorezero = (y_true != 0).reshape(-1,)\n","    error = (y_true - y_pred)\n","    se = error**2\n","    mse = np.mean(se)\n","    rmse = mse**0.5\n","    return rmse"]},{"cell_type":"code","execution_count":231,"metadata":{},"outputs":[],"source":["def mape(y_true, y_pred):\n","    error = y_true - y_pred\n","    pe     = (y_true - y_pred)/y_true*100\n","    ape = np.abs(pe)\n","    mape = np.mean(ape)\n","\n","    return mape    "]},{"cell_type":"code","execution_count":232,"metadata":{},"outputs":[],"source":["def mae(y_true, y_pred):\n","\n","    error = y_true - y_pred\n","    ae = np.abs(error)\n","    mae = np.mean(ae)\n","\n","    return mae"]},{"cell_type":"code","execution_count":233,"metadata":{},"outputs":[],"source":["def r2(y_true, y_pred):\n","    y_mean  = np.mean(y_true)\n","    Stot    = np.sum((y_true - y_mean)**2)\n","    Sres    = np.sum((y_true - y_pred)**2)\n","    r_square    = 1 - Sres/Stot\n","\n","    return r_square"]},{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":["Get y"]},{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":["<h1> Feature selection </h1>\n","Year (of the target), Month (of the target), Avg.Temp (3 and 4 month before), Avg.Humid (3 and 4 month before),\n","Rain amount (3 and 4 month before), lychee yield per area (1 year before), number of the day in target month,\n","lychee yield (of target month but 1 year before)"]},{"cell_type":"code","execution_count":338,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"true\n(24, 2)\n"}],"source":["choose = 'monthly_yearlyyield'\n","\n","if choose == 'monthly_yearlyyield_wyear':\n","    yearlyyield = True\n","    input_vec = [\n","        [monthly_temp, 'x'],\n","        # [monthly_humid, 'x'], \n","        # [monthly_rain, 'x'], \n","        # [monthly_area, 'x'], \n","        # [monthly_yieldarea, 'x'], \n","        # [monthly_lychee, 'x'],\n","        [monthly_yieldarea[:,0].reshape(-1,1), 'y']]   # target year\n","\n","    output_vec = [monthly_lychee_yearlyyield]\n","\n","if choose == 'monthly_yearlyyield_woyear':\n","    yearlyyield = True\n","    input_vec = [\n","        [monthly_temp, 'x'],\n","        # [monthly_humid, 'x'], \n","        # [monthly_rain, 'x'], \n","        # [monthly_area, 'x'], \n","        # [monthly_yieldarea, 'x'], \n","        # [monthly_lychee, 'x'],\n","        ]#[monthly_yieldarea[:,0].reshape(-1,1), 'y']]   # target year\n","\n","    output_vec = [monthly_lychee_yearlyyield]\n","if choose == 'test':\n","    input_vec = [\n","        [daily_temp, 'x'], \n","        [daily_yieldarea[:,0].reshape(-1,1), 'y'],   # target year\n","        [daily_yieldarea[:,0:2].reshape(-1,2), 'y']] # target month\n","\n","    output_vec = [daily_lychee]\n","\n","if choose == 'monthly':\n","    yearlyyield = False\n","    input_vec = [\n","        [monthly_temp, 'x'],\n","        # [monthly_humid, 'x'], \n","        # [monthly_rain, 'x'], \n","        # [monthly_area, 'x'], \n","        [monthly_yieldarea, 'x'], \n","        [monthly_lychee, 'x'], \n","        [monthly_yieldarea[:,0].reshape(-1,1), 'y'],   # target year\n","        [monthly_yieldarea[:,0:2].reshape(-1,2), 'y']] # target month\n","    \n","    output_vec = [monthly_lychee]\n","\n","if choose == 'daily':\n","    yearlyyield = False\n","    input_vec = [\n","        [daily_temp, 'x'],\n","        [daily_humid, 'x'], \n","        # [daily_rain, 'x'], \n","        # [daily_area, 'x'], \n","        # [daily_yieldarea, 'x'], \n","        [daily_lychee, 'x'], \n","        [daily_yieldarea[:,0].reshape(-1,1), 'y'],   # target year\n","        [daily_yieldarea[:,0:2].reshape(-1,2), 'y']] # target month\n","\n","    output_vec = [daily_lychee]\n","\n","if choose == 'hourly':\n","    yearlyyield = False\n","    input_vec = [\n","        [hourly_temp, 'x'],\n","        # [hourly_humid, 'x'], \n","        # [hourly_rain, 'x'], \n","        # [hourly_area, 'x'], \n","        [hourly_yieldarea, 'x'], \n","        [hourly_lychee, 'x'], \n","        [hourly_yieldarea[:,0].reshape(-1,1), 'y'],   # target year\n","        [hourly_yieldarea[:,0:2].reshape(-1,2), 'y']] # target month\n","\n","    output_vec = [hourly_lychee]\n","\n","# daily choose n_steps = 240\n","# hourly choose n_steps = 1920\n","# monthly choose n_steps = 4\n","# axis = 2 for rnn\n","\n","X, Y, n_features, n_size, n_steps, year_target, month_target = get_XY_fr_resolution(input_vec, output_vec, n_steps = 2, axis = 1, req_m_input = [1, 2], req_month = [4, 5, 6], yearlyyield = yearlyyield)"]},{"cell_type":"code","execution_count":339,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"X Shape\n(12, 3)\nY Shape\n(12,)\nn features\n3\nsample size\n12\n"}],"source":["print('X Shape')\n","print(X.shape)\n","print('Y Shape')\n","print(Y.shape)\n","print('n features')\n","print(n_features)\n","print('sample size')\n","print(n_size)"]},{"cell_type":"code","execution_count":340,"metadata":{},"outputs":[],"source":["# print(X)"]},{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":["Seperate train set and test set for displaying"]},{"cell_type":"code","execution_count":341,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"train size\n(8, 3)\ntest size\n(4, 3)\n"}],"source":["X_train, X_test, Y_train, Y_test =  train_test_split(X, Y, test_size=0.3)\n","X_train_ord = X[:int(n_size*(1-0.3)), :]\n","X_test_ord  = X[int(n_size*(1-0.3)):, :]\n","Y_train_ord = Y[:int(n_size*(1-0.3))]\n","Y_test_ord  = Y[int(n_size*(1-0.3)):]\n","print('train size')\n","print(X_train.shape)\n","print('test size')\n","print(X_test.shape)"]},{"cell_type":"markdown","execution_count":216,"metadata":{},"outputs":[],"source":["<h1> Ridge Model w/o Normalization </h1>"]},{"cell_type":"code","execution_count":313,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"(12, 3)\nRidge(alpha=200, copy_X=True, fit_intercept=True, max_iter=None,\n   normalize=False, random_state=None, solver='auto', tol=0.001)\n"}],"source":["# vector for record error\n","train_mae = np.array([])\n","test_mae = np.array([])\n","\n","train_rmse = np.array([])\n","test_rmse = np.array([])\n","\n","train_r2 = np.array([])\n","test_r2 = np.array([])\n","\n","# using grid searchcv to optimize hyper param\n","reg_lr  = Ridge()\n","param   = {'alpha':[0.01, 0.001, 0.1, 0.5, 1, 5, 10, 100, 200, 300, 400, 1000, 10e4, 10e5]}\n","gsc     = GridSearchCV(reg_lr, param, cv = 3)\n","print(X.shape)\n","gsc.fit(X, np.log1p(Y))\n","\n","reg_lr  = gsc.best_estimator_\n","print(gsc.best_estimator_)"]},{"cell_type":"code","execution_count":322,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"train MAE 5501.66\ttest MAE 2387.15\ntrain RMSE 6274.74\ttest RMSE 2958.93\ntrain MAPE 25.60\ttest MAPE 10.63\n=========================\nyear 2007 true : 23229\tpred : 22037\nyear 2008 true : 19089\tpred : 22102\nyear 2009 true : 27922\tpred : 22389\nyear 2010 true : 16052\tpred : 22641\nyear 2011 true : 14033\tpred : 22761\nyear 2012 true : 30097\tpred : 22939\nyear 2013 true : 24997\tpred : 23184\nyear 2014 true : 33525\tpred : 23537\nyear 2015 true : 27016\tpred : 23470\nyear 2016 true : 19180\tpred : 23673\nyear 2017 true : 25349\tpred : 23846\nyear 2018 true : 24130\tpred : 24124\n"}],"source":["reg_lr.fit(X_train_ord, np.log1p(Y_train_ord))\n","\n","Y_all_test = reg_lr.predict(X)\n","Y_all_test[Y_all_test<0] = 0\n","\n","Y_all_test = np.expm1(Y_all_test)\n","\n","train_mae = mae(Y[:int(n_size*(1-0.3))], Y_all_test[:int(n_size*(1-0.3))])\n","test_mae = mae(Y[int(n_size*(1-0.3)):], Y_all_test[int(n_size*(1-0.3)):])\n","\n","train_rmse = rmse(Y[:int(n_size*(1-0.3))], Y_all_test[:int(n_size*(1-0.3))])\n","test_rmse = rmse(Y[int(n_size*(1-0.3)):], Y_all_test[int(n_size*(1-0.3)):])\n","\n","train_mape = mape(Y[:int(n_size*(1-0.3))], Y_all_test[:int(n_size*(1-0.3))])\n","test_mape = mape(Y[int(n_size*(1-0.3)):], Y_all_test[int(n_size*(1-0.3)):])\n","\n","print('train MAE {:.2f}\\ttest MAE {:.2f}'.format(train_mae, test_mae))\n","print('train RMSE {:.2f}\\ttest RMSE {:.2f}'.format(train_rmse, test_rmse))\n","print('train MAPE {:.2f}\\ttest MAPE {:.2f}'.format(train_mape, test_mape))\n","print('=========================')\n","\n","if yearlyyield == False:\n","    for year, month, y_true, y_pred in zip(year_target, month_target, Y, Y_all_test):\n","        print('year {:.0f} month {:.0f} true : {:.0f}\\tpred : {:.0f}'.format(year, month, y_true, y_pred))\n","else:\n","    for year, y_true, y_pred in zip(year_target, Y, Y_all_test):\n","        print('year {:.0f} true : {:.0f}\\tpred : {:.0f}'.format(year, y_true, y_pred))   "]},{"cell_type":"code","execution_count":323,"metadata":{},"outputs":[],"source":["# export output\n","# X_rnn[:int(train_ratio*n_size), :, :]\n","year_train  = year_target[:int(n_size*(1-0.3))]\n","month_train = month_target[:int(n_size*(1-0.3))] if yearlyyield == False else year_train\n","year_test   = year_target[int(n_size*(1-0.3)):]\n","month_test  = month_target[int(n_size*(1-0.3)):] if yearlyyield == False else year_test\n","y_train_true = Y[:int(n_size*(1-0.3))]\n","y_train_pred = Y_all_test[:int(n_size*(1-0.3))]\n","y_test_true = Y[int(n_size*(1-0.3)):]\n","y_test_pred = Y_all_test[int(n_size*(1-0.3)):]\n","export_output('ridge_wonorm_results_monthly_input_yearly_output.xlsx', year_train, month_train, y_train_true, y_train_pred, year_test, month_test, y_test_true, y_test_pred)"]},{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":["<h1> Ridge Model w Normalization </h1>"]},{"cell_type":"code","execution_count":311,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"Pipeline(memory=None,\n     steps=[('normalize', MinMaxScaler(copy=True, feature_range=(0, 1))), ('lr', Ridge(alpha=10, copy_X=True, fit_intercept=True, max_iter=None,\n   normalize=False, random_state=None, solver='auto', tol=0.001))])\n"}],"source":["# vector for record error\n","train_mae = np.array([])\n","test_mae = np.array([])\n","\n","train_rmse = np.array([])\n","test_rmse = np.array([])\n","\n","train_r2 = np.array([])\n","test_r2 = np.array([])\n","\n","# using grid searchcv to optimize hyper param\n","estimators = [('normalize', MinMaxScaler()), ('lr', Ridge())]\n","pipe    = Pipeline(estimators)\n","param   = dict(lr__alpha=[0.01, 0.001, 0.1, 0.5, 1, 5, 10, 100, 10e3, 10e4])\n","\n","gsc     = GridSearchCV(pipe, param, cv = 3)\n","gsc.fit(X, np.log1p(Y))\n","\n","reg_lr_norm  = gsc.best_estimator_\n","print(gsc.best_estimator_)"]},{"cell_type":"code","execution_count":312,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"train MAE 5544.55\ttest MAE 2742.87\ntrain RMSE 6342.59\ttest RMSE 3052.73\ntrain MAPE 25.75\ttest MAPE 11.84\n=========================\nyear 2007 true : 23229\tpred : 22353\nyear 2008 true : 19089\tpred : 22243\nyear 2009 true : 27922\tpred : 22519\nyear 2010 true : 16052\tpred : 22702\nyear 2011 true : 14033\tpred : 22719\nyear 2012 true : 30097\tpred : 22770\nyear 2013 true : 24997\tpred : 22954\nyear 2014 true : 33525\tpred : 23308\nyear 2015 true : 27016\tpred : 22946\nyear 2016 true : 19180\tpred : 23062\nyear 2017 true : 25349\tpred : 23105\nyear 2018 true : 24130\tpred : 23355\n"}],"source":["reg_lr_norm.fit(X_train_ord, np.log1p(Y_train_ord))\n","\n","Y_all_test = reg_lr_norm.predict(X)\n","Y_all_test[Y_all_test<0] = 0\n","Y_all_test = np.expm1(Y_all_test)\n","\n","train_mae = mae(Y[:int(n_size*(1-0.3))], Y_all_test[:int(n_size*(1-0.3))])\n","test_mae = mae(Y[int(n_size*(1-0.3)):], Y_all_test[int(n_size*(1-0.3)):])\n","\n","train_rmse = rmse(Y[:int(n_size*(1-0.3))], Y_all_test[:int(n_size*(1-0.3))])\n","test_rmse = rmse(Y[int(n_size*(1-0.3)):], Y_all_test[int(n_size*(1-0.3)):])\n","\n","train_mape = mape(Y[:int(n_size*(1-0.3))], Y_all_test[:int(n_size*(1-0.3))])\n","test_mape = mape(Y[int(n_size*(1-0.3)):], Y_all_test[int(n_size*(1-0.3)):])\n","\n","print('train MAE {:.2f}\\ttest MAE {:.2f}'.format(train_mae, test_mae))\n","print('train RMSE {:.2f}\\ttest RMSE {:.2f}'.format(train_rmse, test_rmse))\n","print('train MAPE {:.2f}\\ttest MAPE {:.2f}'.format(train_mape, test_mape))\n","print('=========================')\n","\n","if yearlyyield == False:\n","    for year, month, y_true, y_pred in zip(year_target, month_target, Y, Y_all_test):\n","        print('year {:.0f} month {:.0f} true : {:.0f}\\tpred : {:.0f}'.format(year, month, y_true, y_pred))\n","else:\n","    for year, y_true, y_pred in zip(year_target, Y, Y_all_test):\n","        print('year {:.0f} true : {:.0f}\\tpred : {:.0f}'.format(year, y_true, y_pred))   "]},{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":["<h1> Support Vector Regression w/o Normalization </h1>"]},{"cell_type":"code","execution_count":315,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"Pipeline(memory=None,\n     steps=[('svr', SVR(C=0.001, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n  kernel='linear', max_iter=-1, shrinking=True, tol=0.001, verbose=False))])\n"}],"source":["# vector for record error\n","train_mae = np.array([])\n","test_mae = np.array([])\n","\n","train_rmse = np.array([])\n","test_rmse = np.array([])\n","\n","train_r2 = np.array([])\n","test_r2 = np.array([])\n","\n","# using grid searchcv to optimize hyper param\n","estimators = [('svr', SVR(kernel = 'linear', gamma = 'scale'))]\n","pipe    = Pipeline(estimators)\n","param   = dict(\n","    svr__C=[0.001, 0.01, 0.1, 0.5, 1, 5, 100],\n","    svr__epsilon = [0.001, 0.01, 0.1, 0.5, 1])\n","\n","gsc     = GridSearchCV(pipe, param, cv = 2)\n","# gsc.fit(X, np.log1p(Y))\n","gsc.fit(X, Y)\n","\n","reg_svr  = gsc.best_estimator_\n","print(gsc.best_estimator_)"]},{"cell_type":"code","execution_count":316,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"train MAE 5259.46\ttest MAE 2383.46\ntrain RMSE 6254.88\ttest RMSE 3051.81\ntrain MAPE 25.83\ttest MAPE 11.00\n=========================\nyear 2007 month 10 true : 23229\tpred : 23276\nyear 2008 month 10 true : 19089\tpred : 23329\nyear 2009 month 10 true : 27922\tpred : 23591\nyear 2010 month 10 true : 16052\tpred : 23750\nyear 2011 month 10 true : 14033\tpred : 23945\nyear 2012 month 10 true : 30097\tpred : 24035\nyear 2013 month 10 true : 24997\tpred : 24235\nyear 2014 month 10 true : 33525\tpred : 24503\nyear 2015 month 10 true : 27016\tpred : 24397\nyear 2016 month 10 true : 19180\tpred : 24587\nyear 2017 month 10 true : 25349\tpred : 24697\nyear 2018 month 10 true : 24130\tpred : 24986\n"}],"source":["reg_svr.fit(X_train_ord, np.log1p(Y_train_ord))\n","# reg_svr.fit(X_train_ord, Y_train_ord)\n","\n","Y_all_test = reg_svr.predict(X)\n","Y_all_test[Y_all_test<0] = 0\n","Y_all_test = np.expm1(Y_all_test)\n","\n","train_mae = mae(Y[:int(n_size*(1-0.3))], Y_all_test[:int(n_size*(1-0.3))])\n","test_mae = mae(Y[int(n_size*(1-0.3)):], Y_all_test[int(n_size*(1-0.3)):])\n","\n","train_rmse = rmse(Y[:int(n_size*(1-0.3))], Y_all_test[:int(n_size*(1-0.3))])\n","test_rmse = rmse(Y[int(n_size*(1-0.3)):], Y_all_test[int(n_size*(1-0.3)):])\n","\n","train_mape = mape(Y[:int(n_size*(1-0.3))], Y_all_test[:int(n_size*(1-0.3))])\n","test_mape = mape(Y[int(n_size*(1-0.3)):], Y_all_test[int(n_size*(1-0.3)):])\n","\n","print('train MAE {:.2f}\\ttest MAE {:.2f}'.format(train_mae, test_mae))\n","print('train RMSE {:.2f}\\ttest RMSE {:.2f}'.format(train_rmse, test_rmse))\n","print('train MAPE {:.2f}\\ttest MAPE {:.2f}'.format(train_mape, test_mape))\n","print('=========================')\n","\n","if yearlyyield == False:\n","    for year, month, y_true, y_pred in zip(year_target, month_target, Y, Y_all_test):\n","        print('year {:.0f} month {:.0f} true : {:.0f}\\tpred : {:.0f}'.format(year, month, y_true, y_pred))\n","else:\n","    for year, y_true, y_pred in zip(year_target, Y, Y_all_test):\n","        print('year {:.0f} month {:.0f} true : {:.0f}\\tpred : {:.0f}'.format(year, month, y_true, y_pred))   "]},{"cell_type":"markdown","execution_count":51,"metadata":{},"outputs":[],"source":["<h1> Support Vector Regression w Normalization </h1>"]},{"cell_type":"code","execution_count":342,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"Pipeline(memory=None,\n     steps=[('normalize', MinMaxScaler(copy=True, feature_range=(0, 1))), ('svr', SVR(C=0.001, cache_size=200, coef0=0.0, degree=3, epsilon=0.001,\n  gamma='scale', kernel='linear', max_iter=-1, shrinking=True, tol=0.001,\n  verbose=False))])\n"}],"source":["# vector for record error\n","train_mae = np.array([])\n","test_mae = np.array([])\n","\n","train_rmse = np.array([])\n","test_rmse = np.array([])\n","\n","train_r2 = np.array([])\n","test_r2 = np.array([])\n","\n","# using grid searchcv to optimize hyper param\n","estimators = [('normalize', MinMaxScaler()),('svr', SVR(kernel = 'linear', gamma = 'scale'))]\n","pipe    = Pipeline(estimators)\n","param   = dict(\n","    svr__C=[0.001, 0.01, 0.1, 0.5, 1, 5, 100],\n","    svr__epsilon = [0.001, 0.01, 0.1, 0.5, 1])\n","\n","gsc     = GridSearchCV(pipe, param, cv = 2)\n","gsc.fit(X, np.log1p(Y))\n","\n","reg_svr_norm  = gsc.best_estimator_\n","print(gsc.best_estimator_)"]},{"cell_type":"code","execution_count":343,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"train MAE 5501.98\ttest MAE 2275.03\ntrain RMSE 6433.78\ttest RMSE 2932.88\ntrain MAPE 27.09\t\ttest MAPE 10.37\n=========================\nyear 2007 month 10 true : 23229\tpred : 24069\nyear 2008 month 10 true : 19089\tpred : 24066\nyear 2009 month 10 true : 27922\tpred : 24090\nyear 2010 month 10 true : 16052\tpred : 24093\nyear 2011 month 10 true : 14033\tpred : 24118\nyear 2012 month 10 true : 30097\tpred : 24112\nyear 2013 month 10 true : 24997\tpred : 24124\nyear 2014 month 10 true : 33525\tpred : 24142\nyear 2015 month 10 true : 27016\tpred : 24115\nyear 2016 month 10 true : 19180\tpred : 24130\nyear 2017 month 10 true : 25349\tpred : 24128\nyear 2018 month 10 true : 24130\tpred : 24159\n"}],"source":["reg_svr_norm.fit(X_train_ord, np.log1p(Y_train_ord))\n","\n","Y_all_test = reg_svr_norm.predict(X)\n","Y_all_test[Y_all_test<0] = 0\n","Y_all_test = np.expm1(Y_all_test)\n","\n","train_mae = mae(Y[:int(n_size*(1-0.3))], Y_all_test[:int(n_size*(1-0.3))])\n","test_mae = mae(Y[int(n_size*(1-0.3)):], Y_all_test[int(n_size*(1-0.3)):])\n","\n","train_rmse = rmse(Y[:int(n_size*(1-0.3))], Y_all_test[:int(n_size*(1-0.3))])\n","test_rmse = rmse(Y[int(n_size*(1-0.3)):], Y_all_test[int(n_size*(1-0.3)):])\n","\n","train_mape = mape(Y[:int(n_size*(1-0.3))], Y_all_test[:int(n_size*(1-0.3))])\n","test_mape = mape(Y[int(n_size*(1-0.3)):], Y_all_test[int(n_size*(1-0.3)):])\n","\n","print('train MAE {:.2f}\\ttest MAE {:.2f}'.format(train_mae, test_mae))\n","print('train RMSE {:.2f}\\ttest RMSE {:.2f}'.format(train_rmse, test_rmse))\n","print('train MAPE {:.2f}\\t\\ttest MAPE {:.2f}'.format(train_mape, test_mape))\n","print('=========================')\n","\n","if yearlyyield == False:\n","    for year, month, y_true, y_pred in zip(year_target, month_target, Y, Y_all_test):\n","        print('year {:.0f} month {:.0f} true : {:.0f}\\tpred : {:.0f}'.format(year, month, y_true, y_pred))\n","else:\n","    for year, y_true, y_pred in zip(year_target, Y, Y_all_test):\n","        print('year {:.0f} month {:.0f} true : {:.0f}\\tpred : {:.0f}'.format(year, month, y_true, y_pred))   "]},{"cell_type":"code","execution_count":344,"metadata":{},"outputs":[],"source":["# export output\n","year_train  = year_target[:int(n_size*(1-0.3))]\n","month_train = month_target[:int(n_size*(1-0.3))] if yearlyyield == False else year_train\n","year_test   = year_target[int(n_size*(1-0.3)):]\n","month_test  = month_target[int(n_size*(1-0.3)):] if yearlyyield == False else year_test\n","y_train_true = Y[:int(n_size*(1-0.3))]\n","y_train_pred = Y_all_test[:int(n_size*(1-0.3))]\n","y_test_true = Y[int(n_size*(1-0.3)):]\n","y_test_pred = Y_all_test[int(n_size*(1-0.3)):]\n","export_output('svr_wnorm_results_monthly_input_yearly_output_v3.xlsx', year_train, month_train, y_train_true, y_train_pred, year_test, month_test, y_test_true, y_test_pred)"]},{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":["<h1>Get X and y for Recurrent Neural Network</h1>"]},{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":["method for getting x data for rnn"]},{"cell_type":"code","execution_count":324,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"true\n(24, 2)\nn_steps : 2 n_features : 2 n_size : 12\n"}],"source":["choose = 'monthly_yearlyyield'\n","\n","if choose == 'monthly_yearlyyield_wyear':\n","    yearlyyield = True\n","    input_vec = [\n","        [monthly_temp, 'x'],\n","        # [monthly_humid, 'x'], \n","        # [monthly_rain, 'x'], \n","        # [monthly_area, 'x'], \n","        # [monthly_yieldarea, 'x'], \n","        # [monthly_lychee, 'x'],\n","        [monthly_yieldarea[:,0].reshape(-1,1), 'y']]   # target year\n","\n","    output_vec = [monthly_lychee_yearlyyield]\n","\n","if choose == 'monthly_yearlyyield_woyear':\n","    yearlyyield = True\n","    input_vec = [\n","        [monthly_temp, 'x'],\n","        # [monthly_humid, 'x'], \n","        # [monthly_rain, 'x'], \n","        # [monthly_area, 'x'], \n","        # [monthly_yieldarea, 'x'], \n","        # [monthly_lychee, 'x'],\n","        ]#[monthly_yieldarea[:,0].reshape(-1,1), 'y']]   # target year\n","        \n","if choose == 'test':\n","    input_vec = [\n","        [daily_temp, 'x'], \n","        [daily_yieldarea[:,0].reshape(-1,1), 'y'],   # target year\n","        [daily_yieldarea[:,0:2].reshape(-1,2), 'y']] # target month\n","\n","    output_vec = [daily_lychee]\n","\n","if choose == 'monthly':\n","    yearlyyield = False\n","    input_vec = [\n","        [monthly_temp, 'x'],\n","        # [monthly_humid, 'x'], \n","        # [monthly_rain, 'x'], \n","        # [monthly_area, 'x'], \n","        [monthly_yieldarea, 'x'], \n","        [monthly_lychee, 'x'], \n","        [monthly_yieldarea[:,0].reshape(-1,1), 'y'],   # target year\n","        [monthly_yieldarea[:,0:2].reshape(-1,2), 'y']] # target month\n","    \n","    output_vec = [monthly_lychee]\n","\n","if choose == 'daily':\n","    yearlyyield = False\n","    input_vec = [\n","        [daily_temp, 'x'],\n","        [daily_humid, 'x'], \n","        # [daily_rain, 'x'], \n","        # [daily_area, 'x'], \n","        # [daily_yieldarea, 'x'], \n","        [daily_lychee, 'x'], \n","        [daily_yieldarea[:,0].reshape(-1,1), 'y'],   # target year\n","        [daily_yieldarea[:,0:2].reshape(-1,2), 'y']] # target month\n","\n","    output_vec = [daily_lychee]\n","\n","if choose == 'hourly':\n","    yearlyyield = False\n","    input_vec = [\n","        [hourly_temp, 'x'],\n","        # [hourly_humid, 'x'], \n","        # [hourly_rain, 'x'], \n","        # [hourly_area, 'x'], \n","        [hourly_yieldarea, 'x'], \n","        [hourly_lychee, 'x'], \n","        [hourly_yieldarea[:,0].reshape(-1,1), 'y'],   # target year\n","        [hourly_yieldarea[:,0:2].reshape(-1,2), 'y']] # target month\n","\n","    output_vec = [hourly_lychee]\n","\n","# daily choose n_steps = 240\n","# hourly choose n_steps = 1920\n","# monthly choose n_steps = 4\n","# axis = 2 for rnn\n","\n","########## choose architecture of neural network\n","\n","choose = 'gru'\n","\n","X_rnn, Y_rnn, n_features, n_size, n_steps, year_target, month_target = get_XY_fr_resolution(input_vec, output_vec, n_steps = 2, axis = 1 if choose == 'ann' else 2, req_m_input = [1, 2], req_month = [4, 5, 6], yearlyyield = yearlyyield)\n","\n","print('n_steps : {:d} n_features : {:d} n_size : {:d}'.format(n_steps, n_features, n_size))"]},{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":["Seperate train set and test set with unshuffle for displaying</br>\n","test size = 53\n","train size = 124"]},{"cell_type":"code","execution_count":325,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"(8,)\n"}],"source":["train_ratio = 0.7\n","\n","X_train_ord         = X_rnn[:int(train_ratio*n_size), :] if choose == 'ann' else X_rnn[:int(train_ratio*n_size), :, :]\n","X_test_ord          = X_rnn[int(train_ratio*n_size):, :] if choose == 'ann' else X_rnn[int(train_ratio*n_size):, :, :]\n","Y_train_ord         = Y_rnn[:int(train_ratio*n_size)].reshape(-1)\n","Y_test_ord          = Y_rnn[int(train_ratio*n_size):].reshape(-1)\n","print(Y_train_ord.shape)"]},{"cell_type":"code","execution_count":326,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"(8, 2, 2)\n(8,)\n"}],"source":["X_train     = X_train_ord\n","X_test      = X_test_ord\n","Y_train     = Y_train_ord\n","Y_test      = Y_test_ord\n","\n","print(X_train.shape)\n","print(Y_train.shape)"]},{"cell_type":"markdown","execution_count":132,"metadata":{},"outputs":[],"source":["<h1> Recurrent Neural Network w/o Normalization </h1>"]},{"cell_type":"code","execution_count":327,"metadata":{},"outputs":[],"source":["class Scaler3D():\n","\n","    def __init__(self):\n","        self.scaler_list = {}\n","\n","    def fit(self, x):\n","        self.x = x\n","        \n","        min_list = np.array([])\n","        max_list = np.array([])\n","\n","        len_feature = x.shape[-1]\n","\n","        for i in range(len_feature):\n","            self.scaler_list[i] = MinMaxScaler()\n","            self.scaler_list[i].fit(x[:, :, i])\n","\n","    def transform(self, x):\n","        x_copy = x.copy()\n","\n","        len_feature = x.shape[-1]\n","\n","        for i in range(len_feature):\n","            x_copy[:,:,i] = self.scaler_list[i].transform(x[:, :, i])\n","\n","        return x_copy"]},{"cell_type":"code","execution_count":328,"metadata":{},"outputs":[],"source":["def create_model_lstm(n_steps, n_features):\n","    rnn = Sequential()\n","    rnn.add(LSTM(10, activation='relu', return_sequences=True, input_shape=(n_steps, n_features)))\n","    rnn.add(Dropout(0.2))\n","    rnn.add(LSTM(50, activation='relu'))\n","    rnn.add(Dropout(0.2))\n","    rnn.add(Dense(50, activation='relu'))\n","    rnn.add(Dropout(0.2))\n","    rnn.add(Dense(1, activation='relu'))\n","    rnn.compile(optimizer='adam', loss='mse')\n","\n","    return rnn  "]},{"cell_type":"code","execution_count":329,"metadata":{},"outputs":[],"source":["def create_model_gru(n_steps, n_features):\n","    \n","    rnn = Sequential()\n","    rnn.add(GRU(100, activation='relu', return_sequences=True, input_shape=(n_steps, n_features)))\n","    rnn.add(Dropout(0.4))\n","    rnn.add(GRU(100, activation='relu', return_sequences=True))\n","    rnn.add(Dropout(0.4))\n","    rnn.add(GRU(100, activation='relu'))    \n","    # rnn.add(BatchNormalization())    \n","    rnn.add(Dropout(0.4))\n","    rnn.add(Dense(50, activation='relu'))\n","    rnn.add(Dropout(0.4))    \n","    rnn.add(Dense(1, activation='relu'))\n","    rnn.compile(optimizer='adam', loss='mse')\n","    return rnn  "]},{"cell_type":"code","execution_count":330,"metadata":{},"outputs":[],"source":["def create_model_ann(n_steps, n_features):\n","    reg = l1(0.01)\n","    rnn = Sequential()\n","    # input layer\n","    rnn.add(Dense(128, activation='relu', input_dim=n_features))\n","    # hidden layer\n","    rnn.add(Dense(256, activation='relu',\n","                kernel_regularizer=reg)) \n","    rnn.add(Dropout(0.4))\n","    rnn.add(Dense(256, activation='relu',\n","                kernel_regularizer=reg))   \n","    rnn.add(Dropout(0.4)) \n","    rnn.add(Dense(256, activation='relu',\n","                kernel_regularizer=reg))   \n","    rnn.add(Dropout(0.4))     \n","    # output layer\n","    rnn.add(Dense(1, activation='relu'))\n","    rnn.compile(optimizer='adam', loss='mse')\n","    return rnn  "]},{"cell_type":"markdown","execution_count":220,"metadata":{},"outputs":[],"source":["<h1> Recurrent Neural Network w Normalization </h1>"]},{"cell_type":"code","execution_count":333,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"Model: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ngru_3 (GRU)                  (None, 2, 100)            31200     \n_________________________________________________________________\ndropout_4 (Dropout)          (None, 2, 100)            0         \n_________________________________________________________________\ngru_4 (GRU)                  (None, 2, 100)            60600     \n_________________________________________________________________\ndropout_5 (Dropout)          (None, 2, 100)            0         \n_________________________________________________________________\ngru_5 (GRU)                  (None, 100)               60600     \n_________________________________________________________________\ndropout_6 (Dropout)          (None, 100)               0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 50)                5050      \n_________________________________________________________________\ndropout_7 (Dropout)          (None, 50)                0         \n_________________________________________________________________\ndense_3 (Dense)              (None, 1)                 51        \n=================================================================\nTotal params: 157,501\nTrainable params: 157,501\nNon-trainable params: 0\n_________________________________________________________________\n"}],"source":["# Create a callback that saves the model's weights\n","if choose == 'lstm':\n","    checkpoint_path = './checkpoint_path_lstm'\n","    rnn = create_model_lstm(n_steps, n_features)   \n","elif choose == 'gru':\n","    checkpoint_path = './checkpoint_path_gru_3layer_monthly_yearlyyield.ckpt'\n","    rnn = create_model_gru(n_steps, n_features)   \n","else:\n","    checkpoint_path = './checkpoint_path_ann_3layer_monthly_yearlyyield.ckpt'\n","    rnn = create_model_ann(n_steps, n_features)       \n","\n","cp_callback     = tensorflow.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n","                                                 save_weights_only=True,\n","                                                 verbose=0)        \n","rnn.summary()        "]},{"cell_type":"code","execution_count":334,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"---- Iter : 0 ----\nTrain set MAE 18541.28\nTest set MAE 110318.82\nTrain set RMSE 20354.44\nTest set RMSE 188651.83\n---- Iter : 10 ----\nTrain set MAE 11817.31\nTest set MAE 5166.91\nTrain set RMSE 13514.30\nTest set RMSE 6714.18\n---- Iter : 20 ----\nTrain set MAE 6625.75\nTest set MAE 7778.90\nTrain set RMSE 7885.79\nTest set RMSE 8622.17\n---- Iter : 30 ----\nTrain set MAE 12373.87\nTest set MAE 30452.94\nTrain set RMSE 14221.28\nTest set RMSE 30777.44\n---- Iter : 40 ----\nTrain set MAE 8330.13\nTest set MAE 4432.80\nTrain set RMSE 10151.57\nTest set RMSE 5085.23\n---- Iter : 50 ----\nTrain set MAE 9125.39\nTest set MAE 5840.25\nTrain set RMSE 10999.74\nTest set RMSE 6567.85\n---- Iter : 60 ----\nTrain set MAE 9432.55\nTest set MAE 7214.61\nTrain set RMSE 11290.72\nTest set RMSE 7973.55\n---- Iter : 70 ----\nTrain set MAE 6242.79\nTest set MAE 4282.46\nTrain set RMSE 7460.30\nTest set RMSE 5540.87\n---- Iter : 80 ----\nTrain set MAE 7901.04\nTest set MAE 6182.50\nTrain set RMSE 9574.21\nTest set RMSE 7235.92\n---- Iter : 90 ----\nTrain set MAE 7938.27\nTest set MAE 5921.52\nTrain set RMSE 9663.89\nTest set RMSE 6888.76\n---- Iter : 100 ----\nTrain set MAE 7918.15\nTest set MAE 6029.18\nTrain set RMSE 9623.37\nTest set RMSE 7038.96\n---- Iter : 110 ----\nTrain set MAE 6933.74\nTest set MAE 6090.45\nTrain set RMSE 8435.74\nTest set RMSE 6886.91\n---- Iter : 120 ----\nTrain set MAE 9867.07\nTest set MAE 9865.11\nTrain set RMSE 11743.00\nTest set RMSE 10553.87\n---- Iter : 130 ----\nTrain set MAE 7366.83\nTest set MAE 6382.55\nTrain set RMSE 8956.95\nTest set RMSE 7093.41\n---- Iter : 140 ----\nTrain set MAE 6929.54\nTest set MAE 5262.93\nTrain set RMSE 8460.71\nTest set RMSE 6055.78\n---- Iter : 150 ----\nTrain set MAE 6750.48\nTest set MAE 5026.48\nTrain set RMSE 8265.80\nTest set RMSE 5860.74\n---- Iter : 160 ----\nTrain set MAE 7861.67\nTest set MAE 6546.14\nTrain set RMSE 9575.66\nTest set RMSE 7474.94\n---- Iter : 170 ----\nTrain set MAE 7467.45\nTest set MAE 5785.97\nTrain set RMSE 9156.67\nTest set RMSE 6619.21\n---- Iter : 180 ----\nTrain set MAE 6976.39\nTest set MAE 5077.93\nTrain set RMSE 8553.51\nTest set RMSE 6006.57\n---- Iter : 190 ----\nTrain set MAE 6691.80\nTest set MAE 4448.06\nTrain set RMSE 8175.89\nTest set RMSE 5252.18\n---- Iter : 200 ----\nTrain set MAE 7358.17\nTest set MAE 5620.36\nTrain set RMSE 8975.49\nTest set RMSE 6579.91\n---- Iter : 210 ----\nTrain set MAE 7183.74\nTest set MAE 5153.30\nTrain set RMSE 8798.69\nTest set RMSE 5870.20\n---- Iter : 220 ----\nTrain set MAE 6806.45\nTest set MAE 4829.10\nTrain set RMSE 8233.81\nTest set RMSE 5750.43\n---- Iter : 230 ----\nTrain set MAE 6632.11\nTest set MAE 4574.58\nTrain set RMSE 8096.98\nTest set RMSE 5489.25\n---- Iter : 240 ----\nTrain set MAE 7542.06\nTest set MAE 7137.15\nTrain set RMSE 9218.85\nTest set RMSE 8067.13\n---- Iter : 250 ----\nTrain set MAE 6634.58\nTest set MAE 4073.68\nTrain set RMSE 8084.44\nTest set RMSE 4849.81\n---- Iter : 260 ----\nTrain set MAE 7392.78\nTest set MAE 7249.40\nTrain set RMSE 9007.53\nTest set RMSE 8106.94\n---- Iter : 270 ----\nTrain set MAE 6866.39\nTest set MAE 5771.68\nTrain set RMSE 8416.23\nTest set RMSE 6627.10\n---- Iter : 280 ----\nTrain set MAE 7712.78\nTest set MAE 7535.73\nTrain set RMSE 9411.19\nTest set RMSE 8392.06\n---- Iter : 290 ----\nTrain set MAE 7355.40\nTest set MAE 6535.71\nTrain set RMSE 9015.29\nTest set RMSE 7525.85\n"}],"source":["# vector for record error\n","train_mae = np.array([])\n","test_mae = np.array([])\n","\n","train_rmse = np.array([])\n","test_rmse = np.array([])\n","\n","train_r2 = np.array([])\n","test_r2 = np.array([])\n","\n","# minmaxscaler\n","scaler = Scaler3D()\n","scaler.fit(X_train)\n","\n","for i in range(300):\n","\n","    # if os.path.isfile(checkpoint_path):\n","    #     rnn.load_weights(checkpoint_path)\n","\n","        if choose != 'ann':\n","            rnn.fit(scaler.transform(X_train), np.log1p(Y_train), epochs=50, verbose=0, batch_size=32)#, callbacks=[cp_callback])\n","\n","            Y_test_pred = rnn.predict(scaler.transform(X_test))\n","            Y_test_pred[Y_test_pred<0] = 0\n","\n","            Y_train_pred = rnn.predict(scaler.transform(X_train))\n","            Y_train_pred[Y_train_pred<0] = 0\n","\n","            Y_test_pred = np.expm1(Y_test_pred)\n","            Y_train_pred = np.expm1(Y_train_pred)\n","\n","        else:\n","            rnn.fit(scaler.transform(X_train), np.log1p(Y_train), epochs=1, verbose=1, batch_size=32)#, callbacks=[cp_callback])\n","\n","            Y_test_pred = rnn.predict(X_test)\n","            Y_test_pred[Y_test_pred<0] = 0\n","\n","            Y_train_pred = rnn.predict(X_train)\n","            Y_train_pred[Y_train_pred<0] = 0\n","\n","            Y_test_pred = np.expm1(Y_test_pred)\n","            Y_train_pred = np.expm1(Y_train_pred)\n","\n","            Y_train = np.expm1(Y_train)\n","            Y_test  = np.expm1(Y_test)\n","\n","        train_mae = np.append(train_mae, mae(Y_train, Y_train_pred))\n","        test_mae = np.append(test_mae, mae(Y_test, Y_test_pred))\n","\n","        train_rmse = np.append(train_rmse, rmse(Y_train, Y_train_pred))\n","        test_rmse = np.append(test_rmse, rmse(Y_test, Y_test_pred)) \n","\n","        if i%10 == 0:\n","            print('---- Iter : {:d} ----'.format(i))\n","\n","            print('Train set MAE {:.2f}'.format(np.mean(train_mae[-1])))\n","            print('Test set MAE {:.2f}'.format(np.mean(test_mae[-1])))\n","\n","            print('Train set RMSE {:.2f}'.format(np.mean(train_rmse[-1])))\n","            print('Test set RMSE {:.2f}'.format(np.mean(test_rmse[-1])))  "]},{"cell_type":"code","execution_count":335,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"train MAE 2518.34\ttest MAE 4483.59\ntrain RMSE 3107.60\ttest RMSE 5374.50\ntrain MAPE 29.39\t\ttest MAPE 17.09\n=========================\nyear 2007 true : 23229\tpred : 20032\nyear 2008 true : 19089\tpred : 17590\nyear 2009 true : 27922\tpred : 25463\nyear 2010 true : 16052\tpred : 16916\nyear 2011 true : 14033\tpred : 15299\nyear 2012 true : 30097\tpred : 25137\nyear 2013 true : 24997\tpred : 25266\nyear 2014 true : 33525\tpred : 27893\nyear 2015 true : 27016\tpred : 18358\nyear 2016 true : 19180\tpred : 20686\nyear 2017 true : 25349\tpred : 19448\nyear 2018 true : 24130\tpred : 26000\n"}],"source":["Y_all_test = rnn.predict(scaler.transform(X_rnn))\n","Y_all_test[Y_all_test<0] = 0\n","\n","Y_all_test = np.expm1(Y_all_test)\n","# Y_all_test = scaler_Y.inverse_transform(Y_all_test)\n","\n","train_mae = mae(Y_rnn[:int(n_size*(1-0.3))], Y_all_test[:int(n_size*(1-0.3))])\n","test_mae = mae(Y_rnn[int(n_size*(1-0.3)):], Y_all_test[int(n_size*(1-0.3)):])\n","\n","train_rmse = rmse(Y_rnn[:int(n_size*(1-0.3))], Y_all_test[:int(n_size*(1-0.3))])\n","test_rmse = rmse(Y_rnn[int(n_size*(1-0.3)):], Y_all_test[int(n_size*(1-0.3)):])\n","\n","train_mape = mape(Y[:int(n_size*(1-0.3))], Y_all_test[:int(n_size*(1-0.3))])\n","test_mape = mape(Y[int(n_size*(1-0.3)):], Y_all_test[int(n_size*(1-0.3)):])\n","\n","print('train MAE {:.2f}\\ttest MAE {:.2f}'.format(train_mae, test_mae))\n","print('train RMSE {:.2f}\\ttest RMSE {:.2f}'.format(train_rmse, test_rmse))\n","print('train MAPE {:.2f}\\t\\ttest MAPE {:.2f}'.format(train_mape, test_mape))\n","print('=========================')\n","\n","if yearlyyield == False:\n","    for year, month, y_true, y_pred in zip(year_target, month_target, Y, Y_all_test):\n","        print('year {:.0f} month {:.0f} true : {:.0f}\\tpred : {:.0f}'.format(year, month, y_true, y_pred))\n","else:\n","    for year, y_true, y_pred in zip(year_target, Y, Y_all_test):\n","        print('year {:.0f} true : {:.0f}\\tpred : {:.0f}'.format(year, y_true, y_pred[0]))   "]},{"cell_type":"code","execution_count":336,"metadata":{},"outputs":[],"source":["# export output\n","# X_rnn[:int(train_ratio*n_size), :, :]\n","year_train  = year_target[:int(n_size*(1-0.3))]\n","month_train = month_target[:int(n_size*(1-0.3))] if yearlyyield == False else year_train\n","year_test   = year_target[int(n_size*(1-0.3)):]\n","month_test  = month_target[int(n_size*(1-0.3)):] if yearlyyield == False else year_test\n","y_train_true = Y[:int(n_size*(1-0.3))]\n","y_train_pred = Y_all_test[:int(n_size*(1-0.3))]\n","y_test_true = Y[int(n_size*(1-0.3)):]\n","y_test_pred = Y_all_test[int(n_size*(1-0.3)):]\n","export_output('rnn_wnorm_results_monthly_input_yearly_output.xlsx', year_train, month_train, y_train_true, y_train_pred, year_test, month_test, y_test_true, y_test_pred)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}