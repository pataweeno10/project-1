{"cells":[{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":["<h1> Code for Lychee Yield Prediction </h1>"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib.cm as cm\n","# multivariate linear regression with regularization\n","from sklearn.linear_model import LinearRegression, Ridge, Lasso\n","# support vector machine regression\n","from sklearn.svm import SVR\n","from sklearn.metrics import r2_score\n","# neural network\n","import tensorflow\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import LSTM, GRU, Dense, Dropout, Bidirectional, BatchNormalization\n","# normalization\n","from sklearn.preprocessing import MinMaxScaler, StandardScaler\n","from sklearn.pipeline import Pipeline\n","# score\n","from sklearn.metrics import mean_absolute_error\n","from sklearn.model_selection import train_test_split, StratifiedShuffleSplit, GridSearchCV, RandomizedSearchCV\n","# import keras\n","import tensorflow.keras\n","from tensorflow.keras import optimizers, regularizers\n","# import regularizer\n","from tensorflow.keras.regularizers import l1, l2\n","# import matplotlib\n","import matplotlib.pyplot as plt\n","# os\n","import os\n","\n","import pickle\n","from calendar import monthrange"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["def clean_text_to_number(df):\n","    '''\n","    convert all text to 0\n","    '''\n","    cols = df.columns\n","    type_list = []\n","    for col in cols:\n","        print(col)\n","        try:\n","            df[col].astype(float)\n","        except:\n","            for i in range(df[col].shape[0]):\n","                if isinstance(df[col].iloc[i], str):\n","                    df[col].iloc[i] = 0\n","    return df"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"rain amount dataframe\n(6083, 9)\nhumid dataframe\n(6083, 9)\ntemperature dataframe\n(6083, 9)\nrain dataframe sample\n     1    4    7   10 13    16    19   22 total\n0    0    0    0    0  0     0     0  1.2   1.2\n1  4.4  0.2    5  2.6  0  17.4     0    0  29.6\n2    0    0    0    0  0     0     0    0     -\n3    0    0    0    0  0     0     0    0     -\n4    0  0.6  0.7  2.5  2   7.3  15.1  1.4  29.6\narea dataframe sample\n   year  district  code  allarea  yieldarea      yield  yieldperarea\n0  1994         1    10    24562      16404   8366.040           510\n1  1995         1    10    22053      15021   5798.106           386\n2  1996         1    10    27955      18807   8068.203           429\n3  1997         1    10    31203      23278  11429.498           491\n4  1998         1    10    34200      23519   1481.697            63\n"}],"source":["# import data frame\n","rain_df     = pd.read_excel('rain_amount_2003-2019.xlsx')\n","humid_df    = pd.read_excel('relative_humid_2003-2019.xlsx')\n","temp_df     = pd.read_excel('temp_2003-2019.xlsx')\n","area_df     = pd.read_excel('area_2003-2019.xls', sheet_name = 'Sheet1')\n","lychee_yield_df = pd.read_excel('lycheeproduct.xlsx')\n","\n","# extract data\n","rain_df     = rain_df.iloc[5:-5, :]\n","humid_df    = humid_df.iloc[5:-5, :]\n","temp_df     = temp_df.iloc[5:-5, :]\n","\n","# reset index\n","rain_df     = rain_df.reset_index().drop(columns=['index'])\n","humid_df    = humid_df.reset_index().drop(columns=['index'])\n","temp_df     = temp_df.reset_index().drop(columns=['index'])\n","\n","# set column name\n","rain_df.columns     = ['days', 'location', 'date', '1', '4', '7', '10', '13', '16', '19', '22', 'total']\n","humid_df.columns    = ['days', 'location', 'date', '1', '4', '7', '10', '13', '16', '19', '22', 'mean']\n","temp_df.columns     = ['days', 'location', 'date', '1', '4', '7', '10', '13', '16', '19', '22', 'mean']\n","lychee_yield_df.columns = ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', 'total', 'year']\n","area_df.columns     = ['year', 'district', 'code', 'province', 'allarea', 'yieldarea', 'yield', 'yieldperarea']\n","area_df['year']     = area_df['year'] - 543\n","\n","# ดึงค่า date เก็บไว้ก่อน\n","all_datetime    = pd.to_datetime(rain_df['date'])\n","\n","rain_df     = rain_df.drop(columns = ['location', 'days', 'date'])\n","humid_df    = humid_df.drop(columns =['location', 'days', 'date'])\n","temp_df     = temp_df.drop(columns =['location', 'days', 'date'])\n","area_df     = area_df.drop(columns = ['province'])\n","\n","print('rain amount dataframe')\n","print(rain_df.shape)\n","print('humid dataframe')\n","print(humid_df.shape)\n","print('temperature dataframe')\n","print(temp_df.shape)\n","print('rain dataframe sample')\n","print(rain_df.head(5))\n","print('area dataframe sample')\n","print(area_df.head(5))"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["# # get datetime from 3 hour data set\n","# all_year        = pd.DataFrame(all_datetime.dt.year)\n","# all_month       = pd.DataFrame(all_datetime.dt.month)\n","# all_day         = pd.DataFrame(all_datetime.dt.day)\n","\n","# all_year.columns    = ['year']\n","# all_month.columns   = ['month']\n","# all_day.columns     = ['day']\n","# # concat to existing dataframe\n","# rain_df = pd.concat([all_year, all_month, all_day, rain_df], axis = 1)\n","# humid_df = pd.concat([all_year, all_month, all_day, humid_df], axis = 1)\n","# temp_df = pd.concat([all_year, all_month, all_day, temp_df], axis = 1)\n","\n","# # clean text element and save in pickle form\n","\n","# rain_df_clean = clean_text_to_number(rain_df)\n","# with open('rain_df_clean.pickle', 'wb') as f:\n","#     pickle.dump(rain_df_clean, f)\n","# humid_df_clean = clean_text_to_number(humid_df)\n","# with open('humid_df_clean.pickle', 'wb') as f:\n","#     pickle.dump(humid_df_clean, f)\n","# temp_df_clean = clean_text_to_number(temp_df)\n","# with open('temp_df_clean.pickle', 'wb') as f:\n","#     pickle.dump(temp_df_clean, f)"]},{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":["<h1> Load Data from pickle </h1> since clean dataframe take very long time. So after we clean it, we save dataframe in pickle form."]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["with open('rain_df_clean.pickle', 'rb') as f:\n","    rain_df_clean = pickle.load(f)\n","with open('humid_df_clean.pickle', 'rb') as f:\n","    humid_df_clean = pickle.load(f)\n","with open('temp_df_clean.pickle', 'rb') as f:\n","    temp_df_clean = pickle.load(f)"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"--- rain amount dataframe sample ---\n   year  month  day    1    4    7   10 13    16    19   22 total\n0  2003      1    1    0    0    0    0  0     0     0  1.2   1.2\n1  2003      1    2  4.4  0.2    5  2.6  0  17.4     0    0  29.6\n2  2003      1    3    0    0    0    0  0     0     0    0     0\n3  2003      1    4    0    0    0    0  0     0     0    0     0\n4  2003      1    5    0  0.6  0.7  2.5  2   7.3  15.1  1.4  29.6\n --- humid dataframe sample ---\n   year  month  day   1   4   7  10  13  16  19  22 total\n0  2003      1    1  93  95  95  87  75  73  89  93    88\n1  2003      1    2  94  95  94  94  87  91  94  95    93\n2  2003      1    3  95  95  95  87  70  60  92  94    86\n3  2003      1    4  96  95  94  81  70  62  81  85    83\n4  2003      1    5  88  93  93  91  85  95  95  95    92\n --- temperature dataframe sample ---\n   year  month  day     1     4     7    10    13    16    19    22 total\n0  2003      1    1  19.2  18.5  18.2    21  23.5  24.3  22.1  21.3    21\n1  2003      1    2    21  20.9  20.8  21.2  23.5  22.5  21.2  20.5  21.5\n2  2003      1    3  19.5    20  19.5  21.3  24.6  27.5  22.2  19.5  21.8\n3  2003      1    4  19.4  19.6  19.8  21.7  24.2  26.3  23.4    22  22.1\n4  2003      1    5  21.1  20.5  20.3    20    21  19.5  19.3  19.5  20.2\n --- area dataframe sample ---\n   year  district  code  allarea  yieldarea      yield  yieldperarea\n0  1994         1    10    24562      16404   8366.040           510\n1  1995         1    10    22053      15021   5798.106           386\n2  1996         1    10    27955      18807   8068.203           429\n3  1997         1    10    31203      23278  11429.498           491\n4  1998         1    10    34200      23519   1481.697            63\n --- lychee yield dataframe sample ---\n   1  2    3      4      5     6  7  8  9  10  11  12  total  year\n0  0  0    0     77  13875  4447  0  0  0   0   0   0  18399  2004\n1  0  0  120  15463   2352     3  0  0  0   0   0   0  17938  2005\n2  0  0  132  17044   2592     4  0  0  0   0   0   0  19773  2006\n3  0  0    0      0  16125  3861  0  0  0   0   0   0  19986  2007\n4  0  0    0     21  13448   586  0  0  0   0   0   0  14055  2008\n"}],"source":["print(' --- rain amount dataframe sample ---')\n","print(rain_df_clean.head(5))\n","print(' --- humid dataframe sample ---')\n","print(humid_df_clean.head(5))\n","print(' --- temperature dataframe sample ---')\n","print(temp_df_clean.head(5))\n","print(' --- area dataframe sample ---')\n","print(area_df.head(5))\n","print(' --- lychee yield dataframe sample ---')\n","print(lychee_yield_df.head(5))"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["def groupby_col(self, col):\n","    '''\n","    return \n","        1 keys \n","        2 dictionary of sub_df ที่ keys คือแต่ละ element ใน col name\n","    '''\n","\n","    output_dic = {}\n","    all_ele = sorted(list(set(self[col])))\n","\n","    for ele in all_ele:\n","        sub_df = self.loc[self[col] == ele, :]\n","        output_dic[ele] = sub_df\n","\n","    return all_ele, output_dic\n","\n","def groupby_mean(self, col):\n","    '''\n","    return \n","        1 keys \n","        2 dictionary of sub_df ที่ keys คือแต่ละ element ใน col name\n","    '''\n","\n","    output_dic = {}\n","    all_ele = sorted(list(set(self[col])))\n","\n","    for ele in all_ele:\n","        sub_df = self.loc[self[col] == ele, :].mean(axis=0)\n","        output_dic[ele] = sub_df\n","    \n","    return all_ele, output_dic\n","\n","def groupby_max(self, col):\n","    '''\n","    return \n","        1 keys \n","        2 dictionary of sub_df ที่ keys คือแต่ละ element ใน col name\n","    '''\n","\n","    output_dic = {}\n","    all_ele = sorted(list(set(self[col])))\n","\n","    for ele in all_ele:\n","        sub_df = self.loc[self[col] == ele, :].max(axis = 0)\n","        output_dic[ele] = sub_df\n","    \n","    return all_ele, output_dic\n","\n","def groupby_min(self, col):\n","    '''\n","    return \n","        1 keys \n","        2 dictionary of sub_df ที่ keys คือแต่ละ element ใน col name\n","    '''\n","\n","    output_dic = {}\n","    all_ele = sorted(list(set(self[col])))\n","\n","    for ele in all_ele:\n","        sub_df = self.loc[self[col] == ele, :].min(axis = 0)\n","        output_dic[ele] = sub_df\n","    \n","    return all_ele, output_dic\n","\n","def groupby_sum(self, col):\n","    '''\n","    return \n","        1 keys \n","        2 dictionary of sub_df ที่ keys คือแต่ละ element ใน col name\n","    '''\n","\n","    output_dic = {}\n","    all_ele = sorted(list(set(self[col])))\n","\n","    for ele in all_ele:\n","        sub_df = self.loc[self[col] == ele, :].sum(axis = 0)\n","        output_dic[ele] = sub_df\n","    \n","    return all_ele, output_dic\n","\n","# set method to class\n","setattr(pd.core.frame.DataFrame, 'groupby_col', groupby_col)\n","setattr(pd.core.frame.DataFrame, 'groupby_mean', groupby_mean)\n","setattr(pd.core.frame.DataFrame, 'groupby_sum', groupby_sum)\n","setattr(pd.core.frame.DataFrame, 'groupby_max', groupby_max)\n","setattr(pd.core.frame.DataFrame, 'groupby_min', groupby_min)"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["def export_output(filename, year_train, month_train, y_train_true, y_train_pred, year_test, month_test, y_test_true, y_test_pred):\n","    \n","    dic_train = {\n","        'year':year_train.reshape(-1),\n","        'month':month_train.reshape(-1),\n","        'y_true': y_train_true.reshape(-1),\n","        'y_pred': y_train_pred.reshape(-1)\n","    }\n","\n","    dic_test = {\n","        'year':year_test.reshape(-1),\n","        'month':month_test.reshape(-1),\n","        'y_true': y_test_true.reshape(-1),\n","        'y_pred': y_test_pred.reshape(-1)\n","    }\n","    \n","    df_train = pd.DataFrame(dic_train)\n","    df_test = pd.DataFrame(dic_test)\n","    \n","    # Create a Pandas Excel writer using XlsxWriter as the engine.\n","    writer = pd.ExcelWriter(filename, engine='xlsxwriter')\n","    # Write centroids sheet\n","    df_train.to_excel(writer, sheet_name='train set')\n","    df_test.to_excel(writer, sheet_name='test set')\n","    # save output\n","    writer.save()\n"]},{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":["<h1> Rearrange for monthly data </h1>"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"(200, 3)\n"}],"source":["## montly Temp 2004 - 2019\n","monthly_temp = np.array([1,1,1]).reshape(1,3)\n","\n","all_year, sub_year_dic = temp_df_clean.groupby_col('year')\n","\n","for year in all_year:\n","        all_month, sub_month_dic = sub_year_dic[year].groupby_mean('month')\n","\n","        for month in all_month:\n","                # record year month and mean temp of each month\n","                daily_temp = np.array([year, month, sub_month_dic[month].iloc[-1]]).reshape(1,3)\n","                monthly_temp = np.append(monthly_temp, daily_temp, axis = 0)\n","\n","monthly_temp = np.delete(monthly_temp, 0, axis = 0)\n","print(monthly_temp.shape)"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"(200, 3)\n"}],"source":["## monthly Humid 2004 - 2019\n","monthly_humid = np.array([1,1,1]).reshape(1,3)\n","\n","all_year, sub_year_dic = humid_df_clean.groupby_col('year')\n","\n","for year in all_year:\n","        all_month, sub_month_dic = sub_year_dic[year].groupby_mean('month')\n","\n","        for month in all_month:\n","                # record year month and mean temp of each month\n","                daily_humid = np.array([year, month, sub_month_dic[month].iloc[-1]]).reshape(1,3)\n","                monthly_humid = np.append(monthly_humid, daily_humid, axis = 0)\n","\n","monthly_humid = np.delete(monthly_humid, 0, axis = 0)\n","print(monthly_humid.shape)"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"(200, 3)\n"}],"source":["## monthly Rain 2004 - 2019\n","monthly_rain = np.array([1,1,1]).reshape(1,3)\n","\n","all_year, sub_year_dic = rain_df_clean.groupby_col('year')\n","\n","for year in all_year:\n","        all_month, sub_month_dic = sub_year_dic[year].groupby_mean('month')\n","\n","        for month in all_month:\n","                # record year month and mean temp of each month\n","                daily_rain = np.array([year, month, sub_month_dic[month].iloc[-1]]).reshape(1,3)\n","                monthly_rain = np.append(monthly_rain, daily_rain, axis = 0)\n","\n","monthly_rain = np.delete(monthly_rain, 0, axis = 0)\n","print(monthly_rain.shape)"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"(180, 3)\n"}],"source":["## monthly Lychee yield 2004 - 2018\n","monthly_lychee = np.array([1,1,1]).reshape(1,3)\n","\n","all_year, sub_year_dic = rain_df_clean.groupby_col('year')\n","\n","for year in all_year:\n","        all_month, _ = sub_year_dic[year].groupby_mean('month')\n","\n","        for month in all_month:\n","                # record year month and lychee yield of each month\n","                monthly_lychee_temp = lychee_yield_df.loc[lychee_yield_df['year']==year,:]\n","                if monthly_lychee_temp.size != 0:\n","                    monthly_yield = np.array([year, month, monthly_lychee_temp.iloc[0, month-1]]).reshape(1,3)\n","                    monthly_lychee = np.append(monthly_lychee, monthly_yield, axis = 0)\n","\n","monthly_lychee = np.delete(monthly_lychee, 0, axis = 0)\n","print(monthly_lychee.shape)"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"[[ 2004     1 18399]\n [ 2004     2 18399]\n [ 2004     3 18399]\n [ 2004     4 18399]\n [ 2004     5 18399]]\n"}],"source":["## monthly Lychee yield 2004 - 2018 but use yearly yield\n","monthly_lychee_yearlyyield = np.array([1,1,1]).reshape(1,3)\n","\n","all_year, sub_year_dic = rain_df_clean.groupby_col('year')\n","\n","for year in all_year:\n","        all_month, _ = sub_year_dic[year].groupby_mean('month')\n","\n","        for month in all_month:\n","                # record year month and lychee yield of each month\n","                monthly_lychee_temp = lychee_yield_df.loc[lychee_yield_df['year']==year,:]\n","                if monthly_lychee_temp.size != 0:\n","                    monthly_yield = np.array([year, month, monthly_lychee_temp.iloc[0, -2]]).reshape(1,3)\n","                    monthly_lychee_yearlyyield = np.append(monthly_lychee_yearlyyield, monthly_yield, axis = 0)\n","\n","monthly_lychee_yearlyyield = np.delete(monthly_lychee_yearlyyield, 0, axis = 0)\n","print(monthly_lychee_yearlyyield[:5, :])"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"(192, 3)\n"}],"source":["## monthly yield per area 1994 - 2018\n","monthly_area = np.array([1,1,1]).reshape(1,3)\n","\n","all_year, _ = rain_df_clean.groupby_col('year')\n","\n","for year in all_year:\n","        all_month, _ = sub_year_dic[year].groupby_mean('month')\n","\n","        for month in all_month:\n","                # record year month and lychee yield of each month\n","                monthly_area_temp = area_df.loc[area_df['year']==year,:]\n","                if monthly_area_temp.size != 0:\n","                    monthly_area_temp = np.array([year, month, monthly_area_temp.iloc[0, -1]]).reshape(1,3)\n","                    monthly_area = np.append(monthly_area, monthly_area_temp, axis = 0)\n","\n","monthly_area = np.delete(monthly_area, 0, axis = 0)\n","print(monthly_area.shape)"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"(192, 3)\n"}],"source":["## monthly all yield area 1994 - 2018\n","monthly_yieldarea = np.array([1,1,1]).reshape(1,3)\n","\n","all_year, _ = rain_df_clean.groupby_col('year')\n","\n","for year in all_year:\n","        all_month, _ = sub_year_dic[year].groupby_mean('month')\n","\n","        for month in all_month:\n","                # record year month and lychee yield of each month\n","                monthly_area_temp = area_df.loc[area_df['year']==year,:]\n","                if monthly_area_temp.size != 0:\n","                    monthly_area_temp = np.array([year, month, monthly_area_temp.iloc[0, 4]]).reshape(1,3)\n","                    monthly_yieldarea = np.append(monthly_yieldarea, monthly_area_temp, axis = 0)\n","\n","monthly_yieldarea = np.delete(monthly_yieldarea, 0, axis = 0)\n","print(monthly_area.shape)"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"(200, 3)\n"}],"source":["## month range 2004 - 2019\n","monthly_numday = np.array([1,1,1]).reshape(1,3)\n","\n","all_year, _ = rain_df_clean.groupby_col('year')\n","\n","for year in all_year:\n","        all_month, _ = sub_year_dic[year].groupby_mean('month')\n","\n","        for month in all_month:\n","                # record year month and lychee yield of each month\n","                monthly_numday_temp = np.array([year, month, monthrange(year, month)[1]]).reshape(1,3)\n","                monthly_numday = np.append(monthly_numday,monthly_numday_temp, axis = 0)\n","\n","monthly_numday = np.delete(monthly_numday, 0, axis = 0)\n","print(monthly_numday.shape)"]},{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":["<h1> Rearrange for daily data </h1>"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"[[2.003e+03 1.000e+00 1.000e+00 2.100e+01]\n [2.003e+03 1.000e+00 2.000e+00 2.150e+01]\n [2.003e+03 1.000e+00 3.000e+00 2.180e+01]\n [2.003e+03 1.000e+00 4.000e+00 2.210e+01]\n [2.003e+03 1.000e+00 5.000e+00 2.020e+01]\n [2.003e+03 1.000e+00 6.000e+00 2.130e+01]]\n"}],"source":["## daily Temp 2004 - 2019\n","daily_temp = np.array([1,1,1,1]).reshape(1,4)\n","\n","# get yearly dic\n","all_year, sub_year_dic = temp_df_clean.groupby_col('year')\n","\n","for year in all_year:\n","        # get monthly dic\n","        all_month, sub_month_dic = sub_year_dic[year].groupby_col('month')\n","\n","        for month in all_month:\n","            # get daily dic\n","            all_day, sub_day_dic = sub_month_dic[month].groupby_mean('day')       \n","\n","            for day in all_day:\n","                # get daily dataframe\n","                sub_day_df = sub_day_dic[day]\n","                daily_tempo = np.array([year, month, day, sub_day_df.iloc[-1]]).reshape(1,4)\n","                daily_temp = np.append(daily_temp, daily_tempo, axis = 0)\n","\n","daily_temp = np.delete(daily_temp, 0, axis = 0)\n","print(daily_temp[:6, :])"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"(6083, 4)\n"}],"source":["## daily humid 2004 - 2019\n","daily_humid = np.array([1,1,1,1]).reshape(1,4)\n","\n","# get yearly dic\n","all_year, sub_year_dic = humid_df_clean.groupby_col('year')\n","\n","for year in all_year:\n","        # get monthly dic\n","        all_month, sub_month_dic = sub_year_dic[year].groupby_col('month')\n","\n","        for month in all_month:\n","            # get daily dic\n","            all_day, sub_day_dic = sub_month_dic[month].groupby_mean('day')       \n","\n","            for day in all_day:\n","                # get daily dataframe\n","                sub_day_df = sub_day_dic[day]\n","                daily_tempo = np.array([year, month, day, sub_day_df.iloc[-1]]).reshape(1,4)\n","                daily_humid = np.append(daily_humid, daily_tempo, axis = 0)\n","\n","daily_humid = np.delete(daily_humid, 0, axis = 0)\n","print(daily_humid.shape)"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"(6083, 4)\n"}],"source":["## daily rain 2004 - 2019\n","daily_rain = np.array([1,1,1,1]).reshape(1,4)\n","\n","# get yearly dic\n","all_year, sub_year_dic = rain_df_clean.groupby_col('year')\n","\n","for year in all_year:\n","        # get monthly dic\n","        all_month, sub_month_dic = sub_year_dic[year].groupby_col('month')\n","\n","        for month in all_month:\n","            # get daily dic\n","            all_day, sub_day_dic = sub_month_dic[month].groupby_mean('day')       \n","\n","            for day in all_day:\n","                # get daily dataframe\n","                sub_day_df = sub_day_dic[day]\n","                daily_tempo = np.array([year, month, day, sub_day_df.iloc[-1]]).reshape(1,4)\n","                daily_rain = np.append(daily_rain, daily_tempo, axis = 0)\n","\n","daily_rain = np.delete(daily_rain, 0, axis = 0)\n","print(daily_rain.shape)"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"[[2004    1    1    0]\n [2004    1    2    0]\n [2004    1    3    0]\n [2004    1    4    0]\n [2004    1    5    0]\n [2004    1    6    0]]\n"}],"source":["## daily Lychee yield 2004 - 2018\n","daily_lychee = np.array([1,1,1,1]).reshape(1,4)\n","\n","all_year, sub_year_dic = rain_df_clean.groupby_col('year')\n","\n","for year in all_year:\n","        all_month, sub_month_dic = sub_year_dic[year].groupby_col('month')\n","        # record year month and lychee yield of each month\n","        daily_lychee_temp = lychee_yield_df.loc[lychee_yield_df['year']==year,:]\n","\n","        for month in all_month:\n","\n","                # get daily dic\n","                all_day, _ = sub_month_dic[month].groupby_mean('day')       \n","\n","                for day in all_day:    \n","\n","                    if daily_lychee_temp.size != 0:\n","                        # print(year, ' : ', month)\n","                        # print(daily_lychee_temp.iloc[0, month-1])\n","                        daily_yield = np.array([year, month, day, daily_lychee_temp.iloc[0, month-1]]).reshape(1,4)\n","                        daily_lychee = np.append(daily_lychee, daily_yield, axis = 0)\n","\n","daily_lychee = np.delete(daily_lychee, 0, axis = 0)\n","print(daily_lychee[:6, :])"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"[[ 2004     1     1 18399]\n [ 2004     1     2 18399]\n [ 2004     1     3 18399]\n [ 2004     1     4 18399]\n [ 2004     1     5 18399]\n [ 2004     1     6 18399]]\n"}],"source":["## daily Lychee yield 2004 - 2018 yearlyyield\n","daily_lychee_yearlyyield = np.array([1,1,1,1]).reshape(1,4)\n","all_year, sub_year_dic = rain_df_clean.groupby_col('year')\n","\n","for year in all_year:\n","        all_month, sub_month_dic = sub_year_dic[year].groupby_col('month')\n","        # record year month and lychee yield of each month\n","        daily_lychee_temp = lychee_yield_df.loc[lychee_yield_df['year']==year,:]\n","\n","        for month in all_month:\n","\n","                # get daily dic\n","                all_day, _ = sub_month_dic[month].groupby_mean('day')       \n","\n","                for day in all_day:    \n","\n","                    if daily_lychee_temp.size != 0:\n","                        # print(year, ' : ', month)\n","                        # print(daily_lychee_temp.iloc[0, month-1])\n","                        daily_yield = np.array([year, month, day, daily_lychee_temp.iloc[0, -2]]).reshape(1,4)\n","                        daily_lychee_yearlyyield = np.append(daily_lychee_yearlyyield, daily_yield, axis = 0)\n","\n","daily_lychee_yearlyyield = np.delete(daily_lychee_yearlyyield, 0, axis = 0)\n","print(daily_lychee_yearlyyield[:6, :])"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"(5844, 4)\n"}],"source":["## daily yield per area 2004 - 2018\n","daily_area = np.array([1,1,1,1]).reshape(1,4)\n","\n","all_year, sub_year_dic = rain_df_clean.groupby_col('year')\n","\n","for year in all_year:\n","        all_month, sub_month_dic = sub_year_dic[year].groupby_col('month')\n","        # record year month and lychee yield of each month\n","        area_temp = area_df.loc[area_df['year']==year,:]        \n","\n","        for month in all_month:\n","\n","                # get daily dic\n","                all_day, _ = sub_month_dic[month].groupby_mean('day')       \n","\n","                for day in all_day:    \n","\n","                    if area_temp.size != 0:\n","                        daily_area_temp = np.array([year, month, day, area_temp.iloc[0, -1]]).reshape(1,4)\n","                        daily_area = np.append(daily_area, daily_area_temp, axis = 0)\n","\n","daily_area = np.delete(daily_area, 0, axis = 0)\n","print(daily_area.shape)"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"(5844, 4)\n"}],"source":["## daily yield per area 2004 - 2018\n","daily_yieldarea = np.array([1,1,1,1]).reshape(1,4)\n","\n","all_year, sub_year_dic = rain_df_clean.groupby_col('year')\n","\n","for year in all_year:\n","        all_month, sub_month_dic = sub_year_dic[year].groupby_col('month')\n","        # record year month and lychee yield of each month\n","        area_temp = area_df.loc[area_df['year']==year,:]        \n","\n","        for month in all_month:\n","\n","                # get daily dic\n","                all_day, _ = sub_month_dic[month].groupby_mean('day')       \n","\n","                for day in all_day:    \n","\n","                    if area_temp.size != 0:\n","                        daily_area_temp = np.array([year, month, day, area_temp.iloc[0, 4]]).reshape(1,4)\n","                        daily_yieldarea = np.append(daily_yieldarea, daily_area_temp, axis = 0)\n","\n","daily_yieldarea = np.delete(daily_yieldarea, 0, axis = 0)\n","print(daily_yieldarea.shape)"]},{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":["<h1> Rearrange for 3-hourly data </h1>"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"(48664, 5)\n"}],"source":["## hourly Temp 2004 - 2019\n","threehourly_temp = np.array([1,1,1,1,1]).reshape(1,5)\n","\n","# get yearly dic\n","all_year, sub_year_dic = temp_df_clean.groupby_col('year')\n","\n","for year in all_year:\n","        # get monthly dic\n","        all_month, sub_month_dic = sub_year_dic[year].groupby_col('month')\n","\n","        for month in all_month:\n","            # get daily dic\n","            all_day, sub_day_dic = sub_month_dic[month].groupby_col('day')       \n","\n","            for day in all_day:\n","                # get daily dataframe\n","                sub_day_df = sub_day_dic[day]\n","\n","                for hour in ['1', '4', '7', '10', '13', '16', '19', '22']:\n","                    threehourly_tempo = np.array([year, month, day, int(hour), sub_day_df[hour]]).reshape(1,5)\n","                    threehourly_temp = np.append(threehourly_temp, threehourly_tempo, axis = 0)\n","\n","threehourly_temp = np.delete(threehourly_temp, 0, axis = 0)\n","print(threehourly_temp.shape)"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"(48664, 5)\n"}],"source":["## hourly Humid 2004 - 2019\n","threehourly_humid = np.array([1,1,1,1,1]).reshape(1,5)\n","\n","# get yearly dic\n","all_year, sub_year_dic = humid_df_clean.groupby_col('year')\n","\n","for year in all_year:\n","        # get monthly dic\n","        all_month, sub_month_dic = sub_year_dic[year].groupby_col('month')\n","\n","        for month in all_month:\n","            # get daily dic\n","            all_day, sub_day_dic = sub_month_dic[month].groupby_col('day')       \n","\n","            for day in all_day:\n","                # get daily dataframe\n","                sub_day_df = sub_day_dic[day]\n","\n","                for hour in ['1', '4', '7', '10', '13', '16', '19', '22']:\n","                    threehourly_tempo = np.array([year, month, day, int(hour), sub_day_df[hour]]).reshape(1,5)\n","                    threehourly_humid = np.append(threehourly_humid, threehourly_tempo, axis = 0)\n","\n","threehourly_humid = np.delete(threehourly_humid, 0, axis = 0)\n","print(threehourly_humid.shape)"]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"Year 2003 : Month 1\nYear 2003 : Month 2\nYear 2003 : Month 3\nYear 2003 : Month 4\nYear 2003 : Month 5\nYear 2003 : Month 6\nYear 2003 : Month 7\nYear 2003 : Month 8\nYear 2003 : Month 9\nYear 2003 : Month 10\nYear 2003 : Month 11\nYear 2003 : Month 12\nYear 2004 : Month 1\nYear 2004 : Month 2\nYear 2004 : Month 3\nYear 2004 : Month 4\nYear 2004 : Month 5\nYear 2004 : Month 6\nYear 2004 : Month 7\nYear 2004 : Month 8\nYear 2004 : Month 9\nYear 2004 : Month 10\nYear 2004 : Month 11\nYear 2004 : Month 12\nYear 2005 : Month 1\nYear 2005 : Month 2\nYear 2005 : Month 3\nYear 2005 : Month 4\nYear 2005 : Month 5\nYear 2005 : Month 6\nYear 2005 : Month 7\nYear 2005 : Month 8\nYear 2005 : Month 9\nYear 2005 : Month 10\nYear 2005 : Month 11\nYear 2005 : Month 12\nYear 2006 : Month 1\nYear 2006 : Month 2\nYear 2006 : Month 3\nYear 2006 : Month 4\nYear 2006 : Month 5\nYear 2006 : Month 6\nYear 2006 : Month 7\nYear 2006 : Month 8\nYear 2006 : Month 9\nYear 2006 : Month 10\nYear 2006 : Month 11\nYear 2006 : Month 12\nYear 2007 : Month 1\nYear 2007 : Month 2\nYear 2007 : Month 3\nYear 2007 : Month 4\nYear 2007 : Month 5\nYear 2007 : Month 6\nYear 2007 : Month 7\nYear 2007 : Month 8\nYear 2007 : Month 9\nYear 2007 : Month 10\nYear 2007 : Month 11\nYear 2007 : Month 12\nYear 2008 : Month 1\nYear 2008 : Month 2\nYear 2008 : Month 3\nYear 2008 : Month 4\nYear 2008 : Month 5\nYear 2008 : Month 6\nYear 2008 : Month 7\nYear 2008 : Month 8\nYear 2008 : Month 9\nYear 2008 : Month 10\nYear 2008 : Month 11\nYear 2008 : Month 12\nYear 2009 : Month 1\nYear 2009 : Month 2\nYear 2009 : Month 3\nYear 2009 : Month 4\nYear 2009 : Month 5\nYear 2009 : Month 6\nYear 2009 : Month 7\nYear 2009 : Month 8\nYear 2009 : Month 9\nYear 2009 : Month 10\nYear 2009 : Month 11\nYear 2009 : Month 12\nYear 2010 : Month 1\nYear 2010 : Month 2\nYear 2010 : Month 3\nYear 2010 : Month 4\nYear 2010 : Month 5\nYear 2010 : Month 6\nYear 2010 : Month 7\nYear 2010 : Month 8\nYear 2010 : Month 9\nYear 2010 : Month 10\nYear 2010 : Month 11\nYear 2010 : Month 12\nYear 2011 : Month 1\nYear 2011 : Month 2\nYear 2011 : Month 3\nYear 2011 : Month 4\nYear 2011 : Month 5\nYear 2011 : Month 6\nYear 2011 : Month 7\nYear 2011 : Month 8\nYear 2011 : Month 9\nYear 2011 : Month 10\nYear 2011 : Month 11\nYear 2011 : Month 12\nYear 2012 : Month 1\nYear 2012 : Month 2\nYear 2012 : Month 3\nYear 2012 : Month 4\nYear 2012 : Month 5\nYear 2012 : Month 6\nYear 2012 : Month 7\nYear 2012 : Month 8\nYear 2012 : Month 9\nYear 2012 : Month 10\nYear 2012 : Month 11\nYear 2012 : Month 12\nYear 2013 : Month 1\nYear 2013 : Month 2\nYear 2013 : Month 3\nYear 2013 : Month 4\nYear 2013 : Month 5\nYear 2013 : Month 6\nYear 2013 : Month 7\nYear 2013 : Month 8\nYear 2013 : Month 9\nYear 2013 : Month 10\nYear 2013 : Month 11\nYear 2013 : Month 12\nYear 2014 : Month 1\nYear 2014 : Month 2\nYear 2014 : Month 3\nYear 2014 : Month 4\nYear 2014 : Month 5\nYear 2014 : Month 6\nYear 2014 : Month 7\nYear 2014 : Month 8\nYear 2014 : Month 9\nYear 2014 : Month 10\nYear 2014 : Month 11\nYear 2014 : Month 12\nYear 2015 : Month 1\nYear 2015 : Month 2\nYear 2015 : Month 3\nYear 2015 : Month 4\nYear 2015 : Month 5\nYear 2015 : Month 6\nYear 2015 : Month 7\nYear 2015 : Month 8\nYear 2015 : Month 9\nYear 2015 : Month 10\nYear 2015 : Month 11\nYear 2015 : Month 12\nYear 2016 : Month 1\nYear 2016 : Month 2\nYear 2016 : Month 3\nYear 2016 : Month 4\nYear 2016 : Month 5\nYear 2016 : Month 6\nYear 2016 : Month 7\nYear 2016 : Month 8\nYear 2016 : Month 9\nYear 2016 : Month 10\nYear 2016 : Month 11\nYear 2016 : Month 12\nYear 2017 : Month 1\nYear 2017 : Month 2\nYear 2017 : Month 3\nYear 2017 : Month 4\nYear 2017 : Month 5\nYear 2017 : Month 6\nYear 2017 : Month 7\nYear 2017 : Month 8\nYear 2017 : Month 9\nYear 2017 : Month 10\nYear 2017 : Month 11\nYear 2017 : Month 12\nYear 2018 : Month 1\nYear 2018 : Month 2\nYear 2018 : Month 3\nYear 2018 : Month 4\nYear 2018 : Month 5\nYear 2018 : Month 6\nYear 2018 : Month 7\nYear 2018 : Month 8\nYear 2018 : Month 9\nYear 2018 : Month 10\nYear 2018 : Month 11\nYear 2018 : Month 12\nYear 2019 : Month 1\nYear 2019 : Month 2\nYear 2019 : Month 3\nYear 2019 : Month 4\nYear 2019 : Month 5\nYear 2019 : Month 6\nYear 2019 : Month 7\nYear 2019 : Month 8\n(48664, 5)\n"}],"source":["## hourly Rain 2004 - 2019\n","threehourly_rain = np.array([1,1,1,1,1]).reshape(1,5)\n","\n","# get yearly dic\n","all_year, sub_year_dic = rain_df_clean.groupby_col('year')\n","\n","for year in all_year:\n","        # get monthly dic\n","        all_month, sub_month_dic = sub_year_dic[year].groupby_col('month')\n","\n","        for month in all_month:\n","            # get daily dic\n","            all_day, sub_day_dic = sub_month_dic[month].groupby_col('day')       \n","\n","            for day in all_day:\n","                # get daily dataframe\n","                sub_day_df = sub_day_dic[day]\n","\n","                for hour in ['1', '4', '7', '10', '13', '16', '19', '22']:\n","                    threehourly_tempo = np.array([year, month, day, int(hour), sub_day_df[hour]]).reshape(1,5)\n","                    threehourly_rain = np.append(threehourly_rain, threehourly_tempo, axis = 0)\n","\n","threehourly_rain = np.delete(threehourly_rain, 0, axis = 0)\n","print(threehourly_rain.shape)"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"(43832, 5)\n"}],"source":["## hourly Lychee yield 2004 - 2018\n","threehourly_lychee = np.array([1,1,1,1,1]).reshape(1,5)\n","\n","all_year, sub_year_dic = rain_df_clean.groupby_col('year')\n","\n","for year in all_year:\n","    all_month, sub_month_dic = sub_year_dic[year].groupby_col('month')\n","    monthly_lychee_temp = lychee_yield_df.loc[lychee_yield_df['year']==year,:]\n","\n","    for month in all_month:\n","        # get daily dic\n","        all_day, _ = sub_month_dic[month].groupby_col('day')       \n","\n","        for day in all_day:                \n","            for hour in ['1', '4', '7', '10', '13', '16', '19', '22']:\n","                if monthly_lychee_temp.size != 0:\n","                    threehourly_yield = np.array([year, month, day, int(hour), monthly_lychee_temp.iloc[0, month-1]]).reshape(1,5)\n","                    threehourly_lychee = np.append(threehourly_lychee, threehourly_yield, axis = 0)\n","\n","threehourly_lychee = np.delete(threehourly_lychee, 0, axis = 0)\n","print(threehourly_lychee.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## hourly Lychee yield 2004 - 2018 yearlyyield\n","threehourly_lychee_lycheeyield = np.array([1,1,1,1,1]).reshape(1,5)\n","\n","all_year, sub_year_dic = rain_df_clean.groupby_col('year')\n","\n","for year in all_year:\n","    all_month, sub_month_dic = sub_year_dic[year].groupby_col('month')\n","    monthly_lychee_temp = lychee_yield_df.loc[lychee_yield_df['year']==year,:]\n","\n","    for month in all_month:\n","        # get daily dic\n","        all_day, _ = sub_month_dic[month].groupby_col('day')       \n","\n","        for day in all_day:                \n","            for hour in ['1', '4', '7', '10', '13', '16', '19', '22']:\n","                if monthly_lychee_temp.size != 0:\n","                    threehourly_yield = np.array([year, month, day, int(hour), monthly_lychee_temp.iloc[0, month-1]]).reshape(1,5)\n","                    threehourly_lychee_lycheeyield = np.append(threehourly_lychee_lycheeyield, threehourly_yield, axis = 0)\n","\n","threehourly_lychee_lycheeyield = np.delete(threehourly_lychee_lycheeyield, 0, axis = 0)\n","print(threehourly_lychee_lycheeyield[:6,:])"]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"(46752, 5)\n"}],"source":["## hourly yield per area 2004 - 2018\n","threehourly_area = np.array([1,1,1,1,1]).reshape(1,5)\n","\n","all_year, sub_year_dic = rain_df_clean.groupby_col('year')\n","\n","for year in all_year:\n","    all_month, sub_month_dic    = sub_year_dic[year].groupby_col('month')\n","    monthly_area_temp         = area_df.loc[area_df['year']==year,:]\n","\n","    for month in all_month:\n","        # get daily dic\n","        all_day, _ = sub_month_dic[month].groupby_col('day')       \n","\n","        for day in all_day:                \n","            for hour in ['1', '4', '7', '10', '13', '16', '19', '22']:\n","                if monthly_area_temp.size != 0:\n","                    threehourly_area_temp = np.array([year, month, day, int(hour), monthly_area_temp.iloc[0, -1]]).reshape(1,5)\n","                    threehourly_area = np.append(threehourly_area, threehourly_area_temp, axis = 0)\n","\n","threehourly_area = np.delete(threehourly_area, 0, axis = 0)\n","print(threehourly_area.shape)"]},{"cell_type":"code","execution_count":39,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"(46752, 5)\n"}],"source":["## hourly all area 2004 - 2018\n","threehourly_yieldarea = np.array([1,1,1,1,1]).reshape(1,5)\n","\n","all_year, sub_year_dic = rain_df_clean.groupby_col('year')\n","\n","for year in all_year:\n","    all_month, sub_month_dic    = sub_year_dic[year].groupby_col('month')\n","    monthly_area_temp           = area_df.loc[area_df['year']==year,:]\n","\n","    for month in all_month:\n","        # get daily dic\n","        all_day, _ = sub_month_dic[month].groupby_col('day')       \n","\n","        for day in all_day:                \n","            for hour in ['1', '4', '7', '10', '13', '16', '19', '22']:\n","                if monthly_area_temp.size != 0:\n","                    threehourly_area_temp = np.array([year, month, day, int(hour), monthly_area_temp.iloc[0, 4]]).reshape(1,5)\n","                    threehourly_yieldarea = np.append(threehourly_yieldarea, threehourly_area_temp, axis = 0)\n","\n","threehourly_yieldarea = np.delete(threehourly_yieldarea, 0, axis = 0)\n","print(threehourly_yieldarea.shape)"]},{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":["Intersected\n"," year of all data is 2004 - 2018"]},{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":["<h1> Method for getting X data </h1>"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[],"source":["def split_x_sequence(X, n_steps, ind_output):\n","    \n","    X_seq = np.ones((1, n_steps))\n","\n","    for i in range(X.shape[0]):\n","        \n","        if i+n_steps > X.shape[0] - 1:\n","            break\n","        x_seq_temp = X[i:i+n_steps, ind_output].reshape(1,-1)\n","        X_seq = np.append(X_seq, x_seq_temp, axis = 0)\n","    \n","    return X_seq[1:,:]\n","\n","def split_y_sequence(X, n_steps, ind_output, repeat):\n","    \n","    # repeat = False return only target\n","    # repeat = true return target with multiple row\n","    X_seq = np.ones((1, 1)) if repeat == False else np.ones((1, n_steps))\n","\n","    for i in range(X.shape[0]):\n","        \n","        if i+n_steps > X.shape[0] - 1:\n","            break\n","        x_seq_temp = X[i+n_steps, ind_output].reshape(1, -1) if repeat == False else  X[i+n_steps, ind_output]*np.ones((1, n_steps))\n","        X_seq = np.append(X_seq, x_seq_temp, axis = 0)\n","    \n","    return X_seq[1:,:]"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[],"source":["def get_XY_fr_resolution(df_list_input, df_list_output, n_steps, req_m_input = [1, 2], req_month = [4, 5, 6], axis = 1, yearlyyield = False):\n","\n","    df_copy_list  = list()\n","    X             = list()\n","\n","    # extract X\n","    count = 0\n","    for df, xy_split in df_list_input:\n","        df_copy = df.copy()\n","        ind_2004_2018 = np.logical_and(df_copy[:, 0] >= 2004, df_copy[:, 0] <= 2018)\n","        df_copy = df_copy[ind_2004_2018,:]\n","\n","        # find index only for required input month\n","        if yearlyyield and count == 0:\n","            count = count + 1\n","            req_m_ind = np.zeros((df_copy.shape[0],))\n","            for i in req_m_input:\n","                req_m_ind = np.logical_or(req_m_ind, (df_copy[:,1] == i).reshape(-1,))\n","\n","        df_copy = df_copy[req_m_ind, :]\n","\n","        if xy_split == 'x':\n","            X_temp = split_x_sequence(df_copy, n_steps, -1)\n","            print('true')\n","            print(X_temp.shape)\n","        if xy_split == 'y':\n","            X_temp = split_y_sequence(df_copy, n_steps, -1, True) if axis == 2 else split_y_sequence(df_copy, n_steps, -1, False)\n","      \n","        X_temp = X_temp.reshape(X_temp.shape[0], X_temp.shape[1], 1)\n","        X.append(X_temp)\n","\n","    # axis = 2 for rnn and axis = 1 for lr and svr\n","    X = np.concatenate(X, axis = axis)\n","\n","    # extract y\n","    Y = split_y_sequence(df_list_output[0], n_steps, -1, False) if yearlyyield == False else split_y_sequence(df_list_output[0][req_m_ind, :], n_steps, -1, False)  \n","\n","    # get only the data from required month\n","    all_year    = np.unique(df_copy[:, 0])\n","    all_month   = np.unique(df_copy[:, 1]) if yearlyyield == False else np.array([])\n","    req_ind     = np.zeros((X_temp.shape[0], 1))\n","    for year in all_year:\n","        for month in req_month:\n","            year_ind = df_copy[n_steps:, 0] == year\n","            \n","            if yearlyyield == False:\n","                month_ind = df_copy[n_steps:, 1] == month\n","                ym_ind = year_ind*month_ind\n","            else:\n","                ym_ind = year_ind\n","\n","            ym_ind_where = np.where(ym_ind == 1)\n","            \n","            if len(ym_ind_where[0]) != 0:\n","                if yearlyyield == False:\n","                    # get only the data from required month only at the first index\n","                    first_ind = ym_ind_where[0][0]\n","\n","                else:\n","                    # get only the data from the last index of each year\n","                    first_ind = ym_ind_where[0][0]                  \n","\n","                ym_ind = np.zeros((ym_ind.shape[0], 1))\n","                \n","                try:\n","                    ym_ind[first_ind] = 1\n","                except:\n","                    pass\n","\n","                ym_ind  = ym_ind.reshape(-1, 1)\n","                req_ind = req_ind + ym_ind\n","\n","    req_ind = req_ind.astype(bool).reshape(-1)\n","    X = X[req_ind, :, :]\n","    Y = Y[req_ind]\n","    if axis == 1:\n","        X = X.reshape(X.shape[0], X.shape[1])\n","        Y = Y.reshape(Y.shape[0])\n","\n","    n_features = X.shape[2] if axis == 2 else X.shape[1]\n","    n_size      = X.shape[0]\n","\n","    year_target = df_copy[n_steps:, 0][req_ind]\n","    month_target = df_copy[n_steps:, 1][req_ind] if yearlyyield == False else np.array([])\n","\n","    return X, Y, n_features, n_size, n_steps, year_target, month_target"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[],"source":["def rmse(y_true, y_pred):\n","\n","    ind_ignorezero = (y_true != 0).reshape(-1,)\n","    error = (y_true - y_pred)\n","    se = error**2\n","    mse = np.mean(se)\n","    rmse = mse**0.5\n","    return rmse"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[],"source":["def mape(y_true, y_pred):\n","    error = y_true - y_pred\n","    pe     = (y_true - y_pred)/y_true*100\n","    ape = np.abs(pe)\n","    mape = np.mean(ape)\n","\n","    return mape    "]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[],"source":["def mae(y_true, y_pred):\n","\n","    error = y_true - y_pred\n","    ae = np.abs(error)\n","    mae = np.mean(ae)\n","\n","    return mae"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[],"source":["def r2(y_true, y_pred):\n","    y_mean  = np.mean(y_true)\n","    Stot    = np.sum((y_true - y_mean)**2)\n","    Sres    = np.sum((y_true - y_pred)**2)\n","    r_square    = 1 - Sres/Stot\n","\n","    return r_square"]},{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":["Get y"]},{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":["<h1> Feature selection </h1>\n","Year (of the target), Month (of the target), Avg.Temp (3 and 4 month before), Avg.Humid (3 and 4 month before),\n","Rain amount (3 and 4 month before), lychee yield per area (1 year before), number of the day in target month,\n","lychee yield (of target month but 1 year before)"]},{"cell_type":"code","execution_count":164,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"true\n(28, 2)\ntrue\n(28, 2)\n"}],"source":["choose = 'monthly_yearlyyield_wyear'\n","\n","if choose == 'monthly_yearlyyield_wyear':\n","    yearlyyield = True\n","    input_vec = [\n","        [monthly_temp, 'x'],\n","        # [monthly_humid, 'x'], \n","        # [monthly_rain, 'x'], \n","        # [monthly_area, 'x'], \n","        # [monthly_yieldarea, 'x'], \n","        # [monthly_lychee, 'x'],\n","        [monthly_yieldarea[:,0].reshape(-1,1), 'y']]   # target year\n","\n","    output_vec = [monthly_lychee_yearlyyield]\n","\n","if choose == 'monthly_yearlyyield_woyear':\n","    yearlyyield = True\n","    input_vec = [\n","        [monthly_temp, 'x'],\n","        # [monthly_humid, 'x'], \n","        # [monthly_rain, 'x'], \n","        # [monthly_area, 'x'], \n","        # [monthly_yieldarea, 'x'], \n","        # [monthly_lychee, 'x'],\n","        ]#[monthly_yieldarea[:,0].reshape(-1,1), 'y']]   # target year\n","\n","if choose == 'test':\n","    input_vec = [\n","        [daily_temp, 'x'], \n","        [daily_yieldarea[:,0].reshape(-1,1), 'y'],   # target year\n","        [daily_yieldarea[:,0:2].reshape(-1,2), 'y']] # target month\n","\n","    output_vec = [daily_lychee]\n","\n","if choose == 'monthly':\n","    yearlyyield = False\n","    input_vec = [\n","        [monthly_temp, 'x'],\n","        # [monthly_humid, 'x'], \n","        # [monthly_rain, 'x'], \n","        # [monthly_area, 'x'], \n","        [monthly_yieldarea, 'x'], \n","        [monthly_lychee, 'x'], \n","        [monthly_yieldarea[:,0].reshape(-1,1), 'y'],   # target year\n","        [monthly_yieldarea[:,0:2].reshape(-1,2), 'y']] # target month\n","    \n","    output_vec = [monthly_lychee]\n","\n","if choose == 'daily':\n","    yearlyyield = False\n","    input_vec = [\n","        [daily_temp, 'x'],\n","        [daily_humid, 'x'], \n","        # [daily_rain, 'x'], \n","        # [daily_area, 'x'], \n","        # [daily_yieldarea, 'x'], \n","        [daily_lychee, 'x'], \n","        [daily_yieldarea[:,0].reshape(-1,1), 'y'],   # target year\n","        [daily_yieldarea[:,0:2].reshape(-1,2), 'y']] # target month\n","\n","    output_vec = [daily_lychee]\n","\n","if choose == 'hourly':\n","    yearlyyield = False\n","    input_vec = [\n","        [hourly_temp, 'x'],\n","        # [hourly_humid, 'x'], \n","        # [hourly_rain, 'x'], \n","        # [hourly_area, 'x'], \n","        [hourly_yieldarea, 'x'], \n","        [hourly_lychee, 'x'], \n","        [hourly_yieldarea[:,0].reshape(-1,1), 'y'],   # target year\n","        [hourly_yieldarea[:,0:2].reshape(-1,2), 'y']] # target month\n","\n","    output_vec = [hourly_lychee]\n","\n","# daily choose n_steps = 240\n","# hourly choose n_steps = 1920\n","# monthly choose n_steps = 4\n","# axis = 2 for rnn\n","\n","X, Y, n_features, n_size, n_steps, year_target, month_target = get_XY_fr_resolution(input_vec, output_vec, n_steps = 2, axis = 1, req_m_input = [1, 2], req_month = [4, 5, 6], yearlyyield = yearlyyield)"]},{"cell_type":"code","execution_count":165,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"X Shape\n(14, 5)\nY Shape\n(14,)\nn features\n5\nsample size\n14\n"}],"source":["print('X Shape')\n","print(X.shape)\n","print('Y Shape')\n","print(Y.shape)\n","print('n features')\n","print(n_features)\n","print('sample size')\n","print(n_size)"]},{"cell_type":"code","execution_count":166,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"[[1.99548387e+01 2.15482759e+01 4.14370000e+04 4.14370000e+04\n  2.00500000e+03]\n [2.03677419e+01 2.27607143e+01 4.33660000e+04 4.33660000e+04\n  2.00600000e+03]\n [2.00032258e+01 2.26857143e+01 4.71910000e+04 4.71910000e+04\n  2.00700000e+03]\n [1.98451613e+01 2.10250000e+01 4.89860000e+04 4.89860000e+04\n  2.00800000e+03]\n [2.02290323e+01 2.17379310e+01 4.37850000e+04 4.37850000e+04\n  2.00900000e+03]\n [1.95387097e+01 2.28107143e+01 3.42520000e+04 3.42520000e+04\n  2.01000000e+03]\n [2.19516129e+01 2.23821429e+01 3.22190000e+04 3.22190000e+04\n  2.01100000e+03]\n [2.07709677e+01 2.20071429e+01 3.24620000e+04 3.24620000e+04\n  2.01200000e+03]\n [2.05806452e+01 2.27620690e+01 3.21100000e+04 3.21100000e+04\n  2.01300000e+03]\n [2.11129032e+01 2.41250000e+01 3.04500000e+04 3.04500000e+04\n  2.01400000e+03]\n [1.92741935e+01 2.20142857e+01 2.30010000e+04 2.30010000e+04\n  2.01500000e+03]\n [1.96387097e+01 2.17357143e+01 2.04130000e+04 2.04130000e+04\n  2.01600000e+03]\n [1.89709677e+01 2.15931034e+01 1.94000000e+04 1.94000000e+04\n  2.01700000e+03]\n [2.14741935e+01 2.28428571e+01 1.93160000e+04 1.93160000e+04\n  2.01800000e+03]]\n"}],"source":["print(X)"]},{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":["Seperate train set and test set for displaying"]},{"cell_type":"code","execution_count":167,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"train size\n(9, 5)\ntest size\n(5, 5)\n"}],"source":["X_train, X_test, Y_train, Y_test =  train_test_split(X, Y, test_size=0.3)\n","X_train_ord = X[:int(n_size*(1-0.3)), :]\n","X_test_ord  = X[int(n_size*(1-0.3)):, :]\n","Y_train_ord = Y[:int(n_size*(1-0.3))]\n","Y_test_ord  = Y[int(n_size*(1-0.3)):]\n","print('train size')\n","print(X_train.shape)\n","print('test size')\n","print(X_test.shape)"]},{"cell_type":"markdown","execution_count":216,"metadata":{},"outputs":[],"source":["<h1> Ridge Model w/o Normalization </h1>"]},{"cell_type":"code","execution_count":168,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"Ridge(alpha=1000, copy_X=True, fit_intercept=True, max_iter=None,\n   normalize=False, random_state=None, solver='auto', tol=0.001)\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n  DeprecationWarning)\n"}],"source":["# vector for record error\n","train_mae = np.array([])\n","test_mae = np.array([])\n","\n","train_rmse = np.array([])\n","test_rmse = np.array([])\n","\n","train_r2 = np.array([])\n","test_r2 = np.array([])\n","\n","# using grid searchcv to optimize hyper param\n","reg_lr  = Ridge()\n","param   = {'alpha':[0.01, 0.001, 0.1, 0.5, 1, 5, 10, 100, 200, 300, 400, 1000]}\n","gsc     = GridSearchCV(reg_lr, param, cv = 5)\n","gsc.fit(X, np.log1p(Y))\n","\n","reg_lr  = gsc.best_estimator_\n","print(gsc.best_estimator_)"]},{"cell_type":"code","execution_count":169,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"train MAE 2541.08\ttest MAE 661.21\ntrain RMSE 3022.76\ttest RMSE 880.94\ntrain MAPE 18.34\ttest MAPE 10.87\n=========================\nyear 2005 true : 17938\tpred : 14646\nyear 2006 true : 19773\tpred : 15950\nyear 2007 true : 19986\tpred : 18909\nyear 2008 true : 14055\tpred : 20459\nyear 2009 true : 18252\tpred : 16174\nyear 2010 true : 9251\tpred : 10526\nyear 2011 true : 8187\tpred : 9591\nyear 2012 true : 11945\tpred : 9681\nyear 2013 true : 8263\tpred : 9515\nyear 2014 true : 7084\tpred : 8820\nyear 2015 true : 5899\tpred : 6300\nyear 2016 true : 4832\tpred : 5599\nyear 2017 true : 5408\tpred : 5342\nyear 2018 true : 5650\tpred : 5314\n"}],"source":["reg_lr.fit(X_train_ord, np.log1p(Y_train_ord))\n","\n","Y_all_test = reg_lr.predict(X)\n","Y_all_test[Y_all_test<0] = 0\n","\n","Y_all_test = np.expm1(Y_all_test)\n","\n","train_mae = mae(Y[:int(n_size*(1-0.3))], Y_all_test[:int(n_size*(1-0.3))])\n","test_mae = mae(Y[int(n_size*(1-0.3)):], Y_all_test[int(n_size*(1-0.3)):])\n","\n","train_rmse = rmse(Y[:int(n_size*(1-0.3))], Y_all_test[:int(n_size*(1-0.3))])\n","test_rmse = rmse(Y[int(n_size*(1-0.3)):], Y_all_test[int(n_size*(1-0.3)):])\n","\n","train_mape = mape(Y[:int(n_size*(1-0.3))], Y_all_test[:int(n_size*(1-0.3))])\n","test_mape = mape(Y[int(n_size*(1-0.3)):], Y_all_test[int(n_size*(1-0.3)):])\n","\n","print('train MAE {:.2f}\\ttest MAE {:.2f}'.format(train_mae, test_mae))\n","print('train RMSE {:.2f}\\ttest RMSE {:.2f}'.format(train_rmse, test_rmse))\n","print('train MAPE {:.2f}\\ttest MAPE {:.2f}'.format(train_mape, test_mape))\n","print('=========================')\n","\n","if yearlyyield == False:\n","    for year, month, y_true, y_pred in zip(year_target, month_target, Y, Y_all_test):\n","        print('year {:.0f} month {:.0f} true : {:.0f}\\tpred : {:.0f}'.format(year, month, y_true, y_pred))\n","else:\n","    for year, y_true, y_pred in zip(year_target, Y, Y_all_test):\n","        print('year {:.0f} true : {:.0f}\\tpred : {:.0f}'.format(year, y_true, y_pred))   "]},{"cell_type":"code","execution_count":170,"metadata":{},"outputs":[],"source":["# export output\n","# X_rnn[:int(train_ratio*n_size), :, :]\n","year_train  = year_target[:int(n_size*(1-0.3))]\n","month_train = month_target[:int(n_size*(1-0.3))] if yearlyyield == False else year_train\n","year_test   = year_target[int(n_size*(1-0.3)):]\n","month_test  = month_target[int(n_size*(1-0.3)):] if yearlyyield == False else year_test\n","y_train_true = Y[:int(n_size*(1-0.3))]\n","y_train_pred = Y_all_test[:int(n_size*(1-0.3))]\n","y_test_true = Y[int(n_size*(1-0.3)):]\n","y_test_pred = Y_all_test[int(n_size*(1-0.3)):]\n","export_output('ridge_results_monthly_input_yearly_output_v3.xlsx', year_train, month_train, y_train_true, y_train_pred, year_test, month_test, y_test_true, y_test_pred)"]},{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":["<h1> Ridge Model w Normalization </h1>"]},{"cell_type":"code","execution_count":171,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"Pipeline(memory=None,\n     steps=[('normalize', MinMaxScaler(copy=True, feature_range=(0, 1))), ('lr', Ridge(alpha=0.5, copy_X=True, fit_intercept=True, max_iter=None,\n   normalize=False, random_state=None, solver='auto', tol=0.001))])\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n  DeprecationWarning)\n"}],"source":["# vector for record error\n","train_mae = np.array([])\n","test_mae = np.array([])\n","\n","train_rmse = np.array([])\n","test_rmse = np.array([])\n","\n","train_r2 = np.array([])\n","test_r2 = np.array([])\n","\n","# using grid searchcv to optimize hyper param\n","estimators = [('normalize', MinMaxScaler()), ('lr', Ridge())]\n","pipe    = Pipeline(estimators)\n","param   = dict(lr__alpha=[0.01, 0.001, 0.1, 0.5, 1, 5, 10, 100])\n","\n","gsc     = GridSearchCV(pipe, param, cv = 5)\n","gsc.fit(X, np.log1p(Y))\n","\n","reg_lr_norm  = gsc.best_estimator_\n","print(gsc.best_estimator_)"]},{"cell_type":"code","execution_count":172,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"train MAE 2297.95\ttest MAE 853.32\ntrain RMSE 2454.53\ttest RMSE 985.37\ntrain MAPE 17.08\ttest MAPE 14.63\n=========================\nyear 2005 true : 17938\tpred : 16445\nyear 2006 true : 19773\tpred : 16788\nyear 2007 true : 19986\tpred : 18038\nyear 2008 true : 14055\tpred : 17971\nyear 2009 true : 18252\tpred : 14992\nyear 2010 true : 9251\tpred : 11319\nyear 2011 true : 8187\tpred : 9877\nyear 2012 true : 11945\tpred : 9702\nyear 2013 true : 8263\tpred : 9341\nyear 2014 true : 7084\tpred : 8633\nyear 2015 true : 5899\tpred : 6801\nyear 2016 true : 4832\tpred : 6039\nyear 2017 true : 5408\tpred : 5698\nyear 2018 true : 5650\tpred : 5332\n"}],"source":["reg_lr_norm.fit(X_train_ord, np.log1p(Y_train_ord))\n","\n","Y_all_test = reg_lr_norm.predict(X)\n","Y_all_test[Y_all_test<0] = 0\n","Y_all_test = np.expm1(Y_all_test)\n","\n","train_mae = mae(Y[:int(n_size*(1-0.3))], Y_all_test[:int(n_size*(1-0.3))])\n","test_mae = mae(Y[int(n_size*(1-0.3)):], Y_all_test[int(n_size*(1-0.3)):])\n","\n","train_rmse = rmse(Y[:int(n_size*(1-0.3))], Y_all_test[:int(n_size*(1-0.3))])\n","test_rmse = rmse(Y[int(n_size*(1-0.3)):], Y_all_test[int(n_size*(1-0.3)):])\n","\n","train_mape = mape(Y[:int(n_size*(1-0.3))], Y_all_test[:int(n_size*(1-0.3))])\n","test_mape = mape(Y[int(n_size*(1-0.3)):], Y_all_test[int(n_size*(1-0.3)):])\n","\n","print('train MAE {:.2f}\\ttest MAE {:.2f}'.format(train_mae, test_mae))\n","print('train RMSE {:.2f}\\ttest RMSE {:.2f}'.format(train_rmse, test_rmse))\n","print('train MAPE {:.2f}\\ttest MAPE {:.2f}'.format(train_mape, test_mape))\n","print('=========================')\n","\n","if yearlyyield == False:\n","    for year, month, y_true, y_pred in zip(year_target, month_target, Y, Y_all_test):\n","        print('year {:.0f} month {:.0f} true : {:.0f}\\tpred : {:.0f}'.format(year, month, y_true, y_pred))\n","else:\n","    for year, y_true, y_pred in zip(year_target, Y, Y_all_test):\n","        print('year {:.0f} true : {:.0f}\\tpred : {:.0f}'.format(year, y_true, y_pred))   "]},{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":["<h1> Support Vector Regression w/o Normalization </h1>"]},{"cell_type":"code","execution_count":173,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n  DeprecationWarning)\nPipeline(memory=None,\n     steps=[('svr', SVR(C=0.001, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n  kernel='linear', max_iter=-1, shrinking=True, tol=0.001, verbose=False))])\n"}],"source":["# vector for record error\n","train_mae = np.array([])\n","test_mae = np.array([])\n","\n","train_rmse = np.array([])\n","test_rmse = np.array([])\n","\n","train_r2 = np.array([])\n","test_r2 = np.array([])\n","\n","# using grid searchcv to optimize hyper param\n","estimators = [('svr', SVR(kernel = 'linear', gamma = 'scale'))]\n","pipe    = Pipeline(estimators)\n","param   = dict(\n","    svr__C=[0.001, 0.01, 0.1, 0.5, 1, 5, 100],\n","    svr__epsilon = [0.001, 0.01, 0.1, 0.5, 1])\n","\n","gsc     = GridSearchCV(pipe, param, cv = 3)\n","gsc.fit(X, np.log1p(Y))\n","# gsc.fit(X, Y)\n","\n","reg_svr  = gsc.best_estimator_\n","print(gsc.best_estimator_)"]},{"cell_type":"code","execution_count":174,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"train MAE 2467.46\ttest MAE 662.71\ntrain RMSE 3118.11\ttest RMSE 773.77\ntrain MAPE 16.59\ttest MAPE 11.22\n=========================\nyear 2005 month 8 true : 17938\tpred : 14458\nyear 2006 month 8 true : 19773\tpred : 15761\nyear 2007 month 8 true : 19986\tpred : 18887\nyear 2008 month 8 true : 14055\tpred : 20514\nyear 2009 month 8 true : 18252\tpred : 15784\nyear 2010 month 8 true : 9251\tpred : 9834\nyear 2011 month 8 true : 8187\tpred : 8824\nyear 2012 month 8 true : 11945\tpred : 8884\nyear 2013 month 8 true : 8263\tpred : 8671\nyear 2014 month 8 true : 7084\tpred : 7928\nyear 2015 month 8 true : 5899\tpred : 5490\nyear 2016 month 8 true : 4832\tpred : 4804\nyear 2017 month 8 true : 5408\tpred : 4545\nyear 2018 month 8 true : 5650\tpred : 4480\n"}],"source":["reg_svr.fit(X_train_ord, np.log1p(Y_train_ord))\n","# reg_svr.fit(X_train_ord, Y_train_ord)\n","\n","Y_all_test = reg_svr.predict(X)\n","Y_all_test[Y_all_test<0] = 0\n","Y_all_test = np.expm1(Y_all_test)\n","\n","train_mae = mae(Y[:int(n_size*(1-0.3))], Y_all_test[:int(n_size*(1-0.3))])\n","test_mae = mae(Y[int(n_size*(1-0.3)):], Y_all_test[int(n_size*(1-0.3)):])\n","\n","train_rmse = rmse(Y[:int(n_size*(1-0.3))], Y_all_test[:int(n_size*(1-0.3))])\n","test_rmse = rmse(Y[int(n_size*(1-0.3)):], Y_all_test[int(n_size*(1-0.3)):])\n","\n","train_mape = mape(Y[:int(n_size*(1-0.3))], Y_all_test[:int(n_size*(1-0.3))])\n","test_mape = mape(Y[int(n_size*(1-0.3)):], Y_all_test[int(n_size*(1-0.3)):])\n","\n","print('train MAE {:.2f}\\ttest MAE {:.2f}'.format(train_mae, test_mae))\n","print('train RMSE {:.2f}\\ttest RMSE {:.2f}'.format(train_rmse, test_rmse))\n","print('train MAPE {:.2f}\\ttest MAPE {:.2f}'.format(train_mape, test_mape))\n","print('=========================')\n","\n","if yearlyyield == False:\n","    for year, month, y_true, y_pred in zip(year_target, month_target, Y, Y_all_test):\n","        print('year {:.0f} month {:.0f} true : {:.0f}\\tpred : {:.0f}'.format(year, month, y_true, y_pred))\n","else:\n","    for year, y_true, y_pred in zip(year_target, Y, Y_all_test):\n","        print('year {:.0f} month {:.0f} true : {:.0f}\\tpred : {:.0f}'.format(year, month, y_true, y_pred))   "]},{"cell_type":"code","execution_count":177,"metadata":{},"outputs":[],"source":["# export output\n","# X_rnn[:int(train_ratio*n_size), :, :]\n","year_train  = year_target[:int(n_size*(1-0.3))]\n","month_train = month_target[:int(n_size*(1-0.3))] if yearlyyield == False else year_train\n","year_test   = year_target[int(n_size*(1-0.3)):]\n","month_test  = month_target[int(n_size*(1-0.3)):] if yearlyyield == False else year_test\n","y_train_true = Y[:int(n_size*(1-0.3))]\n","y_train_pred = Y_all_test[:int(n_size*(1-0.3))]\n","y_test_true = Y[int(n_size*(1-0.3)):]\n","y_test_pred = Y_all_test[int(n_size*(1-0.3)):]\n","export_output('svr_results_monthly_input_yearly_output_v3.xlsx', year_train, month_train, y_train_true, y_train_pred, year_test, month_test, y_test_true, y_test_pred)"]},{"cell_type":"markdown","execution_count":51,"metadata":{},"outputs":[],"source":["<h1> Support Vector Regression w Normalization </h1>"]},{"cell_type":"code","execution_count":175,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"Pipeline(memory=None,\n     steps=[('normalize', MinMaxScaler(copy=True, feature_range=(0, 1))), ('svr', SVR(C=0.5, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n  kernel='linear', max_iter=-1, shrinking=True, tol=0.001, verbose=False))])\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n  DeprecationWarning)\n"}],"source":["# vector for record error\n","train_mae = np.array([])\n","test_mae = np.array([])\n","\n","train_rmse = np.array([])\n","test_rmse = np.array([])\n","\n","train_r2 = np.array([])\n","test_r2 = np.array([])\n","\n","# using grid searchcv to optimize hyper param\n","estimators = [('normalize', MinMaxScaler()),('svr', SVR(kernel = 'linear', gamma = 'scale'))]\n","pipe    = Pipeline(estimators)\n","param   = dict(\n","    svr__C=[0.001, 0.01, 0.1, 0.5, 1, 5, 100],\n","    svr__epsilon = [0.001, 0.01, 0.1, 0.5, 1])\n","\n","gsc     = GridSearchCV(pipe, param, cv = 3)\n","gsc.fit(X, np.log1p(Y))\n","\n","reg_svr_norm  = gsc.best_estimator_\n","print(gsc.best_estimator_)"]},{"cell_type":"code","execution_count":176,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"train MAE 2307.98\ttest MAE 707.62\ntrain RMSE 2513.20\ttest RMSE 817.80\ntrain MAPE 16.74\t\ttest MAPE 12.09\n=========================\nyear 2005 month 8 true : 17938\tpred : 16223\nyear 2006 month 8 true : 19773\tpred : 16605\nyear 2007 month 8 true : 19986\tpred : 18089\nyear 2008 month 8 true : 14055\tpred : 18283\nyear 2009 month 8 true : 18252\tpred : 15031\nyear 2010 month 8 true : 9251\tpred : 11053\nyear 2011 month 8 true : 8187\tpred : 9608\nyear 2012 month 8 true : 11945\tpred : 9497\nyear 2013 month 8 true : 8263\tpred : 9134\nyear 2014 month 8 true : 7084\tpred : 8376\nyear 2015 month 8 true : 5899\tpred : 6555\nyear 2016 month 8 true : 4832\tpred : 5800\nyear 2017 month 8 true : 5408\tpred : 5480\nyear 2018 month 8 true : 5650\tpred : 5099\n"}],"source":["reg_svr_norm.fit(X_train_ord, np.log1p(Y_train_ord))\n","\n","Y_all_test = reg_svr_norm.predict(X)\n","Y_all_test[Y_all_test<0] = 0\n","Y_all_test = np.expm1(Y_all_test)\n","\n","train_mae = mae(Y[:int(n_size*(1-0.3))], Y_all_test[:int(n_size*(1-0.3))])\n","test_mae = mae(Y[int(n_size*(1-0.3)):], Y_all_test[int(n_size*(1-0.3)):])\n","\n","train_rmse = rmse(Y[:int(n_size*(1-0.3))], Y_all_test[:int(n_size*(1-0.3))])\n","test_rmse = rmse(Y[int(n_size*(1-0.3)):], Y_all_test[int(n_size*(1-0.3)):])\n","\n","train_mape = mape(Y[:int(n_size*(1-0.3))], Y_all_test[:int(n_size*(1-0.3))])\n","test_mape = mape(Y[int(n_size*(1-0.3)):], Y_all_test[int(n_size*(1-0.3)):])\n","\n","print('train MAE {:.2f}\\ttest MAE {:.2f}'.format(train_mae, test_mae))\n","print('train RMSE {:.2f}\\ttest RMSE {:.2f}'.format(train_rmse, test_rmse))\n","print('train MAPE {:.2f}\\t\\ttest MAPE {:.2f}'.format(train_mape, test_mape))\n","print('=========================')\n","\n","if yearlyyield == False:\n","    for year, month, y_true, y_pred in zip(year_target, month_target, Y, Y_all_test):\n","        print('year {:.0f} month {:.0f} true : {:.0f}\\tpred : {:.0f}'.format(year, month, y_true, y_pred))\n","else:\n","    for year, y_true, y_pred in zip(year_target, Y, Y_all_test):\n","        print('year {:.0f} month {:.0f} true : {:.0f}\\tpred : {:.0f}'.format(year, month, y_true, y_pred))   "]},{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":["<h1>Get X and y for Recurrent Neural Network</h1>"]},{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":["method for getting x data for rnn"]},{"cell_type":"code","execution_count":184,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"true\n(28, 2)\ntrue\n(28, 2)\nn_steps : 2 n_features : 3 n_size : 14\n"}],"source":["choose = 'monthly_yearlyyield_wyear'\n","\n","if choose == 'monthly_yearlyyield_wyear':\n","    yearlyyield = True\n","    input_vec = [\n","        [monthly_temp, 'x'],\n","        # [monthly_humid, 'x'], \n","        # [monthly_rain, 'x'], \n","        # [monthly_area, 'x'], \n","        # [monthly_yieldarea, 'x'], \n","        # [monthly_lychee, 'x'],\n","        [monthly_yieldarea[:,0].reshape(-1,1), 'y']]   # target year\n","\n","    output_vec = [monthly_lychee_yearlyyield]\n","\n","if choose == 'monthly_yearlyyield_woyear':\n","    yearlyyield = True\n","    input_vec = [\n","        [monthly_temp, 'x'],\n","        # [monthly_humid, 'x'], \n","        # [monthly_rain, 'x'], \n","        # [monthly_area, 'x'], \n","        # [monthly_yieldarea, 'x'], \n","        # [monthly_lychee, 'x'],\n","        ]#[monthly_yieldarea[:,0].reshape(-1,1), 'y']]   # target year\n","\n","if choose == 'test':\n","    input_vec = [\n","        [daily_temp, 'x'], \n","        [daily_yieldarea[:,0].reshape(-1,1), 'y'],   # target year\n","        [daily_yieldarea[:,0:2].reshape(-1,2), 'y']] # target month\n","\n","    output_vec = [daily_lychee]\n","\n","if choose == 'monthly':\n","    yearlyyield = False\n","    input_vec = [\n","        [monthly_temp, 'x'],\n","        # [monthly_humid, 'x'], \n","        # [monthly_rain, 'x'], \n","        # [monthly_area, 'x'], \n","        [monthly_yieldarea, 'x'], \n","        [monthly_lychee, 'x'], \n","        [monthly_yieldarea[:,0].reshape(-1,1), 'y'],   # target year\n","        [monthly_yieldarea[:,0:2].reshape(-1,2), 'y']] # target month\n","    \n","    output_vec = [monthly_lychee]\n","\n","if choose == 'daily':\n","    yearlyyield = False\n","    input_vec = [\n","        [daily_temp, 'x'],\n","        [daily_humid, 'x'], \n","        # [daily_rain, 'x'], \n","        # [daily_area, 'x'], \n","        # [daily_yieldarea, 'x'], \n","        [daily_lychee, 'x'], \n","        [daily_yieldarea[:,0].reshape(-1,1), 'y'],   # target year\n","        [daily_yieldarea[:,0:2].reshape(-1,2), 'y']] # target month\n","\n","    output_vec = [daily_lychee]\n","\n","if choose == 'hourly':\n","    yearlyyield = False\n","    input_vec = [\n","        [hourly_temp, 'x'],\n","        # [hourly_humid, 'x'], \n","        # [hourly_rain, 'x'], \n","        # [hourly_area, 'x'], \n","        [hourly_yieldarea, 'x'], \n","        [hourly_lychee, 'x'], \n","        [hourly_yieldarea[:,0].reshape(-1,1), 'y'],   # target year\n","        [hourly_yieldarea[:,0:2].reshape(-1,2), 'y']] # target month\n","\n","    output_vec = [hourly_lychee]\n","\n","# daily choose n_steps = 240\n","# hourly choose n_steps = 1920\n","# monthly choose n_steps = 4\n","# axis = 2 for rnn\n","\n","########## choose architecture of neural network\n","\n","choose = 'gru'\n","\n","X_rnn, Y_rnn, n_features, n_size, n_steps, year_target, month_target = get_XY_fr_resolution(input_vec, output_vec, n_steps = 2, axis = 1 if choose == 'ann' else 2, req_m_input = [1, 2], req_month = [4, 5, 6], yearlyyield = yearlyyield)\n","\n","print('n_steps : {:d} n_features : {:d} n_size : {:d}'.format(n_steps, n_features, n_size))"]},{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":["Seperate train set and test set with unshuffle for displaying</br>\n","test size = 53\n","train size = 124"]},{"cell_type":"code","execution_count":186,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"(9,)\n"}],"source":["train_ratio = 0.7\n","\n","X_train_ord         = X_rnn[:int(train_ratio*n_size), :] if choose == 'ann' else X_rnn[:int(train_ratio*n_size), :, :]\n","X_test_ord          = X_rnn[int(train_ratio*n_size):, :] if choose == 'ann' else X_rnn[int(train_ratio*n_size):, :, :]\n","Y_train_ord         = Y_rnn[:int(train_ratio*n_size)].reshape(-1)\n","Y_test_ord          = Y_rnn[int(train_ratio*n_size):].reshape(-1)\n","print(Y_train_ord.shape)"]},{"cell_type":"code","execution_count":187,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"(9, 2, 3)\n(9,)\n"}],"source":["X_train     = X_train_ord\n","X_test      = X_test_ord\n","Y_train     = Y_train_ord\n","Y_test      = Y_test_ord\n","\n","print(X_train.shape)\n","print(Y_train.shape)"]},{"cell_type":"markdown","execution_count":132,"metadata":{},"outputs":[],"source":["<h1> Recurrent Neural Network w/o Normalization </h1>"]},{"cell_type":"code","execution_count":188,"metadata":{},"outputs":[],"source":["class Scaler3D():\n","\n","    def __init__(self):\n","        self.scaler_list = {}\n","\n","    def fit(self, x):\n","        self.x = x\n","        \n","        min_list = np.array([])\n","        max_list = np.array([])\n","\n","        len_feature = x.shape[-1]\n","\n","        for i in range(len_feature):\n","            self.scaler_list[i] = MinMaxScaler()\n","            self.scaler_list[i].fit(x[:, :, i])\n","\n","    def transform(self, x):\n","        x_copy = x.copy()\n","\n","        len_feature = x.shape[-1]\n","\n","        for i in range(len_feature):\n","            x_copy[:,:,i] = self.scaler_list[i].transform(x[:, :, i])\n","\n","        return x_copy"]},{"cell_type":"code","execution_count":189,"metadata":{},"outputs":[],"source":["def create_model_lstm(n_steps, n_features):\n","    rnn = Sequential()\n","    rnn.add(LSTM(10, activation='relu', return_sequences=True, input_shape=(n_steps, n_features)))\n","    rnn.add(Dropout(0.2))\n","    rnn.add(LSTM(50, activation='relu'))\n","    rnn.add(Dropout(0.2))\n","    rnn.add(Dense(50, activation='relu'))\n","    rnn.add(Dropout(0.2))\n","    rnn.add(Dense(1, activation='relu'))\n","    rnn.compile(optimizer='adam', loss='mse')\n","\n","    return rnn  "]},{"cell_type":"code","execution_count":190,"metadata":{},"outputs":[],"source":["def create_model_gru(n_steps, n_features):\n","    \n","    rnn = Sequential()\n","    rnn.add(GRU(100, activation='relu', return_sequences=True, input_shape=(n_steps, n_features)))\n","    rnn.add(Dropout(0.4))\n","    rnn.add(GRU(100, activation='relu', return_sequences=True))\n","    rnn.add(Dropout(0.4))\n","    rnn.add(GRU(100, activation='relu'))    \n","    # rnn.add(BatchNormalization())    \n","    rnn.add(Dropout(0.4))\n","    rnn.add(Dense(50, activation='relu'))\n","    rnn.add(Dropout(0.4))    \n","    rnn.add(Dense(1, activation='relu'))\n","    rnn.compile(optimizer='adam', loss='mse')\n","    return rnn  "]},{"cell_type":"code","execution_count":191,"metadata":{},"outputs":[],"source":["def create_model_ann(n_steps, n_features):\n","    reg = l1(0.01)\n","    rnn = Sequential()\n","    # input layer\n","    rnn.add(Dense(128, activation='relu', input_dim=n_features))\n","    # hidden layer\n","    rnn.add(Dense(256, activation='relu',\n","                kernel_regularizer=reg)) \n","    rnn.add(Dropout(0.4))\n","    rnn.add(Dense(256, activation='relu',\n","                kernel_regularizer=reg))   \n","    rnn.add(Dropout(0.4)) \n","    rnn.add(Dense(256, activation='relu',\n","                kernel_regularizer=reg))   \n","    rnn.add(Dropout(0.4))     \n","    # output layer\n","    rnn.add(Dense(1, activation='relu'))\n","    rnn.compile(optimizer='adam', loss='mse')\n","    return rnn  "]},{"cell_type":"markdown","execution_count":220,"metadata":{},"outputs":[{"ename":"SyntaxError","evalue":"invalid syntax (<ipython-input-220-508429bda964>, line 1)","output_type":"error","traceback":["\u001b[1;36m  File \u001b[1;32m\"<ipython-input-220-508429bda964>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    <h1> Recurrent Neural Network w Normalization </h1>\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"]}],"source":["<h1> Recurrent Neural Network w Normalization </h1>"]},{"cell_type":"code","execution_count":200,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"Model: \"sequential_3\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ngru_9 (GRU)                  (None, 2, 100)            31500     \n_________________________________________________________________\ndropout_12 (Dropout)         (None, 2, 100)            0         \n_________________________________________________________________\ngru_10 (GRU)                 (None, 2, 100)            60600     \n_________________________________________________________________\ndropout_13 (Dropout)         (None, 2, 100)            0         \n_________________________________________________________________\ngru_11 (GRU)                 (None, 100)               60600     \n_________________________________________________________________\ndropout_14 (Dropout)         (None, 100)               0         \n_________________________________________________________________\ndense_6 (Dense)              (None, 50)                5050      \n_________________________________________________________________\ndropout_15 (Dropout)         (None, 50)                0         \n_________________________________________________________________\ndense_7 (Dense)              (None, 1)                 51        \n=================================================================\nTotal params: 157,801\nTrainable params: 157,801\nNon-trainable params: 0\n_________________________________________________________________\n"}],"source":["# Create a callback that saves the model's weights\n","if choose == 'lstm':\n","    checkpoint_path = './checkpoint_path_lstm'\n","    rnn = create_model_lstm(n_steps, n_features)   \n","elif choose == 'gru':\n","    checkpoint_path = './checkpoint_path_gru_3layer_monthly_yearlyyield.ckpt'\n","    rnn = create_model_gru(n_steps, n_features)   \n","else:\n","    checkpoint_path = './checkpoint_path_ann_3layer_monthly_yearlyyield.ckpt'\n","    rnn = create_model_ann(n_steps, n_features)       \n","\n","cp_callback     = tensorflow.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n","                                                 save_weights_only=True,\n","                                                 verbose=0)        \n","rnn.summary()        "]},{"cell_type":"code","execution_count":205,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"---- Iter : 0 ----\nTrain set MAE 4983.34\nTest set MAE 2605.03\nTrain set RMSE 6149.65\nTest set RMSE 2711.06\n---- Iter : 10 ----\nTrain set MAE 5084.22\nTest set MAE 2558.06\nTrain set RMSE 6340.46\nTest set RMSE 2670.75\n---- Iter : 20 ----\nTrain set MAE 4970.00\nTest set MAE 2671.87\nTrain set RMSE 6147.04\nTest set RMSE 2776.75\n---- Iter : 30 ----\nTrain set MAE 5051.69\nTest set MAE 2532.39\nTrain set RMSE 6215.97\nTest set RMSE 2645.32\n---- Iter : 40 ----\nTrain set MAE 5013.21\nTest set MAE 2882.98\nTrain set RMSE 6224.93\nTest set RMSE 2987.43\n---- Iter : 50 ----\nTrain set MAE 5085.69\nTest set MAE 3297.35\nTrain set RMSE 6397.43\nTest set RMSE 3389.54\n---- Iter : 60 ----\nTrain set MAE 5054.62\nTest set MAE 3135.19\nTrain set RMSE 6292.34\nTest set RMSE 3232.71\n---- Iter : 70 ----\nTrain set MAE 5089.15\nTest set MAE 3297.77\nTrain set RMSE 6403.02\nTest set RMSE 3388.83\n---- Iter : 80 ----\nTrain set MAE 5031.66\nTest set MAE 2933.66\nTrain set RMSE 6263.89\nTest set RMSE 3032.24\n---- Iter : 90 ----\nTrain set MAE 5048.89\nTest set MAE 3244.29\nTrain set RMSE 6318.78\nTest set RMSE 3335.31\n---- Iter : 100 ----\nTrain set MAE 5111.41\nTest set MAE 3015.12\nTrain set RMSE 6418.85\nTest set RMSE 3115.28\n---- Iter : 110 ----\nTrain set MAE 4999.47\nTest set MAE 3084.41\nTrain set RMSE 6220.03\nTest set RMSE 3192.23\n---- Iter : 120 ----\nTrain set MAE 5098.08\nTest set MAE 3061.29\nTrain set RMSE 6384.77\nTest set RMSE 3160.83\n---- Iter : 130 ----\nTrain set MAE 5037.47\nTest set MAE 3032.25\nTrain set RMSE 6282.36\nTest set RMSE 3128.19\n---- Iter : 140 ----\nTrain set MAE 5135.97\nTest set MAE 2953.78\nTrain set RMSE 6453.84\nTest set RMSE 3049.16\n---- Iter : 150 ----\nTrain set MAE 5109.92\nTest set MAE 3086.61\nTrain set RMSE 6421.16\nTest set RMSE 3177.41\n---- Iter : 160 ----\nTrain set MAE 5094.37\nTest set MAE 3096.49\nTrain set RMSE 6392.98\nTest set RMSE 3186.35\n---- Iter : 170 ----\nTrain set MAE 5092.23\nTest set MAE 2960.36\nTrain set RMSE 6393.63\nTest set RMSE 3052.83\n---- Iter : 180 ----\nTrain set MAE 4989.04\nTest set MAE 2752.54\nTrain set RMSE 6204.38\nTest set RMSE 2851.98\n---- Iter : 190 ----\nTrain set MAE 5119.33\nTest set MAE 2791.07\nTrain set RMSE 6439.83\nTest set RMSE 2889.36\n---- Iter : 200 ----\nTrain set MAE 5143.54\nTest set MAE 2824.20\nTrain set RMSE 6478.43\nTest set RMSE 2920.65\n---- Iter : 210 ----\nTrain set MAE 5166.22\nTest set MAE 2664.85\nTrain set RMSE 6518.99\nTest set RMSE 2766.86\n---- Iter : 220 ----\nTrain set MAE 5172.98\nTest set MAE 2445.26\nTrain set RMSE 6521.74\nTest set RMSE 2556.05\n---- Iter : 230 ----\nTrain set MAE 5385.94\nTest set MAE 2544.50\nTrain set RMSE 6761.86\nTest set RMSE 2651.07\n---- Iter : 240 ----\nTrain set MAE 5100.25\nTest set MAE 2625.39\nTrain set RMSE 6395.07\nTest set RMSE 2728.80\n---- Iter : 250 ----\nTrain set MAE 5031.93\nTest set MAE 2702.27\nTrain set RMSE 6274.28\nTest set RMSE 2802.87\n---- Iter : 260 ----\nTrain set MAE 5205.13\nTest set MAE 2739.49\nTrain set RMSE 6551.68\nTest set RMSE 2838.81\n---- Iter : 270 ----\nTrain set MAE 5177.06\nTest set MAE 2553.05\nTrain set RMSE 6527.02\nTest set RMSE 2659.32\n---- Iter : 280 ----\nTrain set MAE 5196.02\nTest set MAE 2557.50\nTrain set RMSE 6564.37\nTest set RMSE 2663.59\n---- Iter : 290 ----\nTrain set MAE 5186.56\nTest set MAE 2572.54\nTrain set RMSE 6549.59\nTest set RMSE 2678.03\n"}],"source":["# vector for record error\n","train_mae = np.array([])\n","test_mae = np.array([])\n","\n","train_rmse = np.array([])\n","test_rmse = np.array([])\n","\n","train_r2 = np.array([])\n","test_r2 = np.array([])\n","\n","# minmaxscaler\n","scaler = Scaler3D()\n","scaler.fit(X_train)\n","\n","for i in range(300):\n","\n","    # if os.path.isfile(checkpoint_path):\n","    #     rnn.load_weights(checkpoint_path)\n","\n","        if choose != 'ann':\n","            rnn.fit(scaler.transform(X_train), np.log1p(Y_train), epochs=50, verbose=0, batch_size=32)#, callbacks=[cp_callback])\n","\n","            Y_test_pred = rnn.predict(scaler.transform(X_test))\n","            Y_test_pred[Y_test_pred<0] = 0\n","\n","            Y_train_pred = rnn.predict(scaler.transform(X_train))\n","            Y_train_pred[Y_train_pred<0] = 0\n","\n","            Y_test_pred = np.expm1(Y_test_pred)\n","            Y_train_pred = np.expm1(Y_train_pred)\n","\n","        else:\n","            rnn.fit(scaler.transform(X_train), np.log1p(Y_train), epochs=5, verbose=1, batch_size=32)#, callbacks=[cp_callback])\n","\n","            Y_test_pred = rnn.predict(X_test)\n","            Y_test_pred[Y_test_pred<0] = 0\n","\n","            Y_train_pred = rnn.predict(X_train)\n","            Y_train_pred[Y_train_pred<0] = 0\n","\n","            Y_test_pred = np.expm1(Y_test_pred)\n","            Y_train_pred = np.expm1(Y_train_pred)\n","\n","            Y_train = np.expm1(Y_train)\n","            Y_test  = np.expm1(Y_test)\n","\n","        train_mae = np.append(train_mae, mae(Y_train, Y_train_pred))\n","        test_mae = np.append(test_mae, mae(Y_test, Y_test_pred))\n","\n","        train_rmse = np.append(train_rmse, rmse(Y_train, Y_train_pred))\n","        test_rmse = np.append(test_rmse, rmse(Y_test, Y_test_pred)) \n","\n","        if i%10 == 0:\n","            print('---- Iter : {:d} ----'.format(i))\n","\n","            print('Train set MAE {:.2f}'.format(np.mean(train_mae[-1])))\n","            print('Test set MAE {:.2f}'.format(np.mean(test_mae[-1])))\n","\n","            print('Train set RMSE {:.2f}'.format(np.mean(train_rmse[-1])))\n","            print('Test set RMSE {:.2f}'.format(np.mean(test_rmse[-1])))  "]},{"cell_type":"code","execution_count":206,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"train MAE 141.59\ttest MAE 2680.41\ntrain RMSE 157.86\ttest RMSE 2781.53\ntrain MAPE 42.40\t\ttest MAPE 48.73\n=========================\nyear 2005 true : 17938\tpred : 18134\nyear 2006 true : 19773\tpred : 19869\nyear 2007 true : 19986\tpred : 19861\nyear 2008 true : 14055\tpred : 14204\nyear 2009 true : 18252\tpred : 18323\nyear 2010 true : 9251\tpred : 9220\nyear 2011 true : 8187\tpred : 8458\nyear 2012 true : 11945\tpred : 12072\nyear 2013 true : 8263\tpred : 8471\nyear 2014 true : 7084\tpred : 8455\nyear 2015 true : 5899\tpred : 8463\nyear 2016 true : 4832\tpred : 8451\nyear 2017 true : 5408\tpred : 8461\nyear 2018 true : 5650\tpred : 8445\n"}],"source":["Y_all_test = rnn.predict(scaler.transform(X_rnn))\n","Y_all_test[Y_all_test<0] = 0\n","\n","Y_all_test = np.expm1(Y_all_test)\n","# Y_all_test = scaler_Y.inverse_transform(Y_all_test)\n","\n","train_mae = mae(Y_rnn[:int(n_size*(1-0.3))], Y_all_test[:int(n_size*(1-0.3))])\n","test_mae = mae(Y_rnn[int(n_size*(1-0.3)):], Y_all_test[int(n_size*(1-0.3)):])\n","\n","train_rmse = rmse(Y_rnn[:int(n_size*(1-0.3))], Y_all_test[:int(n_size*(1-0.3))])\n","test_rmse = rmse(Y_rnn[int(n_size*(1-0.3)):], Y_all_test[int(n_size*(1-0.3)):])\n","\n","train_mape = mape(Y[:int(n_size*(1-0.3))], Y_all_test[:int(n_size*(1-0.3))])\n","test_mape = mape(Y[int(n_size*(1-0.3)):], Y_all_test[int(n_size*(1-0.3)):])\n","\n","print('train MAE {:.2f}\\ttest MAE {:.2f}'.format(train_mae, test_mae))\n","print('train RMSE {:.2f}\\ttest RMSE {:.2f}'.format(train_rmse, test_rmse))\n","print('train MAPE {:.2f}\\t\\ttest MAPE {:.2f}'.format(train_mape, test_mape))\n","print('=========================')\n","\n","if yearlyyield == False:\n","    for year, month, y_true, y_pred in zip(year_target, month_target, Y, Y_all_test):\n","        print('year {:.0f} month {:.0f} true : {:.0f}\\tpred : {:.0f}'.format(year, month, y_true, y_pred))\n","else:\n","    for year, y_true, y_pred in zip(year_target, Y, Y_all_test):\n","        print('year {:.0f} true : {:.0f}\\tpred : {:.0f}'.format(year, y_true, y_pred[0]))   "]},{"cell_type":"code","execution_count":252,"metadata":{},"outputs":[],"source":["# export output\n","# X_rnn[:int(train_ratio*n_size), :, :]\n","year_train  = year_target[:int(n_size*(1-0.3))]\n","month_train = month_target[:int(n_size*(1-0.3))] if yearlyyield == False else year_train\n","year_test   = year_target[int(n_size*(1-0.3)):]\n","month_test  = month_target[int(n_size*(1-0.3)):] if yearlyyield == False else year_test\n","y_train_true = Y[:int(n_size*(1-0.3))]\n","y_train_pred = Y_all_test[:int(n_size*(1-0.3))]\n","y_test_true = Y[int(n_size*(1-0.3)):]\n","y_test_pred = Y_all_test[int(n_size*(1-0.3)):]\n","export_output('rnn_results_monthly_input_yearly_output.xlsx', year_train, month_train, y_train_true, y_train_pred, year_test, month_test, y_test_true, y_test_pred)"]}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}